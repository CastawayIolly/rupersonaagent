УНИВЕРСИТЕТ ИТМО С.В. Рыбин СИНТЕЗ РЕЧИ Учебное пособие Санкт-Петербург 2014 Рыбин С. В. СИНТЕЗ РЕЧИ Учебное пособие по дисциплине "Синтез речи".
– СПб: Университет ИТМО, 2014.
– 92 с. В учебном пособии рассматриваются технологии синтеза интонационной речи.
Синтез речи является одной из важнейших задач речевой обработки и имеет широкое применение в современных информационных технологиях.
Материал пособия разбит на 6 разделов.
Изложены история вопроса и основные этапы разработки систем автоматического синтеза.
Пособие может быть использовано при подготовке магистров по направлению 230400.68 “ИНФОРМАЦИОННЫЕ ТЕХНОЛОГИИ”, а также магистров по направлению 230100.68 “ИНФОРМАТИКА И ВЫЧИСЛИТЕЛЬНАЯ ТЕХНИКА” и аспирантов.
Рекомендовано Советом факультета Информационных технологий и программирования 25.02.2014 г., протокол № 2 
Университет ИТМО – ведущий вуз России в области информационных и фотонных технологий, один из немногих российских вузов, получивших в 2009 году статус национального исследовательского университета.
С 2013 года Университет ИТМО – участник программы повышения конкурентоспособности российских университетов среди ведущих мировых научно-образовательных центров, известной как проект «5 в 100».
Цель Университета ИТМО – становление исследовательского университета мирового уровня, предпринимательского по типу, ориентированного на интернационализацию всех направлений деятельности.
@Университет ИТМО, 2014
@С.В. Рыбин. 2014
Оглавление 
ВВЕДЕНИЕ ________________________________ ______________________ 5 
1. СИСТЕМЫ СИНТЕЗА РЕЧИ: ИСТОРИЯ РАЗВИТИЯ, СОВРЕМЕННОЕ СОСТОЯНИЕ ____________________________________________________ 6 
1.1. Первые механические синтезаторы ___________________________ 6
1.2. Первые электрические синтезаторы ___________________________ 9
1.3. ХХ век: синтезаторы первого поколения ______________________ 13
1.3.1. Артикуляционный синтез ________________________________ 13
1.3.2. Формантный синтез ______________________________________ 14
1.3.3. Синтезаторы, использующие линейное предсказание __________ 16
1.4. ХХ век: синтезаторы второго поколения ______________________ 17
1.5. ХХ век: синтезаторы третьего поколения _____________________ 18
1.5.1. Селективный синтез речи ________________________________ 18
1.5.2. Статистический параметрический синтез ____________________ 19
1.6. Перспективные направления синтеза _________________________ 19
2. ОБЗОР ТЕХНОЛОГИЙ TTS ______________________________________ 20
2.1. Типы синтезаторов _________________________________________ 20
2.1.1. Параметрический синтез __________________________________ 20
2.1.2. Компилятивный синтез ___________________________________ 20
2.1.3. Синтез речи по фонетическим правилам _____________________ 21
2.2. Оценка качества синтеза речи _______________________________ 21
2.3. Структура TTS ____________________________________________ 23
3. ЛИНГВИСТИЧЕСКИЙ ТЕКСТОВЫЙ ПРОЦЕССОР _________________ 26
3.1. Задачи лингвистического процессора _________________________ 26
3.2. Нормализация текста (графематический анализ) ______________ 28
3.2.1. Выделение предложений, слов, символов, знаков препинания ___ 29
3.2.2. Обработка пользовательской разметки ______________________ 30
3.2.3. Расшифровка нестандартных записей _______________________ 30
3.3. Использование словарей в синтезе речи _______________________ 32
3.4. Обработка незнакомых слов _________________________________ 33 3.5.
Снятие омонимии (омографии) ______________________________ 34
3.6. Методы разрешения неоднозначности при анализе текста ______ 35
3.6.1. Синтаксический и морфологический анализ предложения ______ 35
3.6.2. Статистические методы ___________________________________ 35
4. ПРОСОДИЧЕСКИЙ ПРОЦЕССОР _______________________________ 36
4.1. Определение границ синтагм ________________________________ 36
4.1.1. Установка пауз по правилам _______________________________ 37
4.1.2. Установка пауз на основе статистических моделей ____________ 38
4.2. Определение интонационного контура ________________________ 39
4.2.1. Генерация контура F0 методом ресинтеза ____________________ 40
4.2.2. Формирование контура F0 для произвольного предложения _____ 42
4.2.3. Генерация тонального контура в системах инженерного типа __ 43
4.2.4. Генерация тонального контура на основе лингвистических моделей интонации ___ 45
4.3. Примеры интонационных контуров __________________________ 47
5. ФОНЕТИЧЕСКИЙ ПРОЦЕССОР ________________________________ 48
5.1. Построение транскрипции __________________________________ 48
5.2. Вычисление физических параметров _________________________ 50
6. АКУСТИЧЕСКИЙ ПРОЦЕССОР _________________________________ 53
6.1. Оптимальный выбор звуковых элементов методом Unit Selection 53
6.1.1. Стоимость замены _______________________________________ 55
6.1.2. Стоимость связи _________________________________________ 57
6.1.3. Поиск по алгоритму Витерби ______________________________ 58
6.1.4. Речевая база и качество синтеза для метода Unit Selection _______ 58
6.1.5. Основные сложности и ограничения применения метода Unit Selection ____ 60
6.2. Сглаживание энергетической огибающей _____________________ 60
6.3. Модификация звуковых элементов ___________________________ 61
6.3.1. Алгоритм TD-PSOLA _____________________________________ 61
6.3.2. Алгоритм SPECINT (Spectrum Interpolation) __________________ 63
6.3.3. Алгоритм LP-PSOLA _____________________________________ 68
6.3.4. Экспериментальные сравнения _____________________________ 71
6.4. Объединение элементов в единый звуковой поток _____________ 74
6.5. Звуковые эффекты, используемые при синтезе речи ____________ 75
6.5.1. Параметрический эквалайзер ______________________________ 76
6.5.2. Ревербератор ____________________________________________ 78
7. СИНТЕЗ, ОСНОВАННЫЙ НА МОДЕЛЯХ __________________________ 79 
ЛИТЕРАТУРА ___________________________________________________ 85
ВВЕДЕНИЕ 
Автоматический синтез речи- это технология, позволяющая преобразовать входную текстовую информацию в звучащую речь.
При этом одним из важнейших аспектов является качество синтезируемой речи.
Именно от качества зависит пригодность использования технологии синтеза речи на современном коммерческом уровне.
Под системами автоматического синтеза речи (иначе их еще называют синтезаторами речи) в настоящее время понимают системы, преобразующие орфографический текст и другую информацию в звучащую речь.
Общепринятое в английской литературе обозначение – TTS (Text To Speech) System – системы преобразования текста в речь.
Технология автоматического синтеза речи может быть полезна в самых различных отраслях и направлениях, таких как: телекоммуникации, мобильные устройства, промышленные и бытовые электронные устройства, автомобильная индустрия, образовательные системы, компьютеризированные системы, Internet-сервисы, системы ограничения доступа, аэрокосмическая промышленность, военно-промышленный комплекс.
Синтезаторы речи обладают широкими возможностями применения.
Например, в call-центрах и автоинформационных системах.
Технология синтеза речи многого достигла в своем развитии.
Синтезированную речь сегодня часто сложно отличить от естественной речи.
Позвонив в информационную службу, мы уже слышим не роботизированную речь, а приятный естественный голос.
Технология синтеза речи, интегрированная в автоинформационную систему, «охотно» вступит в беседу с каждым дозвонившимся и поможет в получении информации.
На 90% запросов к любым информационно-справочным системам способен отвечать компьютер.
Автоинформационная система с синтезом речи освобождает операторов от ответов на часто повторяющиеся вопросы такого плана как курс доллара, точное время, прогноз погоды и многое другое.
Технология синтеза речи открывает широкие возможности для людей с физическими недостатками.
Разработаны говорящие машины для слепых и слабовидящих.
Для немых предусмотрены портативные устройства синтеза речи, в которых сообщение набирается на клавиатуре, что позволяет общаться с другими людьми.
На сегодняшний день благодаря электронным словарям и переводчикам на основе технологии синтеза речи возможно изучение иностранных языков с постановкой правильного произношения.
Электронный словарь помещается в кармане и может быть использован в любом месте, а не только за рабочим столом, как это обычно бывает с традиционным книжным словарем.
Еще одним примером синтеза речи могут служить различные системы звукового оповещения: телефонная справочная информация, объявление станций в метро, информация об отправлении автобуса или поезда, реклама в универмаге.
На основе технологии синтеза речи созданы «говорящие» книги (аудиокниги).
Такие книги позволяют по-новому воспринять литературное произведение – в его звуковом оформлении.
Многие люди полагают, что напечатанный текст не передает всей полноты ощущений.
В то время как элементарная разница в произношении или, например, интонации героев делает произведение более живым.
Можно с уверенностью сказать, что системы синтеза речи в различных формах своего практического применения прочно вошли в нашу повседневную жизнь.
1. СИСТЕМЫ СИНТЕЗА РЕЧИ : ИСТОРИЯ РАЗВИТИЯ, СОВРЕМЕННОЕ СОСТОЯНИЕ 
Синтез речи, то есть в широком смысле искусственное создание звучащей речи, подобной человеческому голосу, – задача, которая издавна интересовала людей (возможно, как часть идеи создания искусственного человека).
Существуют легенды о «говорящих головах», умевших отвечать на вопросы, которые были созданы Гербертом Орильякским (946 – 1003), Альбертом Великим (1198 – 1280) и Роджером Бэконом (1214 – 1294).
Но и достоверная история создания машин, имитирующих человеческую речь, насчитывает уже более двух веков.
С течением времени изменялись, как и сами механизмы, и принципы работы синтезирующих устройств, так и основные области интереса и задачи учёных, занимающихся созданием и развитием синтеза речи.
1.1. Первые механические синтезаторы
Первые синтезаторы, появившиеся во второй половине XVIII века, были механическими, они могли порождать отдельные звуки или небольшие фрагменты слитной человекоподобной речи подобно музыкальным инструментам, то есть требовали участия оператора-исполнителя.
Очень важным является то, что уже в них посредством различных механических приспособлений воспроизводились основные процессы, происходящие при производстве речи человеком.
Первые механические машины являлись скорее музыкальными инструментами, чем сложными техническими системами.
В 1779 году Петербургская Академия наук объявила ежегодную премию за объяснение разницы между пятью гласными звуками и за конструирование устройства, их порождающего.
Немецкий учёный Христиан Готлиб Кратценштейн (1723 – 1795), работавший в то время в Петербурге, предложил лучшее решение.
Он создал систему резонаторов (рис. 1.1), при помощи пульсирующего воздушного потока порождавших русские гласные.
Воздушный поток порождался вибрирующими язычками, подобными голосовым связкам человека [2].
Рисунок 1.1. Система резонаторов Кратценштейна
Ещё ранее и независимо от Кратценштейна над механической системой синтеза речи стал работать и представил результат своих трудов в 1791 году австрийский изобретатель Вольфганг фон Кемпелен (1734 – 1804).
Его машина могла произносить различные звуки и их комбинации.
В ней моделировалось продвижение струи воздуха через голосовой тракт человека: имелись меха для подачи воздуха на язычок, который возбуждал резонатор, управляемый рукой.
Согласные, в том числе и носовые, получались с помощью четырёх каналов, зажимаемых пальцами [2].
По утверждению самого Кемпелена, его машина производила 19 хорошо различимых согласных звуков и короткие фразы на нескольких языках.
Для управления «говорящей машиной» требовался хорошо обученный оператор, порождение речи можно было сравнить с игрой на органе.
Усовершенствованный вариант машины Кемпелена (рис. 1.2) был создан в 1837 году английским физиком Чарльзом Уитстоном (1802 – 1875).
Также под впечатлением от машины Уитстона американский учёный и изобретатель Александр Грэм Бэлл (1847 – 1922) собрал собственную аналогичную модель.
В течение XIX века в технологии синтеза речи не было каких-либо революционных изменений.
Известны исследования английского учёного Роберта Уиллиса (1800 – 1875), который подобно Кратценштейну экспериментировал с синтезом гласных звуков и установил связь между качеством гласных и геометрической формой голосового тракта.
В своих работах 1828 года «О гласных звуках» и «О механизме гортани» Уиллис описал механизм извлечен ия гласных звуков по аналогии со звукоизвлечением органа.
В 1840 году Джозеф Фабер (1800 – 1850) представил свою говорящую машину под названием «Эйфония», которая по сообщениям современников могла производить обычную и шепотную речь, а также исполнять песни. Машина Фабера состояла из воздушного меха, который приводился в движение ножной педалью.
Это были «как бы» легкие человека.
Процесс производства звука был следующим: в вытесняемый из меха воздух направлялся в различные по объёму трубки, при помощи ряда клавиш.
Каждая из этих трубок отвечала за разные положения голосовой щели и полости рта.
То есть Фабер хотел просто механически воспроизвести весь голосовой аппарат человека.
Правда, ему это не удалось до конца осуществить.
Голосовой тон в машине Фабера производился при помощи вибрации тонкой пластинки из слоновой кости на каучуковой подкладке.
Звук получался очень резким и крикливым.
Проще говоря, очень неприятным для человеческого уха.
В источниках, описывающих работу машины Фабера указано, что звук «p» производится вибрацией не «языка», а твердой пластинки, помещенной за гортанью.
А вот трубка, изображающая нос, находилась не сверху надставной трубы, изображающей рот, а ниже её и. Механизм, в целом, был очень тяжелым, и требовал серьезных усилий со сторон ы исполнителя, который пытался извлечь звуки речи.
Рис. 1.2.
Говорящая машина Кемпелена, построенная Уитстоном В XX веке, несмотря на развитие электрических методов синтеза речи, разработка механических синтезаторов речи проводилась до 60-х годов.
Это было связано, с одной стороны, с малой доступностью сложных электрических компонентов, а с другой – с необходимостью имитации и измерения нелинейных эффектов в голосе, которые с трудом поддаются расчётам и не могут быть легко смоделированы с помощью линейных устройств [2].
Среди наиболее известных устройств следует упомянуть механический синтезатор Р. Риша, продемонстрированный им в 1937 году (рис. 1.3).
По форме он практически повторял голосовой тракт человека, был выполнен из резины и металла и управлялся клавишами, подобными клавишам трубы.
Таким образом, общим методом создания механических синтезаторов стала имитация или прямое моделирование голосового тракта человека.
Рис. 1.3. Механическое говорящее устройство Риша 
Основными рабочими компонентами таких моделей были: устройство для подачи воздуха (аналог лёгких), вибрирующая часть (аналог гортани) и система резонаторов, в большей или меньшей степени точно воссоздававших форму голосового тракта человека.
Механические синтезаторы стали прототипом современного артикуляционного синтеза.
Всё более новые и всё более сложные механические синтезаторы регулярно появлялись примерно до середины XX века.
1.2. Первые электрические синтезаторы 
В XIX веке появление резонаторной теории Гельмгольца дало новый толчок в развитии речевых исследований.
Речевой тракт человека рассматривался как последовательность резонаторов.
Было установлено, что гласные звуки различаются резонансными частотами, названными впоследствии формантами.
Вокальный тракт может быть рассмотрен как простая акустическая труба с открытым концом или резонатор.
Форманты образуются при прохождении звуковой волны от звукового источника (голосовых складок) к губам.
Звук частично отражается от губ говорящего и идет к слушателю, а частично отражается от губ и идет в обратном направлении к голосовым складкам.
Начались попытки построить синтезаторы речи – электрические аналоги речепроизводящей системы.
Самый первый электрический синтезатор был создан Дж. Стюартом в 1922 году.
Его схема (рис. 1.4) включала в себя электрический зуммер для моделирования голосовых связок и пару индуктивно-ёмкостных резонаторов для моделирования резонансов горла и ротовой полости.
Таким образом, генерировались первые две форманты, то есть устройство могло синтезировать только гласные звуки.
Рис. 1.4. Электрическая модель голосового тракта Стюарта 
Аналогичный синтезатор, состоящий из четырёх подключенных параллельно резонаторов, возбуждаемых прерывателем тока, был создан немецким инженером Карлом Вилли Вагнером (1883 – 1953) в 1936 году [2].
Следующий важный шаг в формировании технологии синтеза речи связан с развитием радиотехники, построением вокодеров (систем кодирования и декодирования речи, в которых используются различные методы сжатия полосы частот для передачи сигналов, «voic e coder») и ЭВМ.
Первым электрическим синтезатором, способным генерировать фрагменты связной речи, стал «водер» (Voder – Voice Operating Demonstrator), созданный американским инженером Гомером Дадли (1896 – 1987), Р. Ришем и С. Уоткинсом.
Водер был основан на вокодере (название произошло от двух слов voice — голос, и coder — кодировщик), созданном в Bell Laboratories в середине 30-х годов.
От вокодера была взята синтезирующая часть, управлявшаяся вручную посредством тринадцати клавиш, ножной педали и переключателя источника шума на браслете (рис. 1.5) [2].
Водер управлялся от ручной клавиатуры и синтезировал сигналы с заданным спектром.
Десять параллельно соединенных полосовых фильтров составляли блок управления резонансами.
Переключение источника возбуждения- шумового или импульсного генератора- осуществлялось браслетом на запястье оператора, а управление частотой импульсов- ножной педалью.
На выходе фильтров стояли потенциометры, управлявшиеся десятью пальцами и изменявшие напряжение сигнала каждого фильтра.
Для имитации взрывных согласных использовались еще три дополнительные клавиш и. Обучение операторов "игре" на водере требовало значительного времени, но зато в итоге получалась довольно качественная речь с высоким уровнем разборчивости.
Усовершенствованный вариант вокодера Дадли, VODER, был представлен на Нью-Йоркской Всемирной выставке 1939 года.
Рис. 1.5. Схема вокодера Дадли 
В 1938 году советским ученым Е.А.Мурзиным был создан синтезатор звуков АНС.
Евгений Мурзин, назвал свое изобретение в честь Александра Николаевича Скрябина.
В этом устройстве речь генерировалась с помощью рядов Фурье как сумма гармоник — элементарных спектральных составляющих, то есть чистых тонов.
Банк тонов был записан на покрытый фотоэмульсией стеклянный диск, очень похожий на современный компакт-диск.
Он был покрыт фотоэмульсией, и с помощью специального станка на него концентрическими кольцами были записаны 144 фотооптические звуковые дорожки "чистых тонов".
Как происходил синтез звука показано на рис. 1.6.
Важным этапом в развитии методов экспериментальных фонетических исследований и синтеза речи стала разработка звукового спектрографа в 1946 году.
Появилась идея использования спектрограмм для управления синтезатором речи.
Для автоматического озвучивания речевых спектрограмм было создано несколько устройств.
В устройстве Л. Шотта 1948 года использовался линейный источник света, расположенный вдоль оси частот спектрограммы и просвечивающий участки изображения с различной степенью прозрачности, а фотоэлементы, расположенные в ряд вплотную друг к другу по другую сторону спектрограммы, являлись источником управляющих сигналов для набора тех же полосовых фильтров, что и в водере Дадли.
Дополнительные дорожки на спектрограмме управляли переключением тона и шума и несли информацию о частоте основного тона (ЧОТ).
Подобный метод использовался Дж. Борстом и Ф. Купером в устройстве, названным ими «водек» (1957 год) [2].
Рис. 1.6. Синтезатор Мурзина
Наиболее известный «проигрыватель» спектрограмм, синтезатор Pattern Playback (рис. 1.7), был представлен американскими исследователями Ф. Купером, А. Либерманом и Дж. Борстом в 1951 году.
Он состоял из оптической системы для динамической модуляции амплитуд гармоник основного тона в 120 Гц в зависимости от изображений на движущейся прозрачной ленте.
Рис. 1.7. Синтезатор Pattern Playback
При помощи этого синтезатора, позволявшего производить монотонную разборчивую речь, проводились многочисленные эксперименты по оценке значимости для восприятия речи различных акустических характеристик, путём упрощения и стилизации подаваемых на синтез фонограмм.
В первых электрических синтезаторах уже напрямую не моделируется голосовой тракт человека.
Вместо этого основным методом создания синтезированной речи является моделирование (или прямое считывание со спектрограммы) акустических характеристик речевого сигнала.
Основными рабочими компонентами таких синтезаторов были устройства, генерирующие шум и периодический сигнал, и набор фильтров или резонаторов, усиливающих заранее определённые частотные составляющие.
Электрические синтезаторы стали прототипом современного компьютерного пара метрического синтеза.
Следующей важной вехой в истории синтеза речи стало развитие акустической теории речеобразования (1960), создавшей необходимую теоретическую базу для создания основанных на ней формантных и артикуляционных синтезаторов, а также синтез аторов, использующих линейное предсказание.
Эти три метода называют также технологиями синтеза первого поколения [3].
1.3. ХХ век: синтезаторы первого поколения
Синтезаторы первого поколения можно на основании используемых методов разделить на две большие группы: акустические и артикуляционные.
К направлению акустического синтеза относится формантный синтез и синтез с использованием линейного предсказания.
При создании акустических синтезаторов не ставится задачи непосредственного отражения в синтезе процессов, связывающих артикуляцию с акустикой речевого сигнала, а вместо этого они выявляют и воспроизводят в синтезируемом сигнале существенные для восприятия акустические характеристики естественной речи.
В этом смысле акустический синтез является продолжение м того направления, которое было начато созданием вокодеров и электрических параметрических синтезаторов разного типа.
1.3.1. Артикуляционный синтез
Артикуляционный (или артикуляторный) синтез в некоторой мере продолжил направление, заданное первыми механическими синтезаторами.
В нём делается попытка синтезировать речевой сигнал на основе моделирования процесса речеобразования с учетом сведений об артикуляции, используемых для количественной оценки формы речевого тракта, его резонансных свойств и характеристик звуковых источников.
Затем на основе расчетных данных генерируется речевой сигнал.
В артикуляционной модели трубка, соответствующая голосовому тракту, обычно разделяется на множество небольших секций, и таким образом может быть представлена в качестве неоднородной электрической линии передачи [2].
Первые электронные артикуляционные модели были статическими и требовали ручной настройки.
Первый синтезатор американского исследователя Х. Данна 1950 года состоял из 25 одинаковых звеньев, между которыми для учёта влияния положения языка можно было ввести переменную индуктивность, а индуктивность на конце линии отражала влияние губ. Для произнесения вокализованных звуков синтезатор возбуждался пилообразным напряжением регулируемой частоты, а шумные звуки получались подключением к соответствующей точке линии белого шума [2].
Первый артикуляционный синтезатор с динамическим контролем (рис. 1.8) DAVO (Dynamic Analog of the VOcal tract) был разработан в 1958 году в Массачусетском технологическом институте Д. Розеном.
Он управлялся записанными на ленту контролирующими сигналами, созданными вручную.
С течением времени артикуляционные синтезаторы развивались, в них вводилось дополнительное моделирование ослабления сигнала в голосовом тракте, взаимодействия источника и фильтра, распространения сигнала от губ и, конечно, совершенствовалось моделирование голосового источника сигнала.
Кроме этого, многие подходы включают моделирование движений и параметров мышц и управления моторикой.
Однако из-за сложностей подобного рода моделирования в большинстве современных систем синтеза речи, позволяющих получать речь высокого качества, используются более «простые» подходы, а артикуляционный синтез чаще применяется в научных исследованиях в области артикуляционной фонетики и физиологии речи.
Кроме этого, артикуляционный синтез непосредственно связан с областью аудиовизуального синтеза (или «говорящей головы»), задачей которого является построение визуальной модели головы и лица в процессе говорения [3].
Рис.1.8. Аналог голосового тракта с линией передачи, управляемый непрерывно
1.3.2. Формантный синтез 
Первым формантным синтезатором стал PAT (Parametric Artificial Talker) английского исследователя Уолтера Лоуренса, представленный в 1953 году.
Этот синтезатор состоял из трёх электронных формантных резонаторов, соединённых параллельно, на вход которым подавался шум или гармонический сигнал.
Он управлялся шестью временными функциями (три форманты, частота основного тона, амплитуда шума и амплитуда голосового источника), которые считывались с нарисованных на движущейся стеклянной дорожке шаблонов.
Этот синтезатор был первым из параллельных формантных синтезаторов.
Их главным преимуществом была относительная простота управления.
Вторым типом формантных синтезаторов, позволяющим более точно моделировать передаточную функцию голосового тракта, но имеющих зачастую более сложную структуру, стали каскадные синтезаторы, в которых формантные резонаторы были соединены последовательно (рис. 1.9).
В том же 1953 году известный шведский исследователь речи, автор классической акустической модели речеобразования «источник-фильтр» Гуннар Фант продемонстрировал свой каскадный формантный синтезатор OVE I (Orator Verbis Electris).
В нём частота двух нижних резонаторов контролировались механической рукой, а амплитуда и частота основного тона определялись ручными потенциометрами.
Рис.1.9. Каскадный и параллельный синтезаторы
В дальнейшем оба типа синтезаторов усложнялись и совершенствовались, позволяя каждой новой версии звучать всё ближе к естественной человеческой речи.
В 1973 году английскому исследователю Джону Холмсу удалось вручную настроить на своём синтезаторе произнесение предложения «I enjoy the simple life» так хорошо, что обычный слушатель не мог отличить его от произнесения того же текста живым человеком.
Однако оставалась проблема с автоматическим контролем работы синтезатора, который не мог пока приблизиться к ручной настройке произнесения С развитием компьютерной техники и появлением вычислительных машин в середине 50-х годов электрические аналоговые синтезаторы стали постепенно замещаться компьютерными программами или специально сконструированной цифровой аппаратурой, позволявшими работать с цифровым представлением речевого сигнала.
В 1972 году американский исследователь Д. Клатт предложил вариант гибридного формантного синтезатора, в котором сонорные и шумные звуки синтезировались каскадными и параллельными формантными резонаторами соответственно.
Публикация исходного кода программы на языке Фортран в 1980 году позволила учёным в различных лабораториях оценить работу этого синтезатора, а также помогла в проведении перцептивных экспериментов.
Первая модель формантного синтезатора русской речи «Фонемофон-1» (рис. 1.10) была разработана в Минске в начале 70-х годов, и успех в её создании был связан, прежде всего, с разработкой принципов формантного синтеза речевых сигналов.
В последующих версиях удалось добиться синтеза русской речи по произвольному тексту весьма высокого качества [4].
В это же самое время начались исследования в области синтеза речи на кафедре фонетики филологического факультета ЛГУ.
В конце 80-х годов на основе накопленного опыта стало возможным развитие проекта системы автоматического синтеза речи по произвольному русскому тексту.
В 1989 году был изготовлен первый образец компилятивного синтеза.
Рис. 1.10. Внешний вид синтезатора «Фонемофон-1» 
1.3.3. Синтезаторы, использующие линейное предсказание 
Метод линейного предсказания позволяет напрямую использовать при синтезе искусственной речи параметры передаточной функции голосового тракта и является своеобразной альтернативой формантному синтезу.
Первые эксперименты с кодированием речи при помощи коэффициентов линейного предсказания (КЛП) были проведены в середине 60-х годов.
Эта технология впервые была использована в недорогих устройствах типа TI Speak’n’Spell (1980).
Для синтеза речевого сигнала в КЛП-синтезаторе используются следующие изменяющиеся во времени параметры: период основного тона, средняя громкость звука, признак тон-шум и определённое заранее количество коэффициентов линейного предсказания.
При этом качество синтезированной речи зависит от числа коэффициентов, точности их вычисления, а так же от того, насколько хорошо моделируются источники возбуждения.
Обычно для работы КЛП-синтезатора из оцифрованной речи человека вычисляются необходимые параметры, а далее все необходимые единицы синтеза (слова или более короткие единицы) записываются в параметризованном виде в память и затем при синтезе извлекаются и соединяются, или конкатенируются, в определённом порядке.
Таким образом, модель линейного предсказания косвенно поспособствовала развитию технологии конкатенативного синтеза.
Синтезаторы первого поколения обычно требовали детального описания того, что должно быть произнесено, и не включали какого-либо автоматического способа получения подобного описания для произвольного сообщения или текста.
1.4. ХХ век: синтезаторы второго поколения 
В середине 60-х годов, в связи с продолжающимся развитием компьютерной техники и возросшими потребностями общества, перед разработчиками автоматического синтеза речи была поставлена более широкая задача озвучивания любого сообщения, вводимого в компьютер в текстовом виде и неизвестного заранее системе синтеза.
Это привело к развитию синтезаторов типа TTS.
В идеале такие устройства должны имитировать деятельность человека, который читает письменное сообщение или текст любой степени сложности.
Поэтому в синтезаторах такого типа (то есть синтезаторах речи в современном понимании этого термина) появился блок лингвистической обработки, независимый от акустического блока и метода генерации речевого сигнала, тогда как самые ранние синтезаторы и синтезаторы первого поколения были ориентированы в основном или полностью на модельную разработку акустического блока, то есть на задачу генерации речевого сигнала.
Первая полноценная система TTS для английского языка была создана в 1968 году в Японии Норико Умеда и его коллегами.
Она была основана на артикуляционной модели акустического блока.
Анализ текста и расстановка пауз производились при помощи сложных правил.
По свидетельству специалистов, речь, производимая этой системой, была разборчивой, но довольно монотонной.
В дальнейшем алгоритмы лингвистической предобработки текста усложнялись благодаря увеличению скорости компьютерного анализа данных и объёма памяти для хранения вспомогательной лингвистической информации (различных словарей, речевых баз, моделей и т. п.).
Это позволял о более точно представлять необходимые для акустического синтеза детальные фонетические описания: фонетическую транскрипцию и просодические характеристики сегментных единиц, получаемые на основе интонационных моделей (длительность, частоту основного тона и громкость).
Следует подчеркнуть, что эти фонетические описания должны быть преобразованы в процессе синтеза во входные данные (акустические характеристики), необходимые блоку генерации речевого сигнала (например, частоты формант), что может быть сделано двумя способами: либо с помощью особых правил, либо посредством измерения (или «копирования») этих характеристик для отдельных звуков или целых фраз естественной человеческой речи.
Копирование характеристик является наиболее простым и эффективным методом получения качественной (то есть разборчивой и естественной) синтезированной речи.
Так называемый ресинтез (подача на вход синтезатора акустических характеристик естественной речи), является также надежным способом понять, насколько хорошо работает его акустический компонент.
1.5. ХХ век: синтезаторы третьего поколения 
К третьему поколению технологий автоматического синтеза речи обычно относят синтез на основе скрытых Марковских моделей (HMM – hidden Markov models) и селективный синтез речи [2].
В англоязычных источниках метод называют unit selection.
Их общей чертой является использование для автоматического синтеза речи больших объёмов речевых данных, а также высокая естественность синтезированной речи.
1.5.1. Селективный синтез речи 
Метод Unit Selection является в настоящее время основной технологией автоматического синтеза речи, так как он позволяет получать синтезированную речь, которая по своим характеристикам наиболее приближена к естественной [2].
Метод является разновидностью конкатенативного синтеза речи, то есть в процессе синтез а речевого сигнала используются заранее сделанные звукозаписи естественной речи.
В отличие от более ранних аллофонных или дифонных синтезаторов речи, порождающих итоговый речевой сигнал из отдельных и специально подготовленных звуковых единиц, выделенных из небольшого и тщательно подобранного набора слов, при селективном синтезе для каждой базовой единицы синтеза производится выбор наиболее подходящего кандидата из множества вариантов, взятых из озвученных предложений естественного языка.
Для этого записываются специальные звуковые базы, размер которых может составлять до нескольких десятков часов звучащей речи.
В процессе акустического синтеза алгоритм строит 1 Аллофон — реализация фонемы, один из ее вариантов, обусловленный конкретным фонетическим окружением.
В отличие от фонемы, является не абстрактным понятием, а конкретным речевым звуком.
2 Дифон — сегмент речи между серединами соседних аллофонов.
оптимальную последовательность звуковых единиц, учитывая одновременно и то, насколько кандидат подходит под описание необходимых характеристик звука (стоимость замены), и то, насколько хорошо выбранные элементы будут конкатенироваться с соседними (стоимость связи).
При этом с учетом указанных стоимостей из базы в качестве оптимальных могут быть выбраны не отдельные звуки, а их цепочки или даже целые предложения.
Такой подход позволяет минимизировать модификации речевого сигнала, что повышает естественность синтезируемой речи.
Первыми системами селективного синтеза стали n-Talk (1992) и CHATR (1994), а в 1996 году известные специалисты по синтезу речи А. Хант и А. Блэк предложили алгоритм выбора оптимальной последовательности единиц для конкатенации, который стал классическим [5].
1.5.2. Статистический параметрический синтез 
Статистический параметрический синтез является методом, основанным не на правилах, а на имеющихся акустических данных.
При этом подходе делается попытка машинного обучения системы на имеющихся речевых данных с целью получения модели соответствия характеристик речи, поступающих на вход акустического блока, физическим параметрам звуковых единиц.
Получаемая модель даёт два преимущества: уменьшение памяти для хранения модели вместо самой речевой базы и возможность её параметрической модификации, например, быстрого изменения тембра голоса [2].
Наиболее распространённой техникой в данном направлении синтеза является метод, основанный на использовании скрытых Марковских моделей.
Скрытые Марковские модели звуковых единиц применялись в системах распознавания речи с конца 70-х годов.
Работу над автоматическими системами синтеза речи, основанными на HMM, начали в 1995 году японские учёные К. Токуда с коллегами [6].
Возможность использования статистического подхода в применении к синтезу речи обусловлена возросшим быстродействием вычислительных машин и объёмов носителей информации для хранения больших речевых баз, необходимых для обучения акустических моделей.
1.6. Перспективные направления синтеза 
Основными направлениями современных исследований в области автоматического синтеза речи являются аудиовизуальный синтез, синтез экспрессивной и эмоциональной речи, а также объединение двух подходов к синтезу речи третьего поколения: селективного синтеза и синтеза на основе скрытых Марковских моделей [2].
2. ОБЗОР ТЕХНОЛОГИЙ TTS 
2.1. Типы синтезаторов 
Речевые синтезаторы принято делить на два типа: с ограниченной и неограниченной словарной базой.
В синтезаторах с ограниченным словарем речь хранится в виде отдельных слов или предложений, которые выводятся в определенной последовательности в процессе синтеза речевого сообщения.
Речевая база в системах такого типа произносится диктором заранее, а затем преобразуется в цифровую форму с использованием различных методов кодирования, для уменьшения необходимого объема для ее хранения на носителе.
В синтезаторах с неограниченным словарем элементами речи являются фонемы или слоги, поэтому в них применяется метод синтеза по фонетическим правилам, а не простая компоновка.
Данный метод весьма перспективен, т.к. обеспечивает работу с любым необходимым словарем, однако качество речи значительно ниже, чем при использовании метода компоновки.
На сегодняшний день в сфере синтеза речи можно выделить три основные группы методов: параметрический синтез; компилятивный синтез; синтез речи по фонетическим правилам.
Каждый из подходов характеризуется наличием ряда достоинств и недостатков.
2.1.1. Параметрический синтез 
Параметрический синтез речи является итоговой операцией в вокодерных системах, где речевой сигнал представлен набором непрерывно изменяющихся во времени параметров.
Данный метод речевого синтеза целесообразно использовать в случаях, когда набор текстовых сообщений ограничен и редко подвержен изменению.
К достоинствам данного метода относится возможность записать речь для любого языка и любого диктора.
В зависимости от степени сжатия информации в параметрическом представлении качество синтезируемой речи может достигать очень высокого уровня.
Недостатком такого подхода является невозможность применять параметрический синтез для заранее не заданных сообщений.
2.1.2. Компилятивный синтез
Компилятивный синтез сводится к составлению сообщения из предварительно записанного словаря исходных элементов синтеза.
Очевидно, что содержание синтезируемых сообщений фиксируется объёмом словаря.
Как правило, число единиц словаря не превышает нескольких сотен слов.
Основная проблема в компилятивном синтезе — объёмы памяти для хранения словарной базы.
Для решения этой проблемы используются разнообразные методы сжатия/кодирования речевого сигнала.
Компилятивный синтез имеет широкое практическое применение.
За рубежом разнообразные устройства (от военных самолётов до бытовых устройств) оснащаются системами речевого ответа.
Примером компилятивного синтеза речи являются объявления в транспорте: фразы «Осторожно, двери закрываются», «Следующая остановка:», «Остановка…» и названия остановок записаны диктором заранее и лишь соединяются вместе для оповещения по команде водителя или кондуктора.
2.1.3. Синтез речи по фонетическим правилам
В зависимости от размера исходных элементов здесь различают следующие виды синтеза: микросегментный; аллофонный; дифонный; полуслоговый; слоговый; синтез из различных единиц произвольного размера.
Часто в качестве таких элементов используются полуслоги — сегменты, содержащие половину согласного и половину примыкающего к нему гласного.
При этом появляется возможность синтезировать речь по заранее не заданному тексту, но возникают проблемы управления интонационными характеристиками.
Качество такого синтеза не совсем соответствует качеству естественной речи, поскольку на границах «сшивки» дифонов часто возникают искажения.
Однако и компиляция речи из заранее записанных словоформ также не решает проблемы высококачественного синтеза произвольных сообщений, поскольку акустические и просодические (длительность и интонация) характеристики слов изменяются в зависимости от типа фразы и места слова во фразе.
Это положение не меняется даже при использовании больших объемов памяти для хранения словоформ.
2.2. Оценка качества синтеза речи 
При разработке систем автоматического синтеза речи очень важным является вопрос оценки качества синтеза речи.
В процессе оценки качества учитываются следующие основные характеристики: разборчивость речи; естественность (натуральность) речи; мультимодальность речи; многоязычие.
Рассмотрим указанные характеристики более подробно.
Основным критерием оценки качества синтеза речи является разборчивость синтезированной речи.
Очевидно, что чем выше разборчивость речи, тем более высокого класса синтезатор.
Существуют различные способы (типы) оценки разборчивости, основными из которых являются следующие: звуковая (не менее 75 %); слоговая (не менее 85 %); словесная (не менее 99 %); фразовая (98 – 99 %); смысловая.
Обычно разборчивость измеряется (оценивается) следующим образом.
Речевая система синтезирует различные неожиданные для слушателя фразы.
Указанные фразы фиксирует группа слушателей, каждый из которых пытается разобрать (распознать), что сказала машина.
Например, предоставляется возможность прослушать 100 фраз, и слушатели поняли 98 – 99 % – это очень хорошая фразовая разборчивость.
При оценке словесной разборчивости слушателям предлагаются отдельные слова, самые разные, но осмысленные, никак между собой не связанные, из разных областей.
Слушатели записывают слова, которые они поняли (расслышали).
Затем подсчитывается количество понятых слов и рассчитывается процент относительно общего количества предложенных слов.
При словесной разборчивости хорошим считается результат не менее 99 %.
В случае оценки слоговой разборчивости произносятся бессмысленные слоги (например, «псу», «ваз», «дус», «гры» и т.д.).
При этом используются специальные таблицы частотной встречаемости слогов, с учетом которых формируются тестовые последовательности, которые подаются на в ход речевой системы.
Слушателям опять-таки следует записать все понятые ими слоги.
Затем подсчитывается, сколько слогов услышано правильно: если примерно 85 % и выше, то разборчивость считается достаточной.
Звуковая разборчивость оценивается по тем же бессмысленным слогам, но считается не число неправильных восприятий (если хотя бы один звук в слоге был воспринят неправильно, то слог уже неправильный), а считается число звуков, т.е. фонем, воспринятых неправильно.
Поскольку слоги состоят из различных звуков, то считается, что 75 % правильно воспринятых звуков – это уже неплохо.
При оценке разборчивости используются также градации, т.е. более градуированные оценки – какая разборчивость считается отличной, хорошей, удовлетворительной, неудовлетворительной.
Следующей характеристикой, используемой для оценки качества синтезатора речи, является естественность (натуральность) речи.
Это субъективная характеристика, которая оценивается слушателями на основании их личного восприятия речи.
Натуральность синтезированной речи зависит от многих факторов, например, могут быть натуральные звуки, но ритмическая сторона речи может быть сильно испорчена.
Иначе говоря, слушатель может слышать понятную и разборчивую речь, произносимую вполне естественным голосом, но интонация при этом какая-то неестественная, «роботная».
Это может также проявляться в том, что машина путает или “съедает” ударения.
Натуральность речи можно оценить, но нет объективных критериев – это только субъективное впечатление слушателя.
Ведь даже разные люди имеют разное произношение, которое иногда может даже показаться неестественным.
При реализации речевых синтезаторов интонация и ритмика речи определяются исходя из анализа входного предложения.
Расстановка ударений в словах осуществляется в соответствии со словарём и с учётом синтаксических правил.
Под мультимодальностью речи понимают отражение эмоционального состояния говорящего, индивидуальность его голоса, стиль речи, акцент и т.п. В системах автоматического синтеза речи эта характеристика выражается в возможности синтеза различных типов голосов и их индивидуальных особенностей.
Эта возможность относится к экстралингвистическим способностям системы, так как не связана с языковыми и собственно речевыми особенностями реализации.
К мультимодальности речи, в частности, относят поддержку мужских и женских голосов, различные голосовые модуляции (бас, баритон).
Сюда же относится возможность синтеза некоторых эмоциональных компонент, содержащихся в речи, таких, как волнение, гнев, ласка и т.п. Не всегда хорошо, когд а синтезатор «говорит» безразлично и монотонно; во многих случаях полезно, когда он «говорит», моделируя эмоции человека.
В отличие от мультимодальности, многоязычие относится к лингвистическим способностям и подразумевает возможность синтеза речи на нескольких естественных языках.
Например, на русском, английском и т.д.
2.3. Структура TTS
Система синтеза речи обычно состоит из четырех основных частей, будем называть их процессорами.
Лингвистический текстовый процессор.
Он предназначен для решения следующих задач.
Выделение предложений в тексте и разбиение их на отдельные слова; разметка текста на буквы, специальные символы, цифры и знаки пунктуации.
Данный шаг необходим для успешности дальнейшей обработки текста.
Учёт разметки текста, проставленной пользователем (пользовательские теги, пользовательский знак ударения).
Пользовательская разметка имеет приоритет над обработкой текста по умолчанию.
Нормализация текста.
Текст, подаваемый на синтез, часто содержит большое количество обозначений, которые не могут быть прочитаны (т. е. транскрибированы) в исходном виде.
Требуется их расшифровка.
Эта процедура называется нормализацией текста.
Определение места ударения и морфо-грамматических характеристик слов в предложении.
Для определения места ударения в слове система синтеза речи по тексту использует морфограмматический словарь.
Снятие омонимии (омографии).
Снятие омонимии (омографии) представляет из себя выбор одной из нескольких словоформ, соответствующих тому или иному слову текста.
Эти словоформы могут отличаться ударением (замок или замок), наличием буквы ё (все или всё), грамматическими характеристиками (стали- глагол или существительное).
Выбор словоформы производится с помощью анализа контекста: лексического окружения слова, а также его грамматической позиции в предложении.
Просодический процессор.
Просодическая обработка текста заключается в придании тексту интонационного оформления.
Сюда относится деление текста на просодические единицы – синтагмы, определение длины пауз между синтагмами и выбор интонационного контура для каждой из синтагм.
Синтагма – основная единица реализации интонации.
Характеризуется интонационной и смысловой целостностью, единым мелодическим и динамическим контуром, акцентно-ритмической структурой.
Границы синтагмы могут маркироваться паузами; внутри синтагмы паузы недопустимы.
В составе синтагмы выделяется главное слово, получающее т. н. синтагматическое ударение, в то время как остальные словесные ударения могут существенно ослабляться – определяет степень централизации синтагмы (очень высокая для русского языка).
Деление предложения на синтагмы осуществляется в первую очередь с опорой на знаки препинания.
В большинстве случаев наличие знаков препинания является надежным сигналом о наличии паузы.
В то же время некоторые отдельные случаи, такие как вводные слова (возможно, к сожалению, и т.п.), обрабатываются по особым правилам, поскольку выделение их запятыми не обязательно обозначает возможность паузы при чтении.
Длинный отрезок предложения, не разделенный знаками препинания, делится на синтагмы по особому алгоритму, включающему в себя анализ синтаксических связей между словами.
Деление на синтагмы сопровождается также выбором места фразового ударения, то есть основного ударения в синтагме.
В большинстве случаев в русском языке фразовое ударение падает на последний ударный слог синтагмы, например, студент читает книгу.
Однако в некоторых случаях фразовое ударение может переноситься на другой слог, например, когда последним словом в синтагме является местоимение: «Вы можете прочесть ее».
Для каждой синтагмы, выделенной в процессе анализа текста, выбирается наиболее подходящий интонационный контур (ИК).
Набор интонационных контуров, используемый в системе синтеза речи, основан на стандартной классификации Е.А.Брызгуновой [1] и включает в себя такие интонационные типы, как повествовательное предложение, общий вопрос, частный вопрос, восклицание и т.п. Выбор ИК осуществляется на основе знаков препинания (вопросительный знак, восклицательный знак, запятая, тире и т.п.), а также лексического содержания предложения (например, наличия вопросительных слов).
Фонетический процессор.
Задачей фонетического процессора является: построение транскрипции по правилам и учет исключений транскрипции; вычисление физических параметров интонации для синтагм синтезируемого текста.
Акустический процессор.
Основная часть акустической обработки – оптимальный выбор звуковых элементов из базы диктора, осуществляющийся по методу Unit Selection.
Далее может быть произведена модификация звуковых элементов по частоте основного тона, длительности и тембру, а также добавлены звуковые эффекты (например, с помощью инструментов ревербератора и эквалайзера).
Структурно, схему взаимодействия процессоров можно представить следующим образом (рис.2.1).
В качестве формата передачи данных между процессорами в данной схеме предполагается XML-формат данных.
XML — текстовый формат, предназначенный для хранения структурированных данных (взамен существующих файлов баз данных), для обмена информацией между программами, а также для создания на его основе более специализированных языков разметки (например, XHTML), иногда называемых словарями.
XML — это иерархическая структура, предназначенная для хранения любых данных, визуально структура может быть представлена как дерево.
Важнейшее обязательное синтаксическое требование — то, что документ имеет только один корневой элемент.
3. ЛИНГВИСТИЧЕСКИЙ ТЕКСТОВЫЙ ПРОЦЕССОР 
3.1. Задачи лингвистического процессора 
Лингвистический текстовый процессор производит предварительную обработку текста, необходимую для построения его транскрипции и дальнейшей генерации звучащей речи.
Так, в потоке текста должны быть выделены элементы, с которым система синтеза речи должна будет работать в дальнейшем: абзацы, предложения, слова, буквы и другие символы.
При этом должна быть учтена пользовательская разметка текста (при ее наличии), выполненная, например, с помощью специализированных тегов SSML (Speech Synthesis Markup Language).
Кроме того, орфографический текст, который должна обработать система синтеза речи, сам по себе содержит недостаточно информации для создания правильной транскрипции (условной записи, по которой непосредственно будет формироваться звучание текста).
Не все слова орфографического текста могут быть «прочитаны» синтезатором в том виде, в котором они представлены изначально.
В естественных текстах часто встречаются следующие виды нестандартных записей: цифры; включения других алфавитов (для русского языка – в первую очередь, латиница); специальные знаки, не являющиеся ни буквами, ни цифрами; сокращения и аббревиатуры (акронимы); и др. Все эти записи должны быть превращены в «обычные», стандартные слова языка, на котором производится синтез, или в подобные им записи (например, транслитерацию иного алфавита).
Далее производится подготовка слов текста к транскрибированию.
Для русского языка транскрипция в общем случае достаточно регулярна и осуществляется по заданным правилам на отдельном этапе анализа текста, однако на этапе лингвистического анализа могут быть определены места ударных гласных, а также наличие буквы ё, которая обычно передается на письме как е. Для языков с нерегулярной орфографией, таких как английский, список транскрипций слов может быть задан в списке (словаре).
Однако и в том и в другом случае основной проблемой являются слова, не найденные в словаре, а также случаи, когда одному написанию соответствуют два или более разных слов (омонимы, например, «замОк-зАмок»).
Слова, различающиеся звучанием, но пишущиеся одинаково (замОк- зАмок), называются омографами; слова, пишущиеся и звучащие одинаково, но имеющие разное значение и/или разные грамматические характеристики, называются омонимами (например, печь – существительное и печь – глагол).
Для синтеза речи наиболее важно снятие омографии, однако и различение омонимов может быть важным для грамматического анализа текста.
Часто омонимы и омографы объединяют под общим наименованием омонимов.
Рис. 2.1. Схема синтезатора речи 
Для выбора между омонимичными словоформами (снятие омонимии) применяется как анализ лексического контекста, так и анализ грамматической структуры предложения.
Для определения грамматических характеристик слов может использоваться морфограмматический словарь либо статистические методы определения части речи и других грамматических категорий слова (Part-of-speech tagging).
Общая схема работы процессора представлена на рис. 3.1.
Итак, в задачи лингвистического процессора входит: первичная обработка текстовых данных и представление их в едином формате для последующей обработки; выделение предложений в тексте и разбиение их на отдельные слова; разметка текста на буквы, специальные символы, цифры и знаки пунктуации; учет разметки текста, проставленной пользователем; расшифровка сокращений, аббревиатур, числительных и других нестандартных записей, поиск и исправление орфографических ошибок и опечаток;  определение места ударения и морфо-грамматических характеристик слов в предложении; снятие омонимии (омографии).
Нормализация текста и графематический анализ Обработка аббревиатур и иноязычных вставок Морфо-грамматический словарь Исправление ошибок
3.2. Нормализация текста (графематический анализ) 
Задачи, входящие в нормализацию текста: выделять предложения в тексте; разбивать предложения на слова; разбивать текст на буквы, цифры, знаки пунктуации, специальные символы; учитывать информацию, проставленную пользователем (место ударения, наличие паузы и др.); расшифровывать специальные символы (%, *, №...), сокращения («т.е.», «км/ч» и т.п.) и др.; выделять специальные форматы записей (дата, время, интернет- адрес...).
Рассмотрим эти задачи более подробно.
3.2.1. Выделение предложений, слов, символов, знаков препинания 
Для правильного синтеза речи необходимым подготовительным этапом является деление текста на отрезки, которые будут впоследствии основными единицами синтеза.
Это, прежде всего, слова и предложения.
В самом первом приближении словами можно считать отрезки текста между пробелами, а предложениями – отрезки текста между точками и другими конечными знаками препинания.
Однако для анализа реальных текстов такого подхода недостаточно.
Рассмотрим примеры текста, поступающего на вход программы синтеза речи: Порядка 22% от объема полученных в 2011 году средств – 172 тыс. долларов – были переданы 39 благотворительным организациям.
Write a cheque from acc 3949293 (code 84-15-56), for $114.34, sign it and take it down to 1134 St Andrews Dr, or else!!!! (пример взят из [21]).
Анализируя эти примеры, можно сделать следующие наблюдения:- Знаки препинания, как правило, не отделены пробелами от слов и должны быть проанализированы специальным образом.
Далее знаки препинания могут быть сохранены как отдельные символы либо сохраняться в виде флагов соответствующего слова.
Следует учесть, что после слова может следовать несколько знаков препинания.
Корректная информация о знаках препинания крайне важна для синтеза речи, т.к. свидетельствует о смысловом и интонационном делении текста.
- Некоторые другие выражения, объединенные в одно графическое слово, также должны быть отделены друг от друга для индивидуальной обработки (например, сочетания цифра+процент – «22%»).
- Точки не всегда сигнализируют конец предложения; в русском языке точка часто является элементом сокращения – например, «тыс.».
Необходим анализ элемента, который оканчивается точкой (сокращение это или нет) и анализ дальнейшего контекста (следует ли далее слово с большой буквы).
Даже при учете этих факторов могут возникнуть сложные случаи, которые сложно решить без семантического анализа предложения (ср.: В 1868 г. Лев Толстой з акончил «Войну и мир»).
Точка также может быть элементом интернет-ссылки или адреса электронной почты (mail.ru), инициалов (А. С. Пушкин), а также дроби (1.5), даты (19.11.2012) и т.п.- Изредка встречаются случаи, когда порядок следования элементов в тексте должен быть изменен для правильного синтеза (ср.: $114.34).
3.2.2. Обработка пользовательской разметки 
В большинстве коммерческих приложений для синтеза речи пользователь может влиять на результат синтеза с помощью специальной разметки.
Общепринятым форматом пользовательской разметки для синтеза речи является, как уже отмечалось ранее, SSML, основанный на XML.
Язык SSML был создан рабочей группой консорциума по голосовым браузерам и позволяет программно контролировать самые разные параметры процесса синтеза речи.
SSML основан на языке разметки Java Synthesis Markup Language (JSML), разработанном Sun Microsystems.
Он охватывает практически все аспекты синтеза речи, хотя в некоторых областях остались неопределенные аспекты, поэтому каждый производитель принимает иной вариант языка.
Кроме того, в отсутствие разметки, синтезатор, как ожидается, должен выполнить свое собственное толкование этого текста.
Так SSML не является таким жестким в плане синтаксиса, как язык C, или даже HTML.
С помощью тегов SSML могут быть определены такие параметры синтеза речи, как выбор языка, голоса, темпа, тембра, мест пауз, произношения слова и т.п. Анализ данных тегов производится на этапе разбора текста.
3.2.3. Расшифровка нестандартных записей 
Можно выделить следующие типы нестандартных записей в тексте: 
1) Сокращения.
- Сокращения – элементы, которые должны быть заменены на полное слово или словосочетание.
- Сокращение может быть из одного слова (км, стр.) или из нескольких (т.е., к. ф. н., до Р.Х.).
- Сокращение может использоваться без точки (Гб, мск) либо содержать точку (одну или после нескольких частей, см. примеры выше), слеш (км/ч, в/ч, ж/д), дефис (кто-л.).
При расшифровке сокращения эти знаки должны быть исключены из дальнейшей обработки предложения.
При расшифровке сокращений перед разработчиком системы синтеза речи встают следующие трудности.
Во-первых, сокращения зачастую неоднозначны: например, английское «m» может обозначать “million” (миллион) или “metre” (метр), русское «г.»- «город» или «год».
Во-вторых, в языках с богатой морфологией, таких как русский, приходится производить выбор правильной падежной формы слова (например, 1 км=километр, 2 км=километра, 5 км=километров, к 5 км=километрам и т.п.).
2) Специальные знаки – знаки, не являющиеся ни буквами, ни цифрами, но нуждающиеся в словесной расшифровке ($, *, #, % и т.п.).
Во многом такие знаки ведут себя подобно сокращениям и тоже нуждаются в выборе правильной формы в зависимости от контекста (например, 1%, 2%, 5%...).
3) Цифровые записи – это цифры, встречающиеся в естественных текстах, которые должны быть преобразованы в соответствующие слова (числительные).
- Цифры бывают арабские и римские.
Римские цифры могут быть преобразованы в арабские в соответствии с заданным алгоритмом.
- В текстах могут встретиться стандартные последовательности цифр или слов и цифр, требующие чтения по определенному формату.
Самые распространенные из таких форматов: дата, время, номер телефона, индекс.
Они должны быть выявлены в процессе нормализации текста и «прочитаны» по заданным правилам (например, в дате типа 19.11.2012 цифра 11 заменяется названием месяца – «ноября», добавляется слово «года» и т.п.).
- Цифры, не подпадающие под заданные форматы, могут обозначать количество обозначаемых предметов (количественные числительные, например, «десять») или номер следования предмета (порядковые числительные, например, «десятый»).
При расшифровке числительных производится выбор между этими разрядами (например, «10 человек» или «10 этаж»).
При расшифровке числительного, записанного в виде цифры с аффиксом (например, «10-ый», «20-ти», в английском: 2nd, 10th), аффикс должен быть отброшен, а числительному придана соответствующая форма.
- В русском языке расшифровка цифровых записей также сопряжена с выбором правильной формы (падежа и, для некоторых числительных, рода, например, «2 кота», «2 кошки», «2 кошкам» и т.п.).
4) Для русского языка: латиница.
Хотя система синтеза русской речи прежде всего ориентирована на озвучивание текста, написанного кириллицей, однако в реальных текстах часто встречаются элементы, написанные латинским алфавитом.
Это могут быть иностранные имена или названия зарубежных фирм и товаров, адреса интернет-сайтов и электронной почты и т.п. Такие элементы должны быть транслитерированы (транслитерация – передача слова, написанного иноязычным алфавитом, с помощью русских букв).
Правила транслитерации задаются с учетом того, слова какого языка чаще всего могут встретиться в синтезируемых текстах (чаще всего – английского).
5) Аббревиатуры и инициалы.
Аббревиатуры (акронимы) – слова, образованные путем сложения начальных букв или слогов исходного словосочетания, которые читаются по буквам либо как единое слово (например, АТС, ООО, ВАЗ) (в отличие от сокращений, которые при чтении расшифровываются до исходного слова или словосочетания, например, км – километр, и т.п. – и тому подобное).
Выбор способа чтения аббревиатуры задается по правилам, следует также определить, куда будет падать ударение в полученном слове.
Инициалы тоже должны быть прочитаны как отдельные буквы (при этом точки, на которые заканчиваются инициалы, удаляются из дальнейшей обработки предложения).
3.3. Использование словарей в синтезе речи 
Машиночитаемые электронные словари могут выполнять различную роль в системе синтеза речи.
Так, в английском языке, имеющем бедную морфологию, но крайне нерегулярную орфографию, словарь, как правило, содержит список словоформ с соответствующими им транскрипциями (в словаре может также содержаться информация о части речи слова, однако, поскольку большинство английских словоформ может относиться к различным частям речи, то определение частей речи обычно выделяется в отдельный модуль программы).
Ниже приводится фрагмент популярного словаря английского языка CMUDICT; каждая строка содержит в левой части словоформу, в правой части – ее транскрипцию в принятой в словаре нотации: SPEECH S P IY1 CH SPEECHES S P IY1 CH AH0 Z SPEECHIFY S P IY1 CH AH0 F AY2 SPEECHIFYING S P IY1 CH AH0 F AY2 IH0 NG SPEECHLESS S P IY1 CH L AH0 S Для русского языка не является целесообразным хранить в словаре всю информацию о транскрипции каждой формы, поскольку, во-первых, транскрипция с достаточной степенью достоверности выводится из орфографического облика слова, во-вторых, количество отдельных словоформ на то же количество лексем в русском языке значительно больше благодаря развитой морфологии (так, у английского глагола в общем случае четыре формы, а у русского их несколько десятков, если учитывать причастия).
В морфограмматическом словаре русского языка (например, словарь группы AOT www.aot.ru) слова хранятся в форме основ и соответствующих им словоизменительных парадигм (то есть целиком каждая форма не хранится).
При этом для каждой словоформы доступна следующая информация: место ударения в данной словоформе; наличие буквы ё (ё должно определяться, даже если слово написано через е); грамматические характеристики словоформы (например, род, число и падеж для существительного, лицо, число и время для глагола и т.п.); некоторые сведения о семантике (например, является ли слово фамилией, географическим названием и т.п.).
Ниже приводится фрагмент машиночитаемого словаря русского языка.
Каждая строка словаря содержит основу и цифровой или буквенный код, являющийся ссылкой на определенную словоизменительную и акцентную парадигму, то есть на набор окончаний, прибавляемых к данной основе, и место ударения для каждой полученной словоформы (сами парадигмы хранятся в отдельной части словаря).
синтез 67 29 Фа синтезатор 67 29 Фа синтезаторн 106 121 синтезир 100 108 Уп 
При обработке текста в системе синтеза речи на вход модуля словаря поступает нормализованный текст. Каждое слово этого текста ищется в словаре, при нахождении ей присваиваются соответствующие характеристики (номер ударного гласного, замена е на ё, грамматические категории и т.п.) Если в словаре данная словоформа встречается более одного раза (например, дом – им.пад.
ед.ч. и вин.пад. ед.ч.; берег – сущ., произносится с е и берёг – глагол, произносится с ё), учитываются все словарные вхождения.
3.4. Обработка незнакомых слов 
Каким бы объемным ни был словарь, использующийся в системе синтеза речи, тем не менее в текстах, как правило, будут встречаться слова, которые не будут находиться в словаре.
Однако для таких слов также необходимо определить место ударения, построить транскрипцию и – в идеале – определить грамматические характеристики.
Для обработки незнакомых слов в системе синтеза речи могут использоваться следующие методы: 1) Морфологический анализ и правила.
Зачастую слова, не найденные в словаре, могут быть правильно интерпретированы с помощью морфологического анализа (анализ слова на составляющие его элементы – основу и аффиксы), который позволяет связать незнакомое слово с уже известным словом, содержащимся в словаре.
Так, например, если в словаре нет слова супервыставка, мы можем выделить в нем префикс супер- и основу выставка, которая в словаре есть.
Если морфологический анализ не позволяет разложить слово на знакомые элементы, то место ударения или транскрипция может быть выведено с помощью правил (например, поиска внутри слова элементов, сигнализирующих о месте ударения, и т.п.).
2) Статистические методы.
При наличии достаточно большого словаря транскрипций можно обучить статистическую модель, выводящую транскрипцию слова или место ударения автоматически.
Этот способ удобен тем, что не требует участия эксперта для формирования правил, однако может давать сбой на словах, имеющих редкий для обрабатываемого языка орфографический облик (например, иностранные имена и названия, часто встречающиеся среди незнакомых слов).
Незнакомые слова, попадающиеся в текстах, могут быть не только обозначениями каких-то новых предметов и понятий, но и словарными словами, написанными с ошибкой или опечаткой (например, *интелект вместо «интеллект», *карова вместо «корова»).
Ошибки в подающихся на синтез словах могут быть исправлены как с помощью списков частотных ошибок и опечаток (либо просто добавления распространенных ошибочных вариантов, типа *исскуство вместо «искусство», в общий словарь), так и с помощью правил, проверяющих наличие распространенных ошибок (например, для русского языка – написание двойных согласных, безударных гласных и т.п.).
3.5. Снятие омонимии (омографии) 
Снятие омонимии – одна из наиболее важных и сложных задач для автоматического синтеза речи.
Словоформы, имеющие одинаковое написание, но разное прочтение, встречаются во многих языках.
Однако для русского языка эта проблема особенно важна, поскольку количество омонимов очень велико.
Омонимы в русском языке могут различаться ударением (например, стоит-стоит), а также наличием буквы ё, которая в современной орфографии чаще всего передается как е (все-всё), либо и тем и другим (берег-берёг).
Омонимичные словоформы могут иметь одинаковые грамматические признаки (например, замок-замок, замка-замка…), либо различаться грамматическими характеристиками.
В последнем случае омонимичными могут быть как различные словоформы внутри одной парадигмы (например, род.п. ед.ч. – им.п. мн.ч.: облак а-облака, стран ы-страны…), так и формы разных парадигм (например, существительное-инфинитив: вест и-вести, пропасть-пропасть …).
С формальной точки зрения, мы считаем, что слово в тексте представляет собой омоним, если одному слову соответствует несколько словарных вхождений (словоформ), в том числе, когда варианты произношения этого слова различаются ударением или/и наличием буквы ё. В задачи модуля снятия омонимии входит выбор правильного вхождения для данного контекста.
Разрешение омонимии, как и расшифровка специальных обозначений, производится при помощи анализа контекста [10,11].
На уровне индивидуальных слов-омонимов производится поиск в предложении ключевых слов или выражений.
Этот этап включает анализ слов непосредственно рядом с текущим, как, например, в случае устойчивых выражений: скрыто за семью замками, в четырех стенах.
Также анализируется состав предложения целиком, например, дверь была заперта на необычный замок (ключевое слово заперта).
На уровне классов словоформ производится анализ грамматического окружения, то есть поиск согласованных слов в предложении.
Для формализации этого принципа в [10,11] предлагается ввести грамматические правила, увеличивающие условный «вес» словоформы в зависимости от ее окружения.
Правила хранятся в формализованном виде, позволяющем быстро оценивать и корректировать работу системы.
3.6. Методы разрешения неоднозначности при анализе текста 
Выбор правильной формы слова при расшифровке сокращений, числительных и других нестандартных элементов, а также при снятии омонимии сводится к задаче разрешения неоднозначности текста (определенный элемент может быть интерпретирован тем или иным образом, и программа должна выбрать один из возможных вариантов).
Эта задача может быть решена двумя различными способами.
3.6.1. Синтаксический и морфологический анализ предложения 
Сюда может относиться как полный анализ структуры предложения (парсинг), так и анализ окружения конкретного слова, задаваемый в виде контекстных правил.
Например, выбор формы числительного может зависеть от наличия предлога слева (до 10 раз, в 10 раз), формы согласованного слова справа (1 полосатая кошка, 1 полосатый кот) и т.п. Выбор формы омонима может осуществляться разными способами.
В случае с омонимами, одинаковыми по грамматическим характеристикам, разрешение омонимии может осуществляться только с помощью анализа лексического содержания предложения (ключевые слова, устойчивые выражения и т.п.).
Если же грамматические характеристики различаются, то можно использовать и анализ грамматического окружения слова для выбора омонима, подходящего к синтаксическому контексту.
Усложняет проблему то, что омонимичные словоформы могут существенно различаться по частотности (например, уха- уха, сорока-сорока, кредит-кредит, мою-мою…).
В таком случае зачастую становится продуктивным подход, когда задаются специальные условия для нахождения низкочастотного омонимичного варианта, а в остальных случаях по умолчанию берется вариант с высокой частотностью.
3.6.2. Статистические методы 
Статистические методы, основаны на обучении вероятностной модели на основе речевых корпусов.
Такие методы, по сути, также основываются на анализе контекста рассматриваемых слов (например, НММ-модели, основанные на n-граммах, или деревья решений, использующие в качестве признаков характеристики соседних слов), однако контекст здесь учитывается автоматически, без участия эксперта.
Могут быть получены хорошие результаты при наличии достаточно большой обучающей выборки, в которой в достаточном количестве встречаются все нужные элементы (при этом обучающая база данных должна содержать их расшифровку или правильное произношение); однако проблемы появляются при недостаточности данных.
4.ПРОСОДИЧЕСКИЙ ПРОЦЕССОР 
4.1. Определение границ синтагм 
Под синтагмой понимается самостоятельная в интонационном смысле часть предложения или всё предложение.
Установка границ синтагм влияет на передачу интонационных характеристик при синтезе речи, а также на передачу смыслового содержания.
При разбиении текста на синтагмы важно не поставить границу синтагмы там, где она может нарушить смысловое восприятие речи (или передачу смыслового содержания текста).
Синтагмы в речи разделяются паузами.
Такие паузы делают речь более понятной и естественной, разрешая неоднозначные трактовки смысла предложений.
Отметим, что процесс определения синтагм должен удовлетворять решению двух основных задач: установить границы синтагм в тех местах, где они обязательно должны присутствовать, и не устанавливать границу синтагмы там, где она может нарушить смысловое восприятие речи.
Многие системы синтеза речи при определении мест пауз опираются только на знаки препинания.
Однако большие участки текста, расположенные между этими знаками, могут звучать монотонно и осложнять восприятие речи, что делает актуальной задачу определения мест пауз на подобных участках.
При синтезе русской речи дополнительно возникает другая проблема – пунктуация традиционно используется для обособления различных вводных конструкций, таких как, например, «может быть», «конечно» и т.д., которые не выделяются паузами в устной речи.
Кроме того, системы синтеза речи должны не только определять места пауз, но и их продолжительность как внутри предложений, так и между ними.
Самым простым решением данной задачи является задание различных констант, регламентирующих длительность пауз.
Но, так как длительность естественных (производимых человеком) пауз является очень вариативной величиной, необходим специальный метод, позволяющий вычислять длительность пауз в зависимости от типа контекста и структуры предложения.
Принципы, описывающие расстановку пауз в естественной речи, зависят от ряда факторов.
Наиболее значимым из них является синтаксическая структура предложения: паузы зачастую располагаются между синтаксически связными компонентами.
Однако длина предложения, семантика определенных слов и другие особенности также имеют значение.
В системах синтеза речи эти факторы могут быть учтены путем задания правил, определяющих, после какого слова в предложении должна стоять пауза, или путем обучения статистических моделей на большом речевом корпусе, на основе которых будут вычисляться вероятности наличия пауз после того или иного слова.
4.1.1. Установка пауз по правилам 
Процесс определения синтагм в этом случае можно условно разбить на три основные части.
1. Расстановка пауз.
2. Расстановка фразовых ударений.
3. Особые случаи расстановки ударений 
В свою очередь, этап расстановки пауз делится на следующие, последовательно выполняемые, этапы: 
1) определение связей в каждой паре слов; 
2) грамматический анализ; 
3) установка ударений для всех слов в предложении согласно информации, поступившей от лингвистического процессора.
4) установка пауз вокруг больших групп слов.
5) удаление пауз для однородных членов и деепричастных оборотов после служебных слов.
6) установка ударений для слов, которые находятся между пауз.
7) установка пауз на основании синтаксических связей 
8) установка пауз на длинном отрезке без пауз.
Просодический процессор выделяет в каждом предложении последовательности слов, связанные синтаксической связью, которые, скорее всего, будут представлять из себя цельные просодические единицы (синтагмы).
Между парами слов устанавливаются связи того или иного типа, что позволяет определить, может ли внутри данной пары слов быть установлена пауза.
Этот этап является подготовительным перед определением местоположения и длины пауз в предложениях.
Далее проводится неполный (поверхностный) синтаксический анализ предложения.
Для правильного деления предложения на синтагмы не нужно производить полный анализ синтаксической структуры: достаточно выделить самостоятельные группы слов, между которыми в принципе возможна постановка паузы, а внутри которых пауза маловероятна.
Поиск таких групп слов осуществляется при помощи сопоставления словам синтаксических шаблонов – заранее заданных последовательностей част ей речи и/или грамматических форм, соответствующих различным часто встречающимся в текстах словосочетаниям.
При построении системы шаблонов учитываются следующие частеречные категории, грамматические характеристики слов: род, число, падеж и др., а также согласование между различными частями речи.
Дополнительные характеристики включают отдельные семантические признаки слов, а также возможность задания правила для конкретного слова.
Кроме того, отдельно анализируются особые синтаксические структуры, такие как однородные члены предложения, вводные слова, сложные предлоги и т.д. 
4.1.2. Установка пауз на основе статистических моделей 
Установка пауз по правилам работает достаточно хорошо, однако невозможно учесть все, в особенности, сложные случаи, встречающиеся в различных текстах.
Также разработка подобных правил для новых языков требует большого количества времени.
Преимуществом методов машинного обучения является простота применения, при условии наличия размеченного речевого корпуса достаточного объема.
Ожидается, что статистические модели будут более детально имитировать поведение человека, нежели правила, основанные на знаниях экспертов.
Для определения мест пауз и их длительностей в [9] предлагается использовать следующие классификаторы: CART[7] и RF[8].
Классификатор CART применяется как для определения мест пауз, так и для определения их длины: для каждой границы слов определяется длительность паузы между ними (там, где она равна нулю или меньше заданного порога, пауза отсутствует).
Также данный тип классификатора применялся только для определения длин пауз.
В этом случае предсказывается длительность только между теми словами, куда была поставлена пауза на предыдущих этапах обработки текста.
Классификатор RF применялся только для определения мест пауз в в иду его специфики.
Классификатор CART – рекурсивный метод разбиения набора данных на основе минимизации критерия (4.1) :  G(C1,C2)= (D(C1)T(C1)+D(C2)T(C2))/(T(C1)+T(C2)) (4.1) где D(C)=〖(∑_(i=1)^|C|▒∑_(j=1)^|C|▒〖d(U_i,U_j 〗))〗^2/(〖|C|〗^2-|C|),T(C)=(〖|C|〗^2-|C|)/2 
|C| – размер кластера C, d(U,V) – расстояние между векторами признаков U и V, критерием завершения служит минимальное количество элементов в кластере (в[9] рекомендуется значение три).
Классификатор RF выполняет классификацию данных на основе множества признаков путем создания иерархии («деревьев») запросов на основе предсказанных значений признаков в каждой точке.
Лист каждого из деревьев содержит информацию обо всех наблюдениях характеризуемой величины, признаки которой лежат в одной области значений.
В [9] применялся «лес решений», содержащий 100 деревьев, где каждое дерево построено на 60% случайно выбранных данных, что снижает чувствительность алгоритма к шуму в обучающих данных.
Данные параметры были выбраны на основе максимизации качества результата.
Для решения задачи классификации в [9] использовались следующие признаки: 
пунктуация: знак препинания после текущего слова, после двух предыдущих и после двух следующих слов; 
количество слов и слогов: количество слов и слогов в предложении, количество слов и слогов от предыдущей паузы до текущего слова и от текущего слова до конца предложения; 
грамматические признаки: часть речи, падеж, признак является ли слово собственным существительным (имена, названия и т.д.); 
признаки согласования: согласуется ли грамматическая форма текущего слова с двумя последующими словами; 
регистр первой буквы в слове: является ли первая буква в двух предыдущих, в текущем или двух следующих словах заглавной или нет.
Для минимизации ошибок вычисления грамматических признаков необходима процедура разрешения неоднозначности для слов-омонимов и омографов (замОк- зАмок).
Предполагается использовать подход, предложенный в работе [10], точность работы которого составляет 96%.
Сравнивая подходы на основе классификаторов CART и RF, можно отметить следующее.
Очевидным преимуществом использования CART является маленький размер модели, что является важным показателем при реализации системы синтеза речи.
Однако RF дает лучшие результаты при определении мест пауз.
Более того, не все ошибки одинаково критичны: в некоторых случаях пауза недопустима, в то время как в других имеет право быть.
CART допускает более критические ошибки по сравнению с RF, хотя это может быть выявлено только на основе экспертных оценок.
В основном ошибки CART выражаются в виде пауз внутри синтаксически связанных цепочек: после предлогов, союзов и других служебных слов, использующихся для связи последовательности слов; между модификатором (прилагательное, наречие и т.д.) и существительным или глаголом, к которому он относится.
Такого рода ошибки практически отсутствуют при использовании классификатора RF.
Кроме того, модель RF является более гибкой, т.к. она может быть настроена с целью увеличения или уменьшения количества пауз в синтезируемой речи, что может быть полезно для практических приложений системы синтеза речи.
Например, увеличение количества пауз снижает темп речи.
4.2. Определение интонационного контура 
Базовые интонационные модели, из ограниченного набора которых исходят создатели синтезаторов, реализуются на практически бесконечном множестве предложений.
Даже в языках, где тональный параметр не используется для создания лексических противопоставлений, реализация базовой модели в конкретном предложении может зависеть от таких фонетических свойств, как длина предложения, количество, место и степень выраженности словесных ударений, число слогов в использованных словах, структура слогов и даже их звуковой состав.
В результате у разных предложений наблюдаемый контур F0 (контур основной частоты голоса) может иметь весьма разнообразную и сложную форму: интонационно мотивированные изменения тона (подъемы и падения) могут чередоваться в ровными (платообразными) участками; в контуре могут присутствовать "дырки" и локальные падения, обусловленные глухостью/звонкостью согласных; контур в целом может располагаться в разных областях голосового диапазона говорящего; параметры тонального пространства, занимаемого контуром (его рабочая зона), могут меняться от начала к концу предложения, например, контур может одновременно понижаться и сужаться и т. д. Воспроизведение подобных поверхностных эффектов при синтезе речи, с одной стороны, необходимо, так как от этого сильно зависит естественность конечного результата, а с другой – представляет значительные трудности.
Это заставляет разработчиков либо создавать самим, либо искать в лингвистической фонетике какие-то интонационно-просодические модели, которые могли бы послужить основой для автоматического порождения тональных контуров.
Элементы модельных представлений содержатся даже в простейших системах, которые обеспечивают только просодический ресинтез.
4.2.1. Генерация контура F0 методом ресинтеза
В системах, основанных на просодическом ресинтезе, в памяти системы хранятся детальные количественные данные о контурах основной частоты, интенсивности и длительности для некоторого фиксированного набора фраз, полученные в результате измерения их естественны х произнесений.
Например, контур основной частоты может быть запомнен в виде последовательности чисел, представляющих результат попериодного измерения звуковой волны на вокальных отрезках фразы, или же как последовательность значений, измеренных через не большие временные интервалы (например, каждые 10мс) по контуру F0, полученному с помощью каких-либо автоматических методов акустического анализа речи.
Затем эти данные воспроизводятся без изменения при генерации синтетических отрезков, не выходящих, как правило, за пределы того набора фраз, для которых в системе имеются готовые просодические образцы.
Несмотря на очевидные ограничения, описанные системы (на Западе их называют сору- синтезаторами) находят свое применение.
В частности, они оказываются полезными при тестировании качества синтезаторов в озвучивании сегментного состава речевых отрезков, т. е. помогают оценить степень естественности синтезированной речи, состоящей из искусственных звуков и естественной просодии.
В этом случае синтезироваться может любой речевой отрезок, однако для получения просодических данных для ресинтеза он должен быть сначала произнесен человеком, т.е. стать известным синтезирующей системе.
Для понимания закономерностей просодического оформления речевых отрезков подобный ресинтез не представляет особого интереса.
Ресинтез известных просодических образцов используется также в системах, основанных на так называемых методах стилизации тонального контура – акустических или перцептивных.
Цель акустической стилизации состоит в том, что бы сократить детальную информацию, которая содержится в контурах F0 естественных фраз путем автоматического выделения некоторого набора опорных (целевых) точек, аппроксимирующих контур в целом.
Стилизация может быть широкой или узкой, в зависимости от разрешенной максимальной плотности опорных точек.
Узкая разновидность стилизации часто реализуется в виде выбора трех точек контура на отрезке каждого отдельного гласного фразы – начальной, экстремальной (или серединной) и конечной.
Опорные точки при аппроксимации контура соединяются прямыми линиями.
При широкой стилизации в качестве опорных точек часто выбираются локальные экстремумы контура (пики и впадины).
Переходы между ними интерполируются либо прямыми линиями, либо более сложными функциями.
При таком подходе в качестве особых характеристик контура могут использоваться также прямые, отражающие динамику изменения общего тонального пространства контура во времени.
Линия, соединяющая локальные максимумы кривой F0, образует верхнюю границу этого пространства (topline).
Нижняя граница (baseline) задается локальными минимумами.
Нисходящий характер обеих линий отражает общее смещение контура F0 вниз, которое часто наблюдается при произнесении повествовательных предложений во многих языках и называется деклинацией.
Перцептивная стилизация отличается от чисто акустической тем, что при выборе способа аппроксимации наблюдаемой кривой F0 учитываются данные восприятия.
Наиболее известным примером применения метода перцептивной стилизации является модель, разрабатываемая с 1960 г. в Институте перцептивных исследований (IPO) в Голландии.
Исходный контур F0 сначала аппроксимируется вручную последовательностью прямых отрезков (тональных сегментов), которые не соотносятся каким-то специальным образом с сегментной основой анал изируемой фразы.
Затем фраза с аппроксимированным контуром ресинтезируется, далее с помощью повторных ресинтезаций находится такая аппроксимация контура, которая содержит минимальное количество тональных сегментов и на слух не отличается от исходного контура.
Примечательно, что в экспертных экспериментах с перцептивной стилизацией было обнаружено, что модификации кривой F0 на участках глухих и звонких согласных и смежных с ними гласных (так называемые микропросодии) практически не влияют на восприятие тонального контура фразы.
"Голландский" метод аппроксимации контура F0 можно рассматривать как широкую разновидность перцептивной стилизации.
В некоторых публикациях описаны методы автоматической перцептивной стилизации, основанные на подходах, отличных от голландского метода.
Иногда принимается, что минимальным носителем тональных различий является слог.
Восприятие тона в рамках слога зависит не только от F0, но и от других фонетических характеристик (длительности, интенсивности, звуковой структуры и т. п.).
По мнению указанных авторов, перцептивная стилизация тонального контура фразы должна представлять собой последовательность тонированных слогов, а тональный контур слога следует интерпретировать с учетом воздействия всех акустических факторов на восприятие высоты тона, а также с учетом известных психоакустических данных (абсолютных и относительных слуховых порогов оценки тональных изменений).
Описанный метод является примером узкой разновидности перцептивной стилизации, он был реализован в автоматическом режиме и интенсивно тестировался на материале французского языка.
Судя по имеющимся в литературе оценкам, все методы стилизации контуров F0 позволяют генерировать ресинтезированную речь высокого качества.
При создании систем TTS получение качественного тонального ресинтеза с помощью тех или иных автоматических методов не является целью разработок, однако выполняет важную подготовительную функцию.
Во-первых, любой метод стилизации (при условии высокого качества ресинтеза) позволяет получить такое представление наблюдаемого контура F0, которое освобождено от ненужных акустических деталей и параметризованно, т. е. содержит количественную спецификацию конечного числа опорных тональных элементов (точек или отрезков), с помощью которых аппроксимируется контур.
Во-вторых, выбор опорных элементов стилизации зачастую отражает теоретические представления (или допущения) исследователей о том, что представляет собой глубинная интонационная характеристика предложения, которая получается (или может быть получена) на выходе лингвистического блока подготовки текста к озвучиванию.
В этом случае ресинтез на основе выбранного метода стилизации позволяет дать предварительную оценку сложности параметрического просодического интерфейса и активно используется для текущей отладки правил генерации тонального контура.
В то же время ясно, что ресинтез сам по себе не может обеспечить порождение тонального оформления произвольного предложения.
4.2.2. Формирование контура F0 для произвольного предложения 
В конкретных системах автоматического синтеза речи содержание и сложность просодических правил, порождающих тональный контур предложения по его интонационному описанию, зависит как от практических возможностей лингвистического блока системы, так и от того, что понимается под интонационной структурой предложения.
Минимальная интонационно значимая информация включает: указание на коммуникативный тип предложения (sentence mode), интонационное членение и расположение акцентированных (или просто лексически ударных) с логов в пределах каждой интонационной группы.
В рамках этого общего минимального требования имеющиеся приложения делятся на две большие группы в зависимости от того, используется ли в них собственно интонационная транскрипция, базирующаяся на некотором фиксированном наборе интонационных единиц – общих моделей или более элементарных просодических элементов, входящих в интонационную систему синтезируемого языка.
Условно системы синтеза, в которых интонационная транскрипция на входе просодических правил в явном виде не используется, могут рассматриваться как реализации инженерного подхода, в отличие от систем, опирающихся на транскрипцию.
Последние системы называются лингвистически (фонологически) ориентированными.
Рассмотрим основные особенности этих подходов.
4.2.3. Генерация тонального контура в системах инженерного типа 
В эту группу, прежде всего, попадают приложения, которые опираются на узкую акустическую стилизацию тональных контуров.
Алгоритмы автоматического получения контуров F0 (pitch extraction) и автоматической сегментации речевого сигнала создают возможность построения больших, просодическиориентированных баз данных, в которых фиксируются частотные значения опорных точек контура F0 для каждого гласного или отдельного слога в составе предложения.
Соответствие между минимальной интонационно значимой информацией, которая дается для каждого предложения в базе данных, и тональными параметрами гласных или слогов (с учетом большого набора поверхностных фонетических переменных – типа слога, его положения в слове и интонационной группе и т.п.) устанавливается с помощью статистических классификационных методов или методов, применяемых в системах распознавания речи, в частности нейроподобных сетей.
После такого предварительного анализа или обучения реальный синтез произвольного предложения получается путем конкатенации тональных слоговых контуров, выбранных из базы с учетом как интонационных признаков, так и поверхностных фонетических факторов, влияющих на акустическую реализацию слогового контура F0.
Нетрудно видеть, что просодические тональные правила заменяются в системах описанного типа хранением обширного инвентаря тональных слоговых контуров, которые конкатенируются "склеиваются", образуя сложный тональный контур предложения.
По имеющимся в печати отзывам, синтез на основе узкой акустической стилизации и тональной конкатенации обеспечивает очень высокую естественность синтезированной речи.
Разработки в это м направлении начались сравнительно недавно, их технологичность, значительная доля автоматизации подготовительной работы привлекают исследователей, занимающихся речевыми технологиями, и специалисты прогнозируют бурный рост соответствующих приложений.
В то же время с лингвистической точки зрения подобные системы мало интересны: фактически в них можно усматривать представление об интонации как о некотором акустическом гештальте, который развертывается в виде сложной тональной схемы на слоговой цепочке предложения.
Однако возможно, что некоторые речевые единицы, ритуальные или несущие сильную эмоциональную окраску, действительно запоминаются и используются в речи, снабженные подобными "гештальтными схемами-мелодиями", находящимися за пределами собственно интонационной системы языка.
Безусловный интерес для лингвистически ориентированных исследований интонации представляет компьютерный инструментарий, который используется при создании послоговых конкатенативных систем тонального синтеза.
Кроме приложений, основанных на конкатенации слоговых тональных контуров, к системам инженерного типа относится и ряд разработок, которые на самом деле занимают промежуточное положение между чистой тональной конкатенацией и лингвистически ориентированными моделями тонального синтеза.
В приложениях такого типа наиболее часто используется артикуляционно-акустическая модель тонального контура (production- oriented model), предложенная известным японским специалистом в области речевых технологий Х. Фуджисаки [12].
Основное допущение этой модели состоит в том, что тональный контур, непрерывный по своей природе, является на самом деле реализацией локальных физиологических событий, которые осуществляются разными ларингальными механизмами.
Различаются два типа событий – фразовые и акцентные тональные команды, которые моделируются соответственно импульсной и ступенчатой функциями.
Кроме этого, вводится один глобальный параметр, который фиксирует нижнюю границу рабочей области голосового диапазона, на нее накладываются фразовые и акцентные команды.
Локальные компоненты модели описываются несколькими параметрами, которые задают относительную амплитуду тонального изменения и временные моменты реализации команд (таймирование) относительно границ фразы (для фразовых импульсов) и границ акцентированного слова для акцентных.
Результирующий тональный контур получается путем сложения всех компонентов, имеющих, как следует из сказанного выше, разные области реализации во времени.
В связи с этим модель Фуджисаки часто относят к суперпозиционным фонетическим моделям интонации.
При создании системы синтеза для конкретного языка используются просодические базы данных, где каждое предложение содержит, по крайней мере, минимальную интонационную информацию.
При анализе корпуса предложений фразовые команды соотносятся с границами интонационного членения, а акцентные – с акцентированными слогами.
Амплитудные и временные параметры аппроксимирующих функций подбираются по базе данных с помощью статистических методов.
Модель тестировалась в системах синтеза для весьма разных языков: японского, английского, китайского, немецкого и ряда других.
4.2.4.Генерация тонального контура на основе лингвистических моделей интонации 
В лингвистически ориентированных системах тонального синтеза контур F0 рассматривается как акустическая манифестация интонационной структуры предложения, которая может быть представлена в виде определенной конфигурации абстрактных интонационных элементов, которые должны фиксироваться в выходной транскрипции лингвистического блока синтезатора.
В разработке таких систем активное участие принимают лингвисты.
В соответствии с теоретическими направлениями, существующими в западной интонологии, можно выделить два типа моделей, которые не только находят применение в системах синтеза речи по тексту, но и благодаря этому активно развиваются.
Это так называемые суперпозиционные (layred components) и линейные или последовательные (tone sequences) модели.
Оба типа моделей исходят из представления о комбинаторной природе интонации: интонационная структура предложения рассматривается как конструкция, состоящая из нескольких функционально самостоятельных тональных элементов.
Оба типа моделей признают существование и лингвистическую значимость локальных тональных объектов, имеющих фиксированную временную привязку в предложении, и глобальные тональные признаки, которые характеризуют тональное пространство, в рамках которого реализуется контур в целом.
Однако функциональная интерпретация локальных и глобальных тональных элементов и их взаимодействие в предложении трактуются в этих моделях по- разному.
В суперпозиционных моделях интонационная структура предложения рассматривается как иерархическая просодическая структура, определяемая в каждой точке предложения одновременно тремя тональными объектами, каждый из которых имеет свою сферу реализации.
Тональные составляющие описываются следующим образом: выделяются глобальные тональные признаки, характеризующие тональное пространство, в котором реализуется предложение в целом, глобальные тональные признаки пространства, занимаемого последовательными интонационными группами в предложении, и тональные фигуры, которые реализуются на составляющих, называемых акцентны ми группами.
Интонационные контуры основных коммуникативных типов предложений отличаются только глобальным тональным признаком, отражающим частотное смещение тонального контура во времени (его наблюдаемым коррелятом служит линия деклинации, соединяющая акцентированные слоги в предложении).
Так, повествовательные предложения имеют наиболее резкий наклон деклинационной линии, а общий вопрос характеризуется отсутствием наклона (плоской линией деклинации).
Реализационной базой лингвистических моделей суперпозиц ионного типа является описанная выше модель Фуджисаки.
Линейные модели восходят к работам Ж. Пьерхумберт [13], посвященным первоначально интонации американского варианта английского языка.
В лингвистическом плане интонационная модель Пьерхумберт опирается на идеи метрической и автосегментной фонологии, развиваемые в США.
В качестве минимальных элементов в модели выделяются два одинарных тона, отличающиеся тональным уровнем – высокий (H) и низкий (L).
Интонационные тоны рассматриваются как абстрактные тональные цели (мишени), ближайшим отражением которых в наблюдаемом тональном контуре являются точки переломов (изменений) F0.
На основе этих тональных примитивов формируются тональные единицы следующих функциональных типов: 1) тональные акценты – одинарные (H*, L*) и битональные (аналоги контурных тонов) (H*+L, H+L*, L*+H, L+H*).
Знак * обозначает привязку тона к акцентированному лексически ударному слогу; 2) фразовые тоны – два типа тональных движений (H-, L-), которые реализуются между последним тональным акцентом интонационной группы и граничным тоном; 3) граничные тоны – тоны, соотнесенные с начальным (%Н, %L) и конечным (H%, %L) слогами интонационной группы.
Возможные комбинации перечисленных тональных единиц образуют грамматику интонационной структуры фразы, которая состоит из четырех следующих компонентов: начальный тон, тональные акценты, фразовый тон, конечный тон.
Абстрактные тональные репрезентации, которые условно можно рассматривать как маршрут или схему движения в целевом тональном пространстве, преобразуются в наблюдаемые контуры F0 с помощью просодических правил двух типов: тонального шкалирования и таймирования.
Правила тонального шкалирования определяют для абстрактных целевых тонов конкретные значения F0, которые считаются зависимыми от двух факт оров: степени выделенности слога, несущего тон, и тональной спецификации предшествующего тона.
Таким образом, частотная спецификация последовательности тонов осуществляется строго слева направо (отсюда название "линейная" модель).
Правила таймирования зада ют с учетом разных поверхностных фонетических факторов координаты временных точек, в которых должна достигаться тональная цель.
Кроме просодических правил, используются адаптирующие функции, с помощью которых в контуре F0 целевые тональные точки соединяют ся тональными переходами и контур в целом сглаживается.
Глобальные тенденции, наблюдаемые в контурах F0, в крайних вариантах линейной модели описываются также исключительно локально.
Например, деклинация считается поверхностным результатом локального взаимодействия определенных смежных тонов (аналогично downstep в африканских языках), а не глобальным тональным признаком, распространяющимся на всю интонационную группу.
Локальная интерпретация глобальных тенденций является наиболее дискуссионной стороной строго линейных моделей и причиной построения различных гибридных моделей, авторы которых вводят в линейную модель и глобальные тональные признаки.
В целом, надо сказать, что на Западе, особенно в США, линейная модель Пьерхумберт получила очень большой резонанс как в фонологических исследованиях, так и прикладных разработках.
Эта модель в адаптированном виде использовалась в системах синтеза для английского, немецкого, китайского, японского и шведского языков.
При создании приложений все просодические правила и адаптирующие функции настраиваются автоматически с помощью обширных аннотированных баз данных.
Для интонационной аннотации речевых корпусов была создана широко известная просодическая транскрипционная система ToBI (сокр. англ. Tones and Break Indices).
В то же время нельзя не отметить, что лингвистический (функциональный) потенциал линейной модели даже для английского языка в полной мере не проверен и не используется в системах синтеза, так как до сих пор не сформулированы правила выбора тонов, образующих тональный компонент интонационной структуры предложения.
4.3. Примеры интонационных контуров 
Рассмотрим несколько примеров интонационных контуров (ИК) для русского языка, по классификации Брызгуновой [1].
Второй тип ИК (рис. 4.1): синтагматическое ударение на вопросительном слове.
На гласном центра ровный или нисходящий высокий тон, затем дальнейшее падение. Рис. 4.1.
ИК для фразы «Ты сколько писем получил от Ивана?» Третий тип ИК (рис 4.2): восходящий тон с последующим падением.
Рис. 4.2.  ИК для фразы «¬Может Людмила этого не понимает?»  Синтагматическое ударение ставится на последнем слове предложения.
Четвертый тип ИК (рис 4.3): нисходяще-восходящий тон.
Рис. 4.3. ИК для фразы «Чудеса!» 
5. ФОНЕТИЧЕСКИЙ ПРОЦЕССОР
5.1. Построение транскрипции 
Рассмотрим алгоритм построения транскрипции на примере русского языка.
Русский язык в этом отношении является достаточно регулярным, что позволяет описать практически весь алгоритм набором правил.
На вход транскриптора подается текст, в котором указаны места, в которых при произношении будут сделаны паузы, и для каждого слова указано, какая из его гласных находится под ударением.
На выходе транскриптор выдает последовательность фонем и аллофонов, соответствующих входному тексту и определяющих его произношение.
Место ударения в каждом из слов существенно влияет на то, как будет произноситься данное слово — очевидно, что речь, в которой все гласные буквы имеют одинаковую продолжительность и интенсивность, будет звучать весьма неестественно.
В русском языке безударные гласные имеют редукцию.
Чем больше степень редукции, тем меньше длительность произношения данной буквы, и тем меньше возможность различить произносимые буквы между собой, например, «(водное) поло» — «(из-под) пола».
Редукция гласных в русском языке вычисляется следующим образом.
Ударные гласные не редуцируются — степень редукции у них 0.
Гласная в первом предударном слоге (предшествующем ударному слогу) имеет степень редукции 1.
Гласные во втором и следующих предударных слогах имеют степень редукции 2, а гласные в заударных слогах (после ударного слога) — степень редукции 4.
Например, в слове «бородатый» редукция гласных в слогах будет, соответственно, 2-1-0-4.
При этом безударная гласная, являющаяся первой буквой в слове, как, например, «а» в слове «аллофон», редуцируется только до степени 1.
Что касается транскрибирования согласных букв, то здесь также есть свои нюансы.
Так, в положении перед гласной «а» все согласные различимы между собой в произношении, тогда как в других положениях, например, на конце слова или перед согласными, произношение согласных может меняться.
Например, слова «рог» и «рок» не различаются по произношению — в слове «рог» происходит оглушение звонкой согласной «г» на конце слова.
Таким же образом может происходить и озвончение согласных — например, в словосочетании «этот звон» последняя «т» в слове «этот» озвончается и произносится как «д».
Правила оглушения и озвончения согласных реализованы в транскрипторе.
Наличие или отсутствие пауз между словами во многом определяет особенности транскрибирования на стыках слов.
В случае, если между словами нет паузы, имеет место взаимовлияние соседних звуков, принадлежащих разным словам.
Кроме того, предлоги, предшествующие словам, или частицы, следующие за словами, при произношении объединяются с тем словом, с которым соседствуют, и становятся составляющими единого фонетического слова, как, например, в сочетаниях слов «по воде» или «могли бы».
Редукция гласных в таких случаях рассчитывается для всего фонетического слова как целого.
Если между словами присутствует пауза, то она делает невозможным влияние друг на друга звуков в словах, находящихся по разные стороны от нее.
Некоторые слова русского языка произносятся не так, как должны были бы произноситься согласно обычным правилам произношения — например, слово «принтер» произносится как [принтыр], а не [принтер].
Эти слова-исключения вместе со своими транскрипциями хранятся в отдельном словаре.
При обработке текста транскриптором производится следующая последовательность действий.
1. Устанавливается степень редукции гласных влево и вправо от ударной гласной каждого слова.
При этом : 1.1.
Каждой ударной гласной присваивается степень редукции 0.
1.2. Гласным слева от ударной гласной в слове присваивается степень редукции, увеличивающаяся от 1 до 2.
1.3.Гласным справа от ударной гласной присваивается степень редукции 4.
1.4. Если первая буква в слове — безударная гласная, то ей присваивается степень редукции 1.
1.5. Те слова, в которых нет своего ударения (предлоги, частицы и т. п.), рассматриваются как единое фонетическое слово вместе со словом, к которому они относятся.
При этом степени редукции гласных в фонетическом слове (то есть имеющим основное ударение) расставляются аналогично тому, как это делается для обычных слов.
2.Производится транскрибирование текста в фонемы в соответствии с правилами преобразования буква-фонема, которые подгружаются из внешнего файла.
3.Производится транскрибирование фонем в аллофоны в соответствии с правилами преобразования фонема-аллофон, которые также задаются во внешнем файле.
Определение того, какой именно аллофон должен соответствовать данной фонеме, производится в зависимости от контекста — от того, какие фонемы или паузы стоят перед и после данной фонемы.
4. Исключения из обычных правил произношения, существующие для некоторых слов русского языка, обрабатываются отдельно от основной последовательности действий.
Примеры таких слов: принтер, Габриель, Фред и т.п. 5.2.
Вычисление физических параметров На вход алгоритму построения физических параметров подается текст, в котором указаны места, в которых при произношении будут сделаны паузы, для каждого слова указано, какая из его гласных находится под ударением и какой силы — это ударение, а также какой тип интонационного контура лежит на этом слове, для каждой буквы- ей соответствующая фонема и аллофон.
На выходе построитель физических параметров выдает последовательность аллофонов, соответствующих входному тексту, определяющих его произношение с указанием для каждого из них значения частоты основного тона, отклонения энергии и длительности звучания.
Сила ударения и тип интонационного контура в каждом из слов существенно влияет на то, как будет произноситься данное слово — очевидно, что речь, в которой все гласные буквы имеют одинаковую продолжительность и интенсивность, будет звучать весьма неестественно.
В русском языке безударные гласные имеют редукцию.
Чем больше степень редукции, тем меньше длительность произношения данной буквы, и тем меньше возможность различить произносимые буквы между собой, например, «(водное) поло» — «(из-под) пола».
Наличие или отсутствие пауз между словами во многом определяет особенности формирования физических параметров на стыках слов.
В случае, если между словами нет паузы, имеет место взаимовлияние соседних звуков, принадлежащих разным словам.
Кроме того, предлоги, предшествующие словам, или частицы, следующие за словами, при произношении объединяются с тем словом, с которым соседствуют, и становятся составляющими единого фонетического слова, как, например, в сочетаниях слов «по воде» или «могли бы».
Физические параметры в таком случае вычисляются для всего фонетического слова как целого.
Если между словами присутствует пауза, то она делает невозможным влияние друг на друга звуков в словах, находящих ся по разные стороны от нее.
Функциональность описываемого алгоритма состоит в том, чтобы определить временные (в мс) и мелодические (в Гц) характеристики базовых элементов компиляции, которые при обработке синтагмы выбираются в нужной последовательности с пециальным процессором (блоком кодировки).
Необходимые для этого предварительные операции над синтезируемым текстом: выделение синтагм, выбор типа мелодического контура, определение степени выделенности (ударности-безударности) гласных — осуществляются предшествующими модулями.
Правила временного оформления синтагмы сформулированы отдельно для гласных и согласных.
Правила, задающие временные характеристики гласных в обрабатываемой синтагме, учитывают степени выделенности (редукции) гласного (4 градации).
К роме того, для ударного гласного последнего полнозначного слова учитывается число слогов в слове и количество ударных гласных, предшествующих данному в синтагме.
Предусмотрено также продление гласных (независимо от степени их редукции и фонетического качества) в позиции абсолютного конца синтагмы.
Что касается влияния согласных на длительность гласных, то оно учитывается лишь в наиболее ярких случаях, прежде всего, для гласных в позиции перед интервокальными вибрантами.
Для последовательностей гласных, образующих единый элемент компиляции (заударные флексии), действует правило аддитивного сложения длительностей, задаваемых правилами формирования длительностей.
Правила, определяющие временные характеристики согласных учитывают следующие факторы: позиция с огласного относительно границ синтагмы и фонетического слова; интервокальная-неинтервокальная позиция; позиция в кластере (стечения согласных); простой-сложный состав базовых элементов компиляции, необходимых для звукового синтеза согласных.
В алгоритм формирования физических параметров входят также правила, задающие длительность паузы после окончания синтагмы (конечной-неконечной), которые необходимы для синтеза связного текста.
Правила мелодического оформления синтагмы задают два значения частоты основного тона (F0) для каждого выбранного элемента компиляции, которые образуют его начальную и конечную мелодические характеристики.
Вычисление этих “физических” значений происходит на основе предварительного определения по правилам мелодических характеристик транскрипционных аллофонов в полутоновой шкале (Т-значения).
Полутоновые характеристики (начальная и конечная) каждого аллофона формируются текущим образом (слева направо) слоговыми циклами, т.е. в рамках последовательности (Cn)Г, где Cn — любое число согласных, в том числе 0, предшествующих гласному.
Алгоритм формирования физических параметров содержит правила для формирования следующих типов мелодических контуров: повествовательное предложение, повествовательное предложение, в котором есть слово с особым выделением, вопрос с вопросительными словами, восклицательное предложение, восклицательное предложение с вопросительными словами (Какая погода!), "Какая погода...", простой вопрос, вопрос со значением противопоставления, пунктуация - запятая тире, пунктуация двоеточие, пунктуация тире, пунктуация запятая, пауза есть, пунктуации нет.
Для всех контуров, кроме вопроса с вопросительными словами, учитывается возможность разного положения главноударного слога (мелодического центра) синтагмы.
Специальный вопрос формируется для случая совпадения мелодического центра с вопросительным местоимением.
При определении мелодических характеристик элементов компиляции, входящих в обрабатываемый слог, учитываются следующие факторы: тип мелодического контура синтагмы; положение слога относительно мелодического центра контура (совпадение, слева, справа); положение слога относительно начальной и конечной границы синтагмы; степень выделенности (редукции) гласного в обрабатываемом слоге; степень выделенности (редукции) гласного, непосредственно предшествующего обрабатываемому слогу; число символьных элементов в слоге; тип символьного элемента слога (согласный, гласный) и положение этого элемента относительно начала слога (первый - не первый); фонетическое качество согласных в слоге (глухость-звонкость); простой - сложный состав базовых элементов компиляции, необходимых для звукового синтеза согласных в слоге.
Результат применения правил к любой затранскрибированной нужным образом синтагме может быть представлен в виде таблицы стандартного формата, пример которой приводится ниже (таблица 5.1) для фразы “Мама мыла малину?” (в мужском произнесении).
В таблице 5.1 представлены звуки, определяющие произносительный вариант фразы, для которых вычислены параметры длительностей и частоты основного тона с которыми должны быть синтезированы звуки во фразе целиком.
Знаком " + " обозначаются ударные гласные, " ' "- мягкие согласные, а " ? " - фразовое ударение.
6. АКУСТИЧЕСКИЙ ПРОЦЕССОР 
Схема работы акустического процессора представлена на рис. 6.1.
6.1. Оптимальный выбор звуковых элементов методом Unit Selection 
После того, когда требуемые параметры звуковых элементов, необходимых для синтеза определенного предложения, получены, наступает очередь применения метода Unit Selection (US) для выбора оптимальной последовательности их реализаций из звуковой базы данных [1 4].
Для того чтобы определить, насколько тот или иной элемент базы подходит для синтеза данной единицы, вводятся понятия стоимости замены (англ. target cost) и стоимости связи (англ. concatenation cost).
Стоимость замены для элемента из базы iu по отношению к искомому элементу it вычисляется по формуле C^t (u_i,t_i)=∑_(k=1)^p▒〖w_k^t C_k^t 〗(u_i,t_i) (6.1) где C_k^t— расстояние между k-ими характеристиками элементов, w_k^t— вес для k-ой характеристики.
Выбор звуковых элементов (Unit Selection) Сглаживание энергетической огибающей Модификация частотных и темпо-ритмических характеристик Объединение элементов в звуковой потокАкустические базы и правила Данные управления Фонетический процессор Параметры звуковых элементов Звуковые эффекты Синтезированная речь 
Рис.6.1. Схема работы акустического процессора 
Другими словами, это есть взвешенная сумма различий в признаках между требуемым элементом и конкретным элементом речевой базы.
В качестве признаков могут выступать любые уместные, с точки зрения разработчика, просодические и лингвистические характеристики элементов.
Как правило, используется следующая информация: частота основного тона (ЧОТ), длительность, контекст, позиция элемента в слоге, слове, количество ударных слогов во фразе и другие [15].
Выбранные элементы должны не только мало отличаться от целевых, но и хорошо соединяться друг с другом.
Функция стоимости связи двух элементов может быть определена как взвешенная сумма различий в признаках между двумя последовательно выбранными элементами.
C^c=(u_(i-1),u_i)=∑_(k=1)^q▒w_k^c  C_k^C (u_(i-1),u_i)  (6.2) где C_k^C  — расстояние между k-ими характеристиками элементов, w_k^c — вес для k-ой характеристики.
Общая стоимость для целой последовательности из n элементов есть сумма введенных выше стоимостей C(u,t)=∑_(i=1)^n▒〖C^t (u_i,t_i)+ ∑_(i=2)^n▒C^C (u_(i-1),u_i)〗 (6.3) Задача метода US — выбрать такое множество элементов базы, u_1,u_2…,u_n которое бы минимизировало общую стоимость согласно формуле (6.3).
6.1.1. Стоимость замены 
Основное назначение функции стоимости замены — оценивать, в какой мере подходит данная единица речевой базы к требуемому элементу.
В связи с этим, стоимость замены должна отражать, как сильно различия в характеристиках влияют на вос приятие замены одного элемента другим.
При построении этой функции, как правило, руководствуются одним из следующих принципов: независимых признаков, акустического пространства.
Принцип независимых признаков В этом случае расстояние для каждого признака считается независимо от других, взвешивается и затем общая стоимость считается как некоторая функция полученных расстояний.
В качестве такой функции можно использовать простую сумму (6.1).
Функции C_k^t определяют расстояния для каждой отдельно взятой характеристики.
Для категориальных это может быть простое бинарное решение, совпадают они или нет.
Для непрерывных (например, ЧОТ) это может абсолютное расстояние или его логарифм.
Различия в одних характеристиках оказывают больше влияния на восприятие замены, чем в других.
Эта разница отражается в выборе весов w_k^t для конкретного расстояния.
Для установки весов существует несколько подходов: 1) автоматический подбор на основе объективной меры, 2) перцепционный, 3) ручная настройка.
Автоматический подбор на основе объективной меры.
Суть этого подхода заключается в попытке найти такой набор весов, который минимизировал бы акустическое расстояние между синтезированным и эталонным выражениями.
Для оценки близости требуется метрика, поставляющая расстояния между синтезированными и эталонными высказываниями.
Высказывания, воспринимаемые на слух как сходные, должны иметь маленькое расстояние между собой.
Для нахождения оптимальных весов достаточно воспользоваться методом линейной регрессии.
Задача определения такой метрики является отдельной проблемой [16].
При таком подходе веса могут подбираться индивидуально для каждой единицы базового типа.
Перцепционный.
Слабое место предыдущего подхода заключается в том, что разработчик во многом полагается на акустическую меру, которая лишь частично соответствует человеческому восприятию.
В рамках данного подхода ставится эксперимент, в котором людей просят оценить синтезированные предложения, а затем тренируют модель согласно полученным оценкам.
Очевидный недостаток — большие временные затраты и сложность в организации эксперимента.
Ручная настройка.
Проектировщик системы полностью полагается на свой опыт.
В ходе тестирования системы веса постепенно уточняются.
Главное преимущество - полный контроль над процессом.
Очевидным плюсом принципа независимых признаков при построении функции стоимости замены является небольшое число подлежащих настройке весов (равное количеству используемых признаков).
Однако предположение независимого влияния весов на общую стоимость является слишком сильным.
Яркой демонстрацией слабости этого принципа является тот факт, что два различных набора характеристик будут неминуемо иметь ненулевое расстояние.
Это противоречит нашим знаниям о речи, которые как раз говорят о том, что различные комбинации характеристик зачастую проецируются в одну акустическую реализацию.
Принцип акустического пространства Главная идея этого подхода заключается в кластеризации единиц базового типа по просодическому и фонетическому контекста м. Блэк и Тэйлор предложили следующую схему кластеризации.
Вводится объективная мера для измерения расстояний между единицами одного базового типа.
Опять же, выбор подходящей акустической меры — отдельное поле для исследований.
В своей работе авторы используют взвешенное расстояние Махаланобиса на коэффициентах MFCC (Mel Frequency Cepstral Coefficients), ЧОТ, мощности и их дельтах (производных первого порядка).
Акустическое расстояние между двумя единицами Adist(V,U), Adist — это среднее по всем фреймам внутри единиц плюс среднее по X% фреймов единиц, предшествующих рассматриваемым (близкие единицы будут иметь сходный левый контекст):  Adist(V,U)=  (WD∙U)/(|V|)∙ ∑_(i=1)^(|U|)▒∑_(j=1)^n▒(w_j |F_ij (U)- F_((i|V|/|V|)_j) (V)|)/(SD_j∙n∙|U|) (6.4) где U,V — элементы одного базового класса, |U|<|V| — количество фреймов в U и,V 
F_xy (U) — признак y фрейма x элемента U 〖SD〗_j — стандартное отклонение признака j, w_j — вес для признака j, WD — взвешивает разницу в продолжительности элементов.
Введенная мера используется для вычисления «загрязненности» Impurity(C) кластера C как среднего акустического расстояния между элементами кластера: Impurity(C )=(2(∑_(i=1)^(|C|)▒∑_(j=i)^(|C|)▒〖Adist(u_i,u_v 〗) )/(〖|C|〗^2-|C|).
Затем с помощью стандартной техники деревьев решений кластер разбивается на две части наилучшим образом.
Качество разбиения Coodness(C_1,C_2) кластера C на две части C_1 и C_2 задается формулой Coodness(C_1,C_2)=(Adist(C_1 )T〖(C〗_1)+Adist(C_2 )T〖(C〗_2) )/(T〖(C〗_1)+T〖(C〗_2)),T(C)=(〖|C|〗^2-|C|)/2 В качестве критерия разбиения используются бинарные вопросы, которые касаются характеристик, применяемых для вычисления стоимости замены (фонетический контекст, просодический контекст (ЧОТ и длительность для элемента и его соседей), ударение, позиция в слоге, позиция в слове, позиция в предложении).
На каждом этапе выбирается вопрос, дающий лучшее разбиение.
Разбиение обычно продолжается до тех пор, пока не будет достигнут какой-либо порог (например, минимальное количество элементов в листе).
6.1.2.Стоимость связи 
Основное назначение функции стоимости связи — оценивать, насколько хорошо два элемента соединяются друг с другом.
Идеальной была бы функция, имеющая высокую корреляцию с восприятием речи слуховой системой человека.
Обычно общая стоимость складывается из нескольких слагаемых, основанных на спектральных и просодических характеристиках фреймов речи с обеих сторон соединяемых элементов.
Как правило, учитываются: 1. Разница в ЧОТ. 2. Разница в энергии. 3. Нестыковка различных спектральных параметров: (a) MFCC (Mel Frequency Cepstral Coefficients); (b) LPC (Linear Predictive Coding Coefficients); (c) LSF (Line Spectral Frequencies); (d) MCA (Multiple Centroid Analisys). (e) 
Так же, как и при кластеризации речевой базы, вводится акустическая мера на спектральных параметрах.
За последние годы было проведено большое количество исследований с целью выяснить, какая комбинация спектральное представление/метрика дает лучшую корреляцию с человеческим восприятием.
К единому мнению по этой проблеме ученые так и не пришли.
Можно лишь отметить, что расстояние Махаланобиса на коэффициентах MFCC в большинстве тестов показывает неплохие результаты.
6.1.3. Поиск по алгоритму Витерби 
Согласно классическому алгоритму Ханта и Блэка [14] общая стоимость последовательности элементов из базы u=(u_1,…,u_n), для данной спецификации t=(t_1,…,t_n), задается формулой (6.3).
Эта формула дает стоимость для любой фиксированной последовательности элементов базы u=(u_1,…,u_n),.
Цель состоит в том, чтобы найти такую последовательность, стоимость которой будет минимальна.
Задача поиска оптимальной последовательности сводится к поиску пути наименьшей стоимости на графе.
Хотя алгоритм Витерби и превосходит в значительной степени поиск полным перебором (квадратичная оценка против экспоненциальной), в своей чистой реализации, и он может не дать необходимой скорости вычислений.
В этом случае следует воспользоваться одной из техник отсечения (англ. pruning), целью которых является уменьшение количества рассматриваемых последовательностей.
При этом отсечение некоторого подмножества последовательностей приводит к риску исключить оптимальный путь, в то время как полный поиск по алгоритму Витерби гарантированно найдет траекторию с наименьшей стоимостью.
Последствия зависят от того, много ли найдется в базе путей, имеющих стоимость близкую к оптимальной.
Выделяются две основные техники отсечения: предварительный отбор (англ. pre-selection) и отсечение лучей (beam pruning).
В первом случае для каждого элемента спецификации отбирается фиксированное количество лучших кандидатов.
Во втором случае рассматривается только фиксированное количество локально оптимальных путей.
Схематично, процесс работы метода Unit Selection представлен на рис.6.2.
6.1.4. Речевая база и качество синтеза для метода Unit Selection 
Метод Unit Selection критически зависит от речевой базы.
Качественный синтез возможен только на основе полной, сбалансированной и корректно размеченной базы данных.
С ростом объема базы возрастает темповая и интонационная вариативность речи диктора.
Иными словами, чем больше база, тем больше вероятность того, что в ней найдется элемент в необходимом контексте с необходимой длительностью и контуром ЧОТ.
Как следствие, меньше искажения от цифровой модификации сигнала и выше естественность синтезируемой речи.
a1 a2... ak a11 a12... a1N1a21 a22... a2N2............ak1 ak2... akNk- целевой элемент- элемент-кандидат- стоимость замены- стоимость связи 
Рис. 6.2. Схема работы метода Unit Selection 
В процессе подготовки речевой базы на предварительных этапах желательно проводить запись большого числа дикторов.
Запись каждого диктора представляет собой чтение фонетически представительного текста.
Запись желательно осуществлять в заглушенной камере с использованием высококачественных средств записи и оцифровки речевого сигнала.
Полученные предварительные записи большого числа дикторов необходимы для получения максимально качественного итогового набора дикторов, голоса которых будут использоваться в системе синтеза речи.
Наличие относительно широкого круга дикторов на начальном этапе позволяет осуществить осознанный выбор и минимизировать риск того, что голос того или иного диктора окажется малопригодным для использования в системе синтеза речи.
Отобранные на предварительном этапе дикторы используются для записи больших звуковых баз данных, которые в дальнейшем сегментируются на различных уровнях анализа.
В такой ситуации ошибка в выборе диктора на поздних этапах может вылиться в существенные материальные и временные затраты.
Для повышения качества синтеза база сегментируется на разных уровнях.
В качестве меток используются реальная и каноническая транскрипции, орфографически е слова с отметками логического и синтагматического ударения, типы интонационных контуров.
Также размечаются речевые явления: смех, кашель, причмокивания и др. В целом, при использовании корректно размеченной, сбалансированной базы, качество синтезируемой речи можно субъективно охарактеризовать как очень хорошее.
Однако оно не является постоянной величиной.
В какой-то степени такое поведение заложено в самой технологии: когда на выходе образуются немодифицированные фрагменты непрерывной речи, качество буде т соответствовать записям базы.
С другой стороны, в базе просто может не быть хороших соответствий спецификации.
И в этом случае синтез будет звучать менее естественно, с заметными искажениями.
6.1.5. Основные сложности и ограничения применения метода Unit Selection 
Как уже отмечалось выше, качество синтеза методом Unit Selection в большой степени зависит от качества используемой речевой базы.
Одним из ключевых факторов является размер базы.
Чем больше размер базы, тем больше имеется вариантов для синтеза, тем выше вероятность гладкой стыковки фрагментов.
С другой стороны, с увеличением базы возрастают затраты на вычисление стоимостей связи и замены, поэтому для устройств с ограниченными вычислительными ресурсами приходится идти на компромисс между производительностью и качеством.
6.2. Сглаживание энергетической огибающей 
На данном этапе происходит выравнивание энергетической огибающей полученной звуковой последовательности.
В силу ограниченности звуковой базы данных довольно часто возникают ситуации, когда один звук гораздо громче или гораздо тише соседнего.
Данные разногласия в амплитуде будут восприниматься слушателем как неестественные артефакты.
Пример такой ситуации представлен на рис. 6.3.
Рис. 6.3. Нарушение энергетической гладкости сигнала 
Исправление подобных ситуаций происходит путём плавного приведения амплитуды более громкого звука к более тихому.
Результатом работы данного этапа для примера, представленного на рис.6.3, будет следующий звуковой сигнал (рис.6.4).
Рис. 6.4. Обеспечение энергетической гладкости 
6.3. Модификация звуковых элементов 
На данном этапе происходит исправление темпо-ритмических и частотных артефактов [17], проявляющихся в нарушениях плавности интонационной огибающей сигнала и ритмических соотношений между элементами в звуковой последовательности, которые также воспринимаются слушателем, как неестественные образования в потоке речи.
Корректировка происходит путём модификации длительности и частоты основного тона отдельных звуковых единиц, длительность или ча стота основного тона которых, выходит за границы предсказанного допустимого коридора для данной конкретной фразы, интонационной модели и диктора.
6.3.1. Алгоритм TD-PSOLA 
Широко распространены алгоритмы, работающие во временной области, наиболее популярным из которых является технология TD-PSOLA (Time-Domain Pitch-Synchronous-Overlap-Add) [18].
Данный алгоритм работает периодосинхронно, т.е. каждый обрабатываемый фрагмент представляет собой один период.
Обязательным условием для этого является возможность определить частоту основного тона сигнала с высокой точностью, т.к. от этого напрямую зависит качество работы этого алгоритма.
Границами периодов основного тона служат места закрытия гортани.
Далее сигнал разбивается на фрагменты, взвешенные окном Хеннинга, которое захватывает два соседних периода с перекрытием в один период, как показано на рис. 6.5.
Эти взвешенные фрагменты затем могут быть перекомбинированы путём перемещения их центров и наложением с добавлением перекрывающихся частей (отсюда и название, overlap and add – перекрытие и добавление).
Несмотря на то, что после выполнения данных операций, форма результирующего сигнала становится не в точности такой, какая была прежде, процедура перекрытия с добавлением позволяет получить достаточно близкий результат, что бы различия не были заметны.
Непосредственная модификация частоты основного выполняется путём распределения полученных взвешенных фреймов на новые значения частоты, предоставляющей собой множество расстояний между окнами им соответствующее.
Для примера рассмотрим участок речи с частотой основного тона 100Гц, границы периодов буду лежать с интервалом в 10мс.
Взяв эти периоды за основу, проанализируем их и разделим на описанные выше периодосинхронные фрагменты, взвешенные окнами Хеннинга.
Далее создадим новое множество периодов, границы которых буду располагаться ближе друг к другу, скажем через каждые 9мс.
Далее, если перераспределить подготовленные фреймы путём перекрытия с наложением, мы получим сигнал, который будет иметь частоту основного тона, равную 1.0/0.009 = 111Гц.
Если производить обратную операцию – создать множество периодов, границы которых будут располагаться дальше друг от друга, и перераспределить фреймы с перекрытием, мы получим синтезированный сигнал с более низкой частотой основного тона.
Процедура уменьшения частоты основного тона частично объясняет причину использования двух периодов во взвешенных фреймах; это делается для того, чтобы не оставалось пустых мест в результирующем сигнале при увеличении расстояния между центрами фреймов.
При сохранении длительности фонограммы, в целом слушатели не замечают неестественностей в сигнале при небольших модификациях частоты основного тона.
Когда алгоритм применяется для модификации хорошо размеченной на периоды основного тона речи, качество его работы чрезвычайно высоко, и пока степень изменения частоты основного тона не слишком значительна (скажем +/- 10% от оригинала), качество речи может быть «идеальным», в том смысле, что слушатель не может заметить в речи какой-то неестественности.
С точки зрения вычислительной нагрузки на аппаратные ресурсы, сложно представить какой-либо алгоритм, работающий быстрее.
Поэтому зачастую TD-PSOLA рассматривается как приемлемое решение для проблемы модификации частоты основного тона.
Однако, конечно алгоритм не идеален во многих ситуациях, не потому, что он не выполняет поставленную задачу, а потому, что на практике, как минимум, нам приходится модифицировать частоту основного тона более чем на 10%, например, чтобы гарантировать гладкость интонационного контура в синтезированной речи в случаях отсутствия звуковых элементов с требуемой частотой в базе данных.
Так же, работая во временной области, он вносит неконтролируемые искажения в сигнал и, при уменьшении частоты основного тона, существенно редуцируется энергия на границах "склеек" фреймов.
Рис.6.5. Основные операции алгоритма PSOLA : (a) участок вокализованного сигнала, размеченный на периоды основного тона, (b) взвешивающие окна Хеннинга, центрированные на каждом периоде.
(c) полученная последовательность пар периодов после процедуры взвешивания окном (d) ресинтезированный путём перекрытия с добавлением сигнал 
6.3.2. Алгоритм SPECINT (Spectrum Interpolation) 
В связи с психоакустическими эффектами малейшие искажения в относительном положении формант, изменения огибающей основного тона, ведут к побочным эффектам, из-за которых речь становится неестественной, непривычной для нашего восприятия, как следствие человек при её прослушивании быстро утомляется и не может длительное время внимательно её воспринимать.
Вследствие этого одним из основополагающих действий является получение огибающей основного тона исходного сигнала и её воспроизведение на сигнале новой длины.
Немаловажно сохранение энергетической огибающей, поскольку при увеличении или уменьшении частоты основного тона появляются неизбежные её искажения, что также приводит к снижению естественности речи.
Перед тем как понизить, или повысить основной тон, увеличить, или уменьшить длительность, необходимо получить значения основного тона на всём модифицируемом участке.
При модификации изменить требуемые характеристики аллофонов так, чтобы траектория основного тона осталась прежней, т.е. измениться должен только масштаб (частоты и времени), иначе при малейшем изменении спектральной картины мы услышим режущие слух, новые интонации в речи даже при незначительных модификациях.
Для этого анализируется сигнал с целью получения вектора значений частоты основного тона на всём его протяжении.
В системе синтеза русской речи это аллофон.
То есть на каждом периоде аллофона вычисляется значение его основного тона, заполняется некоторый массив данных (вектор значений).
Далее полученная огибающая изменяется по тону (поднимается или опускается), затем путём сплайн-интерполяции она растягивается или сжимается на требуемую длину.
В итоге получаем модель аллофона после модификации, под которую мы должны модифицировать исходный аллофон.
Модификация сигнала посредством периодосинхронного дискре тного преобразования Фурье Модификация сигнала под требуемую модель происходит следующим образом [19].
Каждый период модифицируется под параметры, смоделированные выше.
Рассмотрим этот процесс на примере некоторого периода.
Путём дискретного преобразования Фурье получаем спектр сигнала, рассматриваем отдельно вещественные и мнимые его составляющие (рис. 6.6 и рис. 6.7 соответственно).
Рис.6.6. Вещественная часть сигнала после ДФП (до и после интерполяции) 
Очевидно, что в спектральной области мы получим пики на частотах, кратных частоте периода.
Далее мы интерполируем пики на весь диапазон частот, равный половине частоты дискретизации, и вычисляем значения сплайнов в точках, соответствующих пикам нового периода.
Далее, выполнив обратное дискретное преобразование Фурье, мы получим период с требуемой частотой.
Рис.6.7. Мнимая часть сигнала после ДФП (до и после интерполяции)
Однако при таком подходе без дополнений мы не можем контролировать амплитуду результирующего сигнала.
Точнее огибающая амплитуды у нас сохранится, но абсолютное её значение будет отличным от исходного, что сделает сигнал громче или тише, т.к. этот параметр напрямую зависит от того, повышается или понижается основной тон.
С увеличением частоты основного тона амплитуда уменьшается, с уменьшением — увеличивается.
Для сохранения исходных величин амплитуды вычисляется нормирующий коэффициент, на который домножаются значения коэффициентов вещественной и мнимой части.
В результате получаются пики, находящиеся на огибающей, которая нормирована та ким образом, чтобы после обратного ДФП получились те же значения амплитуд, как и в исходном сигнале (рис. 6.8 и рис. 6.9).
Рис.6.8. Вещественная часть спектра сигнала после ДФП (до и после интерполяции с нормировкой) 
Спектры мощности сигнала до и после модификации отображены на рис.6.10.
Из рисунка легко заметить, что период был модифицирован примерно со 115Гц на 155Гц.
Его поведение во временной области показано на рис. 6.11.
Рис.6.9. Мнимая часть спектра сигнала после ДФП (до и после интерполяции с нормировкой) 
Со всеми остальными периодами сигнала производится аналогичные действия.
Рис.6.10. Спектры мощности исходного и модифицированного сигнала 
Рис.6.11. Один период во временной области (слева — исходный, справа — после модификации) Модификация длительности 
Изменения основного тона приводят к изменению длины аллофона, звук которого подвергается модификации.
Это обуславливает потерю естественности, диктор начинает говорить то быстрее, то медленнее.
Подобное явление нередко возникает и при компилятивном синтезе.
В таких случаях также необходимо исправлять длительность аллофонов.
Повышение основного тона периодического сигнала по вышеописанному алгоритму уменьшает его длительность.
Для её восстановления обычно используется повтор периодов сигнала.
При этом необходимо избежать возникновения двух основных дефектов снижающих качество синтезированного сигнала.
Первый связан с тем, что при каждом повторе сбивается фаза сигнала (рис. 6.12), что выражается в характерном потрескивании при воспроизведении сигнала.
Второй связан с тем, что многократное повторение одного периода человеческое ухо воспринимает как гудение или звон.
Рис.6.12. Слева - пример корректной стыковки периодов, справа - пример некорректной стыковки периодов 
В [19] была предложена и реализована следующая схема повтора периодов.
Пусть, L_n,n=0,…N — массив значений левого периода (рис. 6.13), а, R_p,p=0,…P — массив значений правого периода (рис. 6.14).
Рис.6.1 3. Периоды до удлинения сигнала.
Тогда массив значений нового периода, который необходимо вставить между правым и левым определяется суперпозицией:  Рис.6.1 4.
Периоды после удлинения аллофона.
Добавленный период в центре M_k=TR_k+TL_k,k=0…K,{█(TL_k=0,k=0..G@TL_k=L_(k-G) W_(k-G)^1,k=G..K^,) {█(TR_k=0,k=F..K@TR_k=R_k W_k^2,k=0..F^,)┤┤ где W_n^1=1/2 (1-cos⁡(πn/S) ),n=0..S,〖 W〗_n^2=1/2 (1-cos⁡(πn/F) ),n=0..F, G=max⁡(0,K-N),S=min⁡(N,K),F=min(P,K) Полученный в результате период (рис. 6.11) идеально стыкуется по фазе как с правым, так и с левым своим соседом, при этом не является повтором ни того, ни другого, что и является необходимым нам решением вышеописанных дефектов.
Алгоритм пригоден и для многократного повторения, если его применить последовательно для вставки каждого нового периода.
Соответственно, понижение высоты основного тона периодического сигнала вышеизложенным алгоритмом увеличивает его длительность.
В этом случае, для компенсации (уменьшении длительности) также важно избежать сбоя фазы, поэтому используется аналогичный подход, массив значений нового периода, который необходимо вставить вместо имеющихся двух определяется суперпозицией:M_k=TR_k+TL_k,k=0…K,{█(TR_k=0,k=0..G@TL_k=R_(k+P-K) W_(k-G)^1,k=G..K^,) {█(TL_k=0,k=F..K@TL_k=L_k W_k^2,k=0..F^,)┤┤ гдеW_n^1=1/2 (1-cos⁡(πn/S) ),n=0..S,〖 W〗_n^2=1/2 (1-cos⁡(πn/F) ),n=0..F, G=max⁡(0,K-P),S=min⁡(P,K),F=min(N,K) 
6.3.3. Алгоритм LP-PSOLA 
Данный подход [20] комбинирует в себе основные идеи методов TD PSOLA и SPECINT.
Применяется LP модель, изображённую на рис. 6.15, для получения сигнала ошибки e[n].
Рис.6.1 5. Структурная схема блока LP фильтра 
Далее он модифицируется методом, представленным в разделе 6.3.1.
И в заключение, полученная модифицированная функция ошибки предсказания e'[n] используется для восстановления исходного сигнала с новой частотой основного тона.
Формула для вычисления e[n] дана в (6.5): e[n]=s[n]-a^(-T)∙s ̅[n-1] (6.5) где s ̅[n-1]=〖[s┤[n-1],s[n-2],..,s[n-P]]〗^T,a ̅=〖[a_1,a_2,…,a_p]〗^T Результирующий вектор коэффициентов линейного предсказания вычисляется по формуле a ̅_n=(R^(-1) ) ̅[n-1] p ̅[n] (6.6) где (R^(-1) ) ̅[n-1]=∑_(i=0)^n▒〖s ̅[i-1] s ̅[i-1],p ̅[n] 〗=∑_(i=0)^n▒〖s ̅[i-1]s[i]〗Значения p ̅[n]в выражении (6.6) можно вычислить рекурсивно, для того чтобы избежать дополнительных накладных вычислительных расходов, как показано в формуле (6.7): p ̅[n]=s ̅[n-1]s[n]+p ̅[n-1] (6.7) Далее, полученные LP коэффициенты на этапе анализа сигнала, применяются в обратном LP фильтре к модифицированной функции ошибки e'[n] для того, чтобы получить модифицированный сигнал s'[n] с желаемой частотой основного тона, как показано в (6.8): s^'[n] =e^' [n]+a^(-T)∙s ̅^' [n-1] (6.8) Общая схема алгоритма представлена на рис. 6.1 6.
Модифицированную функци ю ошибки e'[n] можно получить из e[n], используя алгоритм TD-PSOLA, как показано далее.
LP модель определяется для каждого отсчёта сигнала n, что позволяет добиться плавных переходов с соседними моделями.
Качество результирующей модели зависит от выбора порядка её порядка P. После правильного определения меток частоты основного тона  p_m [n] и периодов частоты основного тона p[n] в исходном сигнале, контур частоты основного тона может быть модифицирован желаемым образом.
С этой целью определяются новые метки p_m [n], соответствующие значениям новым периодом основного тона p[n] так, что p^' [n]=β[n]p[n]где β[n] это степень модификации периода основного тона, который может быть различным для естественной просодической модификации, автоматической коррекции частоты основного тона и так далее.
Рис.6.1 6. Схема анализа и синтеза нового сигнала с использованием LP-модели 
Новые метки частоты основного тона p_m'[n]определяются путём добавления в интервал p'[n] отсчётов между двумя соседними метками так, что метка частоты основного тона будет перемещена в позицию n+p'[n], если n содержит метку (т.е. p_m'[n+p'[n]]=1 если p_m'[n]=1 где позиция метки частоты основного тона равна 1).
На следующем шаге необходимо соединить каждую новую метку частоты основного тона p_m'[n] с соответствующим ей ближайшим пиком в оригинальном сигнале p_m[n] Это делается путём непосредственного сравнения временных индексов p_m[n] и p_m'[n], как показано на рис. 6.17.
Рис.6.1 7. Распределение меток частоты основного тона при модификации сигнала: (a) увеличение частоты, (b) уменьшение частоты 
В заключение, для генерации итоговой функции ошибки, сигнал разбивается на взвешенные окном Хеннинга фрагменты по парам периодов с перекрыти ем в один период, т.е. для каждой метки, начиная с предыдущей и заканчивая следующей.
Данные сегменты соединяются согласно процедуре перекрытия с наложением так, чтобы соответствовать новым периодам частоты основного тона p'[n], полученным ранее, как показано на рис. 6.18.
Данный подход так же обладает рядом проблем: аппаратная сложность вычисления LP коэффициентов и обратного LP-фильтра, в сигнале возбуждения остаётся информация о голосовом тракте, ведущая к появлению непонятных тембральных артефактов при восстановлении сигнала по модифицированной функции ошибки.
Рис.6.1 8. Получение модифицированного сигнала: (a) увеличение частоты, (b) уменьшение частоты 
6.3.4. Экспериментальные сравнения 
Рассмотрим ряд экспериментов модификации частоты основного тона представленными алгоритмами и сравнение результатов их работы.
Пример 1.
Участок синтезированной женским голосом речи был модифицирован с β[n]=2 и β[n]=0.5.
Рис.6.19 демонстрирует неболь шие участки исходного и модифицированного сигналов методами TD-PSOLA, SPECINT и LP-PSOLA.
На рис. 6.20 приведены им соответствующие спектрограммы : a) исходный сигнал, b) модифицированный сигнал методом LP-PSOLA с β[n]=2, c) модифицированный сигнал методом SPECINT с β[n]=2, d) модифицированный сигнал методом TD-PSOLA с β[n]=2, e) модифицированный сигнал методом LP-PSOLA с β[n]=0.5, f) модифицированный сигнал методом SPECINT с β[n]=0.5, g) модифицированный сигнал методом TD-PSOLA с β[n]=0.5.
Рис.6.19. Фрагменты сигналов в примере 1 
Исходя из данных на рис.6.19, можно сделать вывод, что все алгоритмы работают корректно - пики периодов основного тона становятся дальше или ближе друг от друга при модификации с β[n]=2 и β[n]=0.5 соответственно.
Аналогичный вывод можно сделать и проанализировав частотные полосы, представленные спектрограммами на рис. 6.20.
Здесь: a) исходный сигнал, b) модифицированный сигнал методом LP-PSOLA с β[n]=2, c) модифицированный сигнал методом SPECINT с β[n]=2, d) модифицированный сигнал методом TD-PSOLA с β[n]=2, e) модифицированный сигнал методом LP-PSOLA с β[n]=0.5, f) модифицированный сигнал методом SPECINT с β[n]=0.5, g) модифицированный сигнал методом TD-PSOLA с β[n]=0.5.
Пример 2.
Вновь характеристики частоты основного тона были модифицированы с β[n]=2 и β[n]=0.5.
Однако в данном примере использовалась речь, синтезированная мужским голосом.
Вид результатов во временной и частотной области практически аналогичен тем, что изображены на рис.6.19 и рис.6.20 соответственно.
Так же, как и в примере 1, по результатам не сложно определить, что частота основного тона модифицирована должным образом.
В то время как спектральная огибающая осталась неизменной.
Рис.6.20. Спектрограммы сигналов в примере 1 
Пример 3.
На рис.6.21 приведено сравнение результатов представленных методов во временной области с β[n]=2 на сигнале из предыдущего примера 1.
Здесь: a) исходный сигнал, b) модифицированный сигнал методом TD-PSOLA, c) модифицированный сигнал методом SPECINT, d) модифицированный сигнал методом LP-PSOLA.
Данный пример иллюстрирует значительные недостатки алгоритма TD- PSOLA, которые заключаются в существенной редукции энергии сигнала между соединяемыми пиками периодов частоты основного тона при β[n]>1.
Хотя большие окна анализа могли бы исправить эту проблему, они могли бы стать причиной появления ложных пиков в модифицированном сигнале, т.к. они могут не полностью редуцироваться окнами анализа.
А такие ложные пики ведут к грубостям и неестественностям в сигнале.
Рис.6.21. Фрагменты сигналов в примере 3 
Проведенные эксперименты показали, что наилучшие результаты для модификации частоты основного тона в диапазоне 0.5<=β[n]<=2 достигаются при использовании алгоритма LP-PSOLA.
Преимущество этого метода заключается в сохранении индивидуальности каждого гортанного импульса.
Однако, поскольку в сигнале ошибки частично остаётся формантная структура, метод LP-PSOLA не является совершенным и зависит от порядка LP фильтра.
6.4. Объединение элементов в единый звуковой поток 
Рассмотрим обработку данных на данном этапе на примере пары звуковых единиц, не умаляя общности задачи, т.к. на данном этапе происходит стыковка каждой пары звуковых элементов при формировании единого звукового потока.
При конкатенативном синтезе можно выделить следующие типы таких пар, требующих различной логики стыковки: оба аллофона взяты из одного файла и идут подряд — в этом случае никакой стыковки вообще не происходит; оба аллофона взяты в точных контекстах ; первый аллофон взят в точном контексте, второй — в близком или дальнем; первый аллофон взят в близком или дальнем контексте, а второй — в точном; оба аллофона взяты в близких/ом (дальних/ем) контекстах.
Каждый из представленных вариантов можно разделить на следующие типы, в зависимости от вида аллофона: 1) невокализованный — невокализованный (C – C); 2) невокализованный — вокализованный (С – V); 3) вокализованный — невокализованный (V – C); 4) вокализованный — вокализованный (V – V).
Основная задача выполнения данного шага - обеспечить плавность переходов (границ) между аллофонами.
Достигается это путём сохранения перехода, который является естественным для данной звуковой единицы и плавным наложением одной звуковой единицы на другую.
Схематично данные операции представлены на рис.6.22 и 6.23 для вариантов стыковки типа "точный контекст — точный контекст», «близкий (дальний) контекст — точный контекст", "точный контекст — близкий (дальний) контекст" соответственно.
Рис.6.22. Слева - стыковка типа "точный контекст — точный контекст", справа - типа "близкий (дальний) контекст — точный контекст" 
В вариантах стыковки типа "точный — точный" и "точный — близкий" для контекстов типа C – C, V – C в случае если длина невокализованного аллофона, содержащего "реальный" переход меньше чем 2/3 длины второго (правого) невокализованного аллофона, то перекрытие будет происходить по типу "близкий (дальний) — близкий (дальний)".
При реализации стыковки типа "близкий (дальний)- близкий (дальний) контексты" первый аллофон накладывается на второй на один период в вокализованном случае и на 20мс - в невокализованном.
6.5. Звуковые эффекты, используемые при синтезе речи 
Алгоритмы постобработки звука в системах синтеза речи должны удовлетворять следующим требованиям: не искажать речевой сигнал; иметь минимальный набор регулируемых параметров; небольшой временной ресурс реализации.
Рис.6.2 3. Стыковка типа "точный контекст — близкий (дальний) контекст" 
6.5.1. Параметрический эквалайзер 
Большое распространение в области обработки речевых сигналов имеют устройства, позволяющие изменять тембр сигнала.
Это объясняется тем, что частотная характеристика сигнала, особенно после модификации, требует коррекции в той или иной степени.
Для выравнивания спектральной картины необходимы частотные корректоры.
Наиболее распространенным частотным корректором является эквалайзер.
Он представляет собой многополосный регулятор тембра, позволяющий осуществлять одновременную и взаимонезависимую регулировку усиления или ослабления сигнала сразу в нескольких частотных полосах.
Первые эквалайзеры были довольно простыми устройствами.
Как правило, это была одна ручка, при помощи которой можно было вырезать определенную часть высокочастотной составляющей.
Первый "серьезный" эквалайзер был изобретен Питером Бэксендалом (Peter J Baxandall).
Его эквалайзер предусматривал отдельную регуляцию низких и высоких частот, причем можно было делать как усиление, так и ослабление.
Регулятор оставался в своем среднем положении, если эквализации не требовалось.
Эквалайзеры делятся на два больших класса - графические эквалайзеры и параметрические эквалайзеры.
Первые из них являются многополосными регуляторами тембра с фиксированными полосами частот коррекции. В таких эквалайзерах имеется возможность регулировать только величину подъема и спада амплитудно-частотной характеристики (АЧХ).
Параметрические эквалайзеры позволяют регулировать, как ширину, так и усиление/ослабление сигнала в каждой полосе.
Это позволяет получить достаточно вариативную геометрию АЧХ.
При работе с эквалайзером очень важно понимать, что усиление какой-либо частотной полосы приводит к усилению общего уровня аудио сигнала, и чрезмерное усиление полос может зачастую привести к искажениям звукового сигнала.
В связи с этим ослабление «ненужных» частот зачастую дает более качественный результат, нежели усиление «нужных».
Поэтому эквалайзером следует пользоваться очень аккуратно и не использовать его, если в этом нет очевидной надобности.
Важный - диапазон регулировки.
Он обычно составляет плюс/минус 12 или 15 децибел.
Как правило, больше и не требуется
Золотое правило применения эквалайзера- "лучше меньше, да лучше".
Если вам нравится, как звучит речь в необработанном виде, то применение эквалайзера едва ли сделает ее еще лучше, а вот испортить может вполне.
Второе правило - серебряное - звучит так: "Лучше вычитать, а не добавлять".
Простейшим для реализации в системе синтеза речи представляется трехполосных параметрический эквалайзер.
Он представляет собой три параллельно включенных фильтра: фильтр нижних частот (ФНЧ), полосовой фильтр (ПФ) и фильтр верхних частот (ФВЧ).
Разбиение спектра на три полосы производится заданием пользователем левой и правой частот: F_L и F_R.
В каждой спектральной полосе предусмотрена независимая пользовательская регулировка усиления/ослабления:a_L,a_C,a_R.
Возникает вопрос выбора фильтров для реализации эквалайзера.
БИХ фильтры (фильтры с бесконечной импульсной характеристикой) требуют существенно меньших вычислительных затрат при фильтрации по сравнению с фильтрами с конечной импульсной характеристикой (КИХ фильтрами).
Расчет КИХ фильтров более сложен, чем расчет БИХ фильтров с аналогичными частотными характеристиками.
У БИХ фильтров неизбежны фазовые искажения, существенно влияющие на восприятие речевого сигнала.
Их легко исключить при использовании КИХ фильтров 
Возможна неустойчивость работы БИХ фильтра.
КИХ фильтры, реализуемые не рекурсивно, т. е. с помощью прямой свертки, всегда устойчивы.
Данные соображения позволяют сделать выбор в пользу реализации эквалайзера КИХ фильтрами.
На рис.6.2 4 и 6.2 5 представлены типовые АЧХ (амплитудно-частотная характеристика фильтра) для ФНЧ и полосового фильтра (64 коэффициента): 
Рис.6.2 4. АЧХ для фильтра нижних частот эквалайзера  
Рис.6.2 5. АЧХ для полосового (центрального) фильтра эквалайзера 
На рис.6.2 6 представлена схема работы выше описанного трехполосного эквалайзера для системы синтеза речи.
Рис.6.2 6. Схема работы трехполосного эквалайзера 
6.5.2. Ревербератор 
Реверберация (от латинского reverberatus, "повторный удар") - это процесс продолжения звучания после окончания звукового импульса или колебания благодаря отражениям звуковых волн от поверхностей.
Поэтому  ФНЧ ПФ ФВЧ   реверберация имеет место только в закрытых помещения х, хотя в особых условиях некоторые ее виды могут иметь место и на открытом пространстве (например, узкое горное ущелье, стадион, городская площадь и т.п.).
Различные реализации ревербераторов очень востребованы у специалистов, занимающихся обработкой музыкальных и речевых сигналов.
Эффект реверберации проявляется в более сочном гулком объемном звучании, обычно более приятном для восприятия, чем исходный «сухой» звук.
Простейший ревербератор для системы синтеза речи можно реализовать, как набор линий задержки ∆_1,∆_2,..∆_N, каждая со своим весовым коэффициентом a_i.
В реальных условиях эффект реверберации наблюдается не сразу - ведь звуковой волне первоначально требуется какое-то время для того, чтобы достигнуть отражающей поверхности и возвратиться обратно.
Линии задержки как раз имитируют этот процесс.
Типичное значение первой задержки: 20-50 мс.
Перед добавлением к исходному сигналу, выход ревербератора фильтруется ФНЧ фильтром первого порядка.
Желаемое соотношение между "сухим" и обработанным сигналом задается коэффициентом применимости ревербератора: γ∈(0,1).
Ревербератор обычно может работать в двух режимах: ручной и с использованием готовой конфигурации.
Для ручного режима регулируется первая (минимальная) задержка ∆_i, а величины остальных задержек определяются автоматически: ∆_i=∆_1 2^((1-i)/N),2≤i≤N Практически, ручной режим реализует так называемый эффект задержки («эффект эхо»).
Режим готовой конфигурации предусматривает использование заранее рассчитанных параметров, имитирующих акустическую модель определенного помещения, например, «закрытая небольшая комната», «зал», «открытое прост ранство» и т.п. В этом случае все параметры задержек ∆_i и весовых коэффициентов a_i имеют свои уникальные значения.
На рис.6.2 7 приведена схема работы предложенного ревербератора.
7. СИНТЕЗ, ОСНОВАННЫЙ НА МОДЕЛЯХ 
Данный тип синтеза является гибридом подходов, основанных на правилах и речевом корпусе.
В этом случае происходит описание звуковой базы данных параметрической моделью.
Параметры (например, спектральные характеристики, частота основного тона, длительность и т.д.) обобщаются множеством статистических моделей, представляющими собой скрытые марковские модели, которые содержат в себе шаблоны речевых элементов.
Рис.6.2 7. Схема работы ревербератора 
Определение параметров речевого сигнала происходит на основе критерия максимального правдоподобия применительно к этим моделям.
Так для модели, имеющей N состояний с M компонентами на состояние и вектор наблюдений 𝐎=[o1′,o2′,…,oT′]′, функция правдоподобия наблюдения ot состояния Sj определяется следующим выражением: p(ot|qj=Sj)=∑ cjmbjm(ot)=∑ cjmN(ot;μimΣjm)M m=1M m=1  (7.1) Для модели, вектор наблюдения которой не содержит динамических признаков, т.е. ot=ct, наблюдения, которые максимизируют p(O|λ), являются наиболее вероятной последовательностью: p(O|λ)=p(O|Q,λ)P(Q|λ), (7.2) где Q – последовательность состояний и компонент: Q=(q,i), q={q1,q2,…,qT}, i={i1,i2,…,iT}.
После получения Q, максимизация p(O|λ) и p(O|Q,λ) выполняется следующим образом: logp(O|Q,λ)=log∏ bqt,it(ot)=−1 2(O−μ)′Σ−1(O−μ)−T t=1 1 2∑ log|Σqt|T t=1 −1 2TDlog(2π), (7.3) где μ=[μq1,i1′,μq2,i2′,…,μqT,iT′]′; Σ=diag [Σq1,i1,Σq2,i2,…,ΣqT,iT], T – длина последовательности векторов наблюдений в количестве фреймов; D – размерность статических векторов параметров.
В выражении 7.3 logp(O|Q,λ) максимален, если его производная равна 0: ∂(logp(O|Q,λ)) ∂с=−Σ−1с+Σ−1μ=0   … ФНЧ   Таким образом, максимум достигается при c = μ, т.е., другими словами, наиболее вероятная получаемая последовательность наблюдений является последовательностью векторов средних, независимо от ковариации Σ. При введении динамических признаков, вектор наблюдений можно определить, как ot=[ct′,∆ct′,∆2ct′]′, где: ∆(n)ct= ∑ ω(n)(τ)ct+τ L(n) τ=−L(n) (n=0,1,2) При введении нового определения вектора признаков, выражение 7.3 примет следующий вид: logp(O|Q,λ)=(O−μ)′Σ−1(O−μ)−1 2log|Σ|−3TD 2log(2π) =(Wc−μ)′Σ−1(Wc−μ)−1 2log|Σ|−3TD 2log(2π) =e(c)−1 2log|Σ|−3TD 2log(2π) где:- μ и Σ определяются так же, как и в 7.3;- e(c)=(Wc−μ)′Σ−1(Wc−μ);- W=[ω1,ω2,…,ωT]′;- ωt=[ωt(0),ωt(1),ωt(2)];- ωt(n)=[OM×M,…,OM×M,ω(n)(−L(N))IM×M,…,ω(0)IM×M, …,ω(n)(L(N))IM×M,OM×M,…,OM×M] Минимизация выполняется следующим образом: ∂log(O|Q,λ) ∂c=0, (W′Σ−1W)c−W′Σ−1μ=0, (7.4) Выражение 7.4 можно представить в следующем виде: Rc=r, где: R=W′Σ−1W, r=W′Σ−1μ При решении данной задачи напрямую требуется O(T3M3) операций, однако существует более быстрый алгоритм, позволяющий существенно снизить вычислительную сложность вычислений. Синтез речи, основанный на моделях, представлен в системе HTS, являющейся единственной открытой системой.
Также подобные системы были реализованы в компании Microsoft и Whistler.
У истоков данного подхода к синтезу речи лежит концепция линейного предсказания значения текущего отсчета на основе линейной комбинации набора предшествующих ему отсчетов.
Данная концепция предполагает расчет коэффициентов авторегрессионного фильтра : σ Ap(z), Ap(z)=1+∑akz−kp k=1 путем минимизации сигнала остатка, который вычисляется путем вычитания из исходного сигнала сигнала, предсказанного AR фильтром.
Минимизация выполняется путем решения уравнения: ∑ ajφx(i−j)=−φx(i),(i=1,…,p)p j=1, где p – порядок предсказания, соответствующий количеству резонансных частот, порождаемых фильтром, от 0 до половины частоты дискретизации; ai – коэффициенты линейного предсказания, первый коэффициент a0=1; φ x(i) – значение автокорреляционной функции сигнала x. Исходный речевой сигнал получается путем подач и сигнала остатка на AR фильтр, параметры которого содержатся в моделях той или иной звуковой единицы.
В основе такого подхода лежит упрощенная модель человеческого вокального тракта, где сигнал возбуждение и форма вокального тракта моделируются независимо.
Предполагается, что функция возбуждения бывает двух типов: вокализованная, порождаемая периодическими единичными импульсами, моделирующими открытие гортани; невокализованная, порождаемая белым шумом, моделирующим шумовые завихрения воздуха в гортани.
Стоит отметить, что такая замена оригинальной функции возбуждения ведет к существенному снижению естественности синтезированной речи.
Далее сигнал возбуждения (вокальная и шумовая составляющие) обрабатывается дополнительными фильтрами, моделирующими вокальный тракт, а именно: гортань (G(z)), носовые и ротовые особенности (V(z)), губы (R(z)), как представлено на рисунке 7.1.
Данный набор фильтров можно представить следующим выражением G(z)V(z)R(z)=1 (1−αz−1)(1−βz−1)B ∏ (1+b1,kz−1+b2,kz−2)K k=1c(1−z−1) ≈σ Ap(z) (1.5) При моделировании вокализованной речи, количество коэффициентов AR фильтра p следует выбирать, основываясь на следующих соотношениях: 2 коэффициента для формирования гортанных искажений, 2 – на каждую форманту, которые условно распределены через каждые 100 0 Гц спектра.
Таким образом, например, при частоте дискретизации 22050Гц следует выбрать 24-25 коэффициентов.
Рис.7.1. Модель речевого тракта 
По своей природе речевой сигнал является нестационарным.
Однако, для применения техники на основе линейного предсказания необходимо иметь стационарный сигнал.
Для этого речь разбивают на перекрывающиеся между собой окна, внутри которых, в силу их небольшой длины, предполагается, что сигнал стационарен.
Выбор размера такого окна (фрейма) и величины смещения напрямую влияет на вычислительную сложность алгоритма (меньшее смещение фреймов ведет к большему их количеству для обработки) и точность извлечения параметров (в зависимости от степени стационарности речи на некотором участке, использование большего или меньшего окна ведет к более точному вычислению параметров).
Рис.7.2. Синтез речи на основе линейного предсказания 
На рисунке 7.2 представлена общая схема генерации речи не основе линейного предсказания: сигнал возбуждения, представленный либо единичными импульсами в случае вокализованного фрейма, либо белым шумом в случае невокализованного фрейма, является входом для AR фильтра, моделирующего вокальный тракт.
Применение такой параметрической модели позволяет далее легко производить какие-либо просодические модификации.
Так, частота основного тона определяется расстоянием между последовательными единичными импульсами, которое может быть задано требуемым значением T. Для сохранения исходной амплитуды сигнала используется масштабный коэффициент σ 0, который должен быть заменен на σ=σ0√T0 T, где T0 – длина периода исходного сигнала.
Длина сигнала модифицируется путем дублирования или удаления фреймов.
Так же благодаря применению параметрической модели, гладкость спектральных характеристик может быть достигнута путем линейной интерполяции сегментов.
Готовые фреймы складываются с перекрытием, формируя итоговый сигнал.
Главным недостатком применения подхода на основе линейного предсказания является сильная роботизированность голоса.
Эксперименты показываю т, что данный недостаток не может быть устранен путем увеличения порядка модели.
В первую очередь, отдельное моделирование параметров фильтра и сигнала возбуждения может ухудшить результат, если их характеристики изменяются независимо.
Также, функция возбуждения, которая имеет различную природу для вокализованных и невокализованных звуков, не может должным образом моделировать смешанные звуки, такие как, например, «в».
Однако стоит отметить, что последнее можно исправить путем применения смешанной функции возбуждения [ссылки на статьи про смешанный сигнал возбуждения].
По сравнению с методом Unit Selection, подход, в основе которого лежат модели речи, имеет следующие преимущества и недостатки.
1. Автоматическое обучение параметров моделей, которое возможно выполнять на относительно небольшом речевом материале, позволяет существенно сократить объем требуемой памяти, а также позволяет разрабатывать новый голос за гораздо меньшее время.
2. Речь, полученная на основе моделей, более искусственна, однако в ней не наблюдаются разрывы, присутствующие при конкатенативном синтезе.
Кроме того, при применении технологии Unit Selection качество синтеза существенно ухудшается в случае отсутствия подходящего звукового элемента в базе данных.
При применении моделей отсутствующие в обучающей выборке звуковые элементы синтезируются на основе средних значений, максимально приближенных к требуемым, благодаря применению технологии кластеризации контекстов, основанной на деревьях.
Это позволяет добиться разборчивости при ограниченном количестве контекстов.
3. Синтез, основанный на моделях, позволяет легко модифицировать характеристики голоса путем применения адаптации/интерполяции диктора, в то время как метод Unit Selection порождает речь, стиль которой не может быть отличен от стиля, представленного в речевом корпусе.
В заключение, достоинства и недостатки подходов, основанного на моделях и Unit Selection, можно представить в виде таблицы (таблица 7.1).
Таблица 7.1.
Достоинства и недостатки современных подходов к синтезу речи Критерий сравнения Подход Unit Selection Основанный на моделях подход Сложность создания нового голоса Высокая Невысокая Объем требуемой памяти Высокий Невысокий Качество синтезируемой речи Высокое Роботизированная речь Ощущение разрывов речи Возможно Менее вероятно Качество синтеза элементов, отсутствующих в звуковом корпусе Низкое Высокое Стиль речи Фиксирован Может быть модифицирован В качестве схем, объединяющих данные подходы, могут применяться следующие: генерация физических параметров звуковых элементов на основе скрытых марковских моделей для последующего вычисления стоимости замены для метода Unit Selection ; использование значений вероятностей переходов как «стоимости»; использование звуковых элементов, размер которых сопоставим с размером состояния модели; использование статистических моделей для вычисления стоимости связи между элементами.
Сами по себе системы статистического моделирования развиваются независимо от систем синтез речи.
Они включают в себя такие приложения, как кодирование речи, преобразование параметров диктора и «подделку» речи диктора в задачах идентификации/верификации.
ЛИТЕРАТУРА 
1. Брызгунова Е.А. (1982) Интонация // Русская грамматика. Том 1. М. Наука. С. 96-122.
2. Фланаган Дж. Анализ, синтез и восприятие речи. М.: Связь, 1968.
3. Taylor P. Text-to-Speech Synthesis. Cambridge University Press, 2009. 474 p. 
4. Лобанов Б.М., Цирульник Л. И. Компьютерный синтез и клонирование речи. Минск, «Белорусская Наука», 2008. 316 с. 
5. Hunt A., Black A. Unit Selection in a Concatenative Speech Synthesis System Using a Large Speech Database// Proceedings of ICASSP 96, 1996, pp. 373- 376.
6. Tokuda K., Masuko T., Yamada T. An algorithm for speech parameter generation from continuous m ixture HMMs with dynamic features // Proceedings of Eurospeech-1995, 1995.
7. Loh W. -Y. Classiﬁcation and Regression Tree Methods // Encyclopedia of Statistics in Quality and Reliability, Wiley. 2008. P. 315-323.
8. Breiman L. Cutler A. Random Forests [Электронный ресурс], Режим доступа: http://www.stat.berkeley.edu/~breiman /RandomForests /cc_home.htm, свобо-дный. – Загл. с экрана. – Яз. англ. 
9. Чистиков П.Г., Хомицевич О.Г., Рыбин С.В. Статистические методы определения мест и длительностей пауз в система х синтеза речи. Изв. вузов. Приборостроение. Тематический выпуск "Речевые информационные системы" (в печати).
10. Хомицевич О.Г., Рыбин С.В., Аничкин И.М. Использование лингвистического анализа для нормализации текста и снятия омонимии в системе синтеза русск ой речи. Изв. вузов. Приборостроение. Тематический выпуск "Речевые информационные системы". 2013. №2. С. 42-46.
11. Аничкин И.М., Чистиков П.Г. Формализация правил автоматического снятия омонимии в системе синтеза речи по тексту // Труды XXXVIII международной филологической конференции, 2008.
12. Fujisaki H. Dynamic characteristics of voice fundamental frequency in speech and singing // Production of Speech. N.Y. 1983.
13. Pierrehumbert, J. (1980) The phonology and phonetics of English intonation. PhD thesis, MIT. Distributed 1988, Indiana University Linguistics Club.
14. Black A.W., Hunt A.J. Unit Selection in a Concatenative Speech Synthesis Using a Large Speech Database // In Proceedings of ICASSP 96. Atlanta, Georgia, 1996. Vol. 1, pp. 373-376.
15. Conkie A. A robust unit selection system for speech synthesis // In Proceedings of Joint Meeting of ASA, EAA and DAGA. Berlin, Germany, 1999. Paper 1PSCB-10. 16. Vepa J. Join Cost for Unit Selection Speech Synthesis. University of Edinburgh, 2004.
17. Чистиков П.Г., Рыбин С.В. "П роблемы естественности речевого сигнала в системах синтеза", журнал "Информационные технологии в образовании", Санкт-Петербург, 2011.
18. Moulines E., Verhelst W. "Time-domain and frequency-domain techniques for prosodic modification of speech in Speech Coding and Synthesis", pp. 519–555, Netherland, 1995.
19. Главатских И.А., Чистиков П.Г. "Метод модификации физических параметров речевого сигнала на основе периодосинхронно го Фурье- анализа", труды XXXVII международной филологической конференции, формальные м етоды анализа русской речи, Россия, 2009.
20. Rafael C. D. de Paiva, Luiz W. P. Biscainho and Sergio L. Netto "On the application of RLS adaptive filtering for voice pitch modification", in proceedings of the 10th International Conference on Digital Audio Eff ects, France, 2007.
21. Taylor P. Text-to-Speech Synthesis. Cambridge University Press; 1 edition, 2009.
Миссия университета – генерация передовых знаний, внедрение инновационных разработок и подготовка элитных кадров, способных действовать в условиях быстро меняющегося мира и обеспечивать опережающее развитие науки, технологий и других областей для содействия решению актуальных задач.
КАФЕДРА РЕЧЕВЫХ ИНФОРМАЦИОННЫХ СИСТЕМ 
О кафедре Кафедра речевых информационных систем (РИС) создана в 2011 году на факультете Информационных технологий и программирования (ФИТиП).
Организатором создания кафедры выступает «Центр речевых технологий» (www.speechpro.ru).
Заведующий – генеральный директор ООО «Центр речевых технологий», кандидат технических наук Хитров Михаил Васильевич, вице-президент консорциума «Российские речевые технологии», член ISCA, IEEE.
Кафедра РИС обеспечивает подготовку докторантов, аспирантов и магистров.
Для тех, кто имеет высшее образование, но хотел бы связать свое будущее с речевыми технология ми, имеются курсы дополнительного профессионального образования.
Обучение на кафедре Кафедра «Речевые информационные системы» (базовая кафедра «Центра речевых технологий») Санкт-Петербургского национального исследовательского университета информационных технологий, механики и оптики (ИТМО) в рамках направления 230400.68 «Информационные системы и технологии» открывает прием в магистратуру по новой образовательной программе 230400.68.04 «Речевые информационные системы».
Срок обучения 2 года.
Обучение завершается защитой магистерской диссертации.
Целевая установка магистратуры – подготовка специалистов, способных участвовать в исследовательской и проектной работе в области речевых информационных технологий со специализацией в направлениях распознавания и синтеза речи, распознавания личностей по голосу, мультимодальной биометрии, в области проектирования и разработки информационных систем и программного обеспечения.
Область профессиональной деятельности выпускников кафедры РИС включает: исследование, разработка, внедрение речевых информационных технологий и систем; методы и алгоритмы цифровой обработки речевых сигналов; автоматизированные системы обработки речевых сигналов; программное обеспечение автоматизированных речевых информационных систем; системы автоматизированного проектирования программных и аппаратных средств для речевых информационных систем и информационной поддержки таких средств.
Объектами профессиональной деятельности выпускников кафедры РИС являются: информационные процессы, технологии, системы и сети, предназначенные для обработки, распознавания, синтеза речевых сигналов; инструментальное (математическое, информационное, техническое, лингвистическое, программное, эргономическое, организационное и правовое) обеспечение речевых информационных систем; способы и методы проектирования, отладки, производства и эксплуатации информационных технологий и систем в областях обработки, распознавания, синтеза речевых сигналов, телекоммуникации, связи, инфокоммуникации, медицины.
Широкий профиль подготовки, знание универсальных методов исследования и проектирования информационных систем, практические навыки работы с современным программным обеспечением – все это позволяет выпускникам кафедры найти работу в научных институтах и университетах, в фирмах, на производственных предприятиях, а также в коммерческих структурах.
Студентам, которые хорошо проявляют себя в учебе, предлагается работа в ООО «Центр речевых технологий».
Учебный план предусматривает, в частности, следующие курсы: Информационные технологии: Систем ный анализ и моделирование информационных процессов и систем; Проектирование информационных систем; Организация проектирования и разработки программного обеспечения распределенных систем; Организация проектирования и разработки программного обеспечения вст роенных систем; Тестирования программного обеспечения; Управление качеством разработки программного обеспечения.
Речевые технологии: Цифровая обработка сигналов; Цифровая обработка речевых сигналов; Математическое моделирование и теория принятия решений; Распознавание образов; Распознавание и синтез речи; Распознавание диктора (говорящего по голосу); Мультимодальные биометрические системы.
К преподаванию привлекаются ведущие специалисты «Центра речевых технологий», преподаватели НИУ ИТМО, а также специалисты, работающие в известных научных, производственных и коммерческих организациях.
Рыбин Сергей Витальевич СИНТЕЗ РЕЧИ Учебное пособие  В авторской редакции Редакционно-издательский отдел НИУ ИТМО Зав. РИО     Н.Ф. Гусарова Подписано к печати Заказ № 3227 Тираж 50 Отпечатано на ризографе                        Редакционно-издательский отдел Университета ИТМО 197101, Санкт-Петербург, Кронверкский пр., 49
И.Б. Тампель, А.А. Карпов АВТОМАТИЧЕСКОЕ РАСПОЗНАВАНИЕ РЕЧИ Учебное пособие Санкт-Петербург 2017 УНИВЕРСИТЕТ ИТМО И.Б. Тампель, А.А. Карпов АВТОМАТИЧЕСКОЕ РАСПОЗНАВАНИЕ РЕЧИ Учебное пособие  РЕКОМЕДОВАНО К ИСПОЛЬЗОВАНИЮ В УНИВЕРСИТЕТЕ ИТМО по направлению подготовки «информационные системы и технологии» в качестве учебно го пособия для реализации основных образовательных программ высшего образования магистратуры      Санкт-Петербург 2017  Тампель И.Б., Карпов А.А.
АВТОМАТИЧЕСКОЕ РАСПОЗНАВАНИЕ РЕЧИ.
Учебное пособие.
СПб: Университет ИТМО, 201 7.
– 152 с. В учебном пособии рассматривают ся методы автоматического распознавания речи.
Материал пособия разбит на 1 6 разделов.
Первые два раздела посвящены вопросам речеобразования и восприятия слуховой системой.
В каждом разделе приведены краткие теоретические и/или практические сведения.
Пособие может быть использовано при подготовке магистров по направлению 09.04.02 ИНФОРМАЦИОННЫЕ СИСТЕМЫ И ТЕХНОЛОГИИ и аспирантов.
Рецензент: к.т.н. Кореневский М.Л. Рекомендовано к печати Ученым с оветом факультета Информационных технологий и программирования 21.10.2017 г., протокол № 10 Университет ИТМО – ведущий вуз России в области информационных и фотонных технологий, один из немногих российских вузов, получивших в 2009 году статус национального исследовательского университета.
С 2013 года Университет ИТМО – участник программы повышения конкурентоспособности российских университетов среди ведущих мировых научно-образовательных центров, известной как проект «5 в 100».
Цель Университета ИТМО – становление исследовательского университета мирового уровня, предпринимательского по типу, ориентированного на интернационализацию всех направлений деятельности.
Университет ИТМО, 2017 СПИИРАН, 2017 И.Б. Тампель, А.А. Карпов, 2017 
Содержание стр. 
Введение………………………………………………………………………….5 
1. РЕЧЕОБРАЗОВАНИЕ ……………………………………………………….. 6 
1.1. Физиология речеобразования ……………………………………………… 6 
1.1.1. Процесс образования звуков с голосовым возбуждением …………….. 8 
1.2. Передаточная функция голосового тракта ……………………………….. 10 
1.2.1. Расчёт передаточной функции с помощью электроаналогий ………… 13 
1.3. Турбулентный и импульсный источники звука ………………………….14 
1.4. Носовые согласные ………………………………………………………… 15 
1.5. Выводы ……………………………………………………………………… 15 
2. СЛУХОВАЯ СИСТЕМА…………………………………….……………..... 23 
2.1. Строение уха человека ……………………………………………………... 23 
2.2. Маскировка. Восприятие высоты звука …………………………………... 26 
2.3. Восприятие громкости звука. Кривая равной громкости ……………….. 28 
2.4. Адаптация …………………………………………………………………… 29 
2.5. Физиологические методы обработки сигналов …………………………... 31 
2.6. Выводы ……………………………………………………………………… 35 
3. ПРИЗНАКИ РЕЧЕВОГО СИГНАЛА ДЛЯ РАСПОЗНАВАНИ Я РЕЧИ.... 37 
4. КОЛИЧЕСТВЕННАЯ ОЦЕНКА СИСТЕМ РАСПОЗНАВАНИЯ РЕЧИ … 42 
4.1. Показатели оценки качества распознавания речи..………..………..…...42 
4.2. Показатели оценки скорости распознавания речи……………………….. 46
5. МЕТОД ДИНАМИЧЕСКОГО ПРОГРАММИРОВАНИЯ ДЛЯ РАСПОЗНАВАНИЯ РЕЧИ……………………………… …………….. ……… 48 
5.1. Меры близости в пространстве признаков ……………………………….. 50 
6. РАСПОЗНАВАНИЕ РЕЧИ С ПОМОЩЬЮ СКРЫТЫХ МАРКОВСКИХ МОДЕЛЕЙ ………………………………………………………………………. 53 
6.1. Алгоритм «Вперёд-Назад»……………… ………………….. …………......  56 
6.2. Алгоритм Витерби …………………………………………………………. 59 
6.3. Алгоритм Баума-Уэлша …………………………………………………….60 
7. НЕОДНОРОДНАЯ МАРКОВСКАЯ МОДЕЛЬ ……………………………..  64 
8. ПРОБЛЕМА ВЫБОРА ЕДИНИЦ ФОНЕТИЧЕСКОГО УРОВНЯ ………..  67 
8.1. Кластеризация на основе дерева решений ………………………………...  68 
8.2. Управляемый данными метод построения состояний ……………………  70 
9. МЕТОДЫ НОРМАЛИЗАЦИИ И АДАПТАЦИИ …………………………..  74 
9.1. Вычитание среднего кепстра ……………………………………………….76 
9.2. Адаптация акустических моделей к шуму векторны ми рядами Тейлора  78 
9.3. Байесовская адаптация ……………………………………………………..  82 
9.4. Линейная регрессия максимума правдоподобия …………………………  83 
9.5. Метод собственных дикторов ……………………………………………...  86 
9.6. Нормализация признаков по длине голосового тракта …………………..  86 
10. ДИСКРИМИНАНТНЫЕ МЕТОДЫ ………………………………………..  91 
10.1. Долговременные  признаки ……………………………………………….92 
11. УСЛОВНЫЕ СЛУЧАЙНЫЕ ПОЛЯ………………….…………………….96 
12. НЕЙРОННЫЕ СЕТИ ……………… ……………………… ………………...  99
12.1. Глубокие нейронные сети………………………………………………… 100 
12.2. Рекуррентные нейронные сети…………………………………………… 102 
12.3. Нормализация и адаптация нейронных сетей…………………………… 105 
12.3.1. Методы линейного преобразования……………………………………. 107 
12.3.2. Методы ограниченного обучения………………………………………. 109 
12.3.3. Методы подпространств…………………… …………………………… 111 
13. МОДЕЛИ ЯЗЫКА…………………………………………………………... 113 
13.1. Использование условных вероятностей………………………………….114 
13.2. Статистическое сглаживание …………………………………………….. 115 
13.3. Классовые модели ………………………………………………………… 116 
13.4. Морфемные модели ………………………………………………………. 117 
13.5. Синтаксические и семантические модели ……………………………..... 117 
13.6. Модели темы высказывания ………………………………………………  119 
13.7. Модели языка на основе нейронных сетей……………………………… 119 
14. ДЕКОДЕР……………………………………………………………………. 123 
14.1. Организация лексикона в виде префиксного дерева…………………… 124 
14.2. Использование взвешенных конечных автоматов ……………………… 125 
14.3. Использование взвешенных преобразователей с конечным числом состояний………………………………………………….…………………….. 126 
15. ПРОБЛЕМА ВНЕСЛОВАРНЫХ СЛОВ …………………………………... 128 
15.1. Использование моделей заполнения …………………………………….. 129 
15.2. Использование фиксированных комбинаций фонем…………………… 130 
15.3 Использование нескольких систем распознавания ……………………… 131 
16. АУДИОВИЗУАЛЬНОЕ РАСПОЗНАВАНИЕ РЕЧИ …………………...... 133
16.1. Способы объединения аудио- и видеомодальностей речи………….......133 
16.2. Методы аудиовизуального моделирования и распознавания речи…..... 137
ЛИТЕРАТУРА …......…......…......…......…......…......…......…......…......….......  142
Введение 
Автоматическое распознавание речи является динамично развивающимся направлением в области искусственного интеллекта.
За последние полвека в данной области достигнуты значительные успехи – имеется множество коммерческих приложений, которые делают вложения в данную область оправданными и выгодными.
Среди таких приложений, в первую очередь, можно отметить внедрение call-центров или IVR-систем (Interactive Voice Response) – систем автоматического доступа к информации, минуя оператора.
В современных call-центрах вопросы формулируются пользователем на естественном языке, и ответ синтезируется компьютером также на языке пользователя.
Внедрение call-центров позволило высвободить огромное количество операторов и улучшить качество обслуживания во многих аэропортах и на железнодорожных вокзалах.
Системы автоматического распознавания речи широко применяются в медицинских исследованиях, требующих ввода информации, когда руки оператора заняты (рентгеновские), или когда требуется управлять автономными аппаратами исследования внутренних органов.
Даже заполнение медицинских карт средним персоналом в продвинутых медицинских учреждениях ведётся голосом.
Важной областью применения систем автоматического распознавания и синтеза речи является помощь людям с инвалидностью, как с проблемами опорно-двигательного аппарата, так и слабовидящим (ассистивные технологии).
Следует отметить, что в России медицинские приложения систем автоматического распознавания речи практически не реализованы, что оставляет огромное поле деятельности для разработчиков.
Несмотря на значительные успехи, главная цель исследований, которая изначально подразумевалась свободное общение человека и «машины» пока не достигнута.
Развитие направления выявило новые трудности, бросающие вызов исследователям на современном этапе, когда задача распознавания речи смыкается с проблемой понимания смысла сообщения и требует привлечения научной психологии.
Первые два раздела пособия посвящены вопросам речеобразования и восприятия.
Очевидно, что понимание структуры речевого сигнала и лежащих в его основе движений речеобразующих органов может помочь в решении задачи автоматического распознавания речи.
В ещё большей степени это относится к пониманию вопросов, связанных с восприятием звуков вообще и речевых звуков в частности.
Очень важным вопросом, на который предстоит ответить в ходе изучения речеобразования и восприятия является вопрос о признаках, или параметрах речевого сигнала, которые содержат информацию, достаточную для распознавания речи.
Очевидно, по самому своему смыслу, эти параметры должны являться следствием сознательно контролируемых движений речевых органов.
Очевидно также, что выделение э тих параметров должно являться главной задачей слуховой системы при распознавании речи.1.
РЕЧЕОБРАЗОВАНИЕ 1.1.
Физиология речеобразования Процесс речеобразования иллюстрируется на рис. 1.1. и 1.2.
Благодаря создаваемому в лёгких давлению, поток воздуха устремляется в голосовой тракт, проходит через голосовые складки, может устремляться в носовую полость (если нёбная занавеска открыта) и выходит в открытое пространство, минуя возможные зубные и губные сужения.
Рис.1.1. Речевой аппарат человека [1].
Речь представляет собой звуковые колебания воздуха в диапазоне частот от 70-100 Гц до нескольких килогерц.
Для того чтобы в выходящем воздушном потоке возникли колебания с такими частотами, необходимо наличие источника звука на пути воздушного потока.
Источником звука могут являться: 
1. Голосовые складки; 
2. Турбулентный шум в сужении; 
3. Шум внезапно высвободившегося воздуха при смычке (импульсный).
Рис.1.2. Схематическое изображение речевого аппарата и функциональных узлов речевого тракта человека [1].
Места сужения или смычки могут быть разными для разных языков (так, в ряде языков существу ют необычные для русского языка звуки, источником которых является гортанная смычка, то есть взрыв, образующийся при размыкании голосовых складок).
При образовании звука /х/ и шепотной речи шумовым источником являются сведенные, но не колеблющиеся голосовые складки.
В соответствии с типом источника речевые звуки подразделяются на классы: 1.
Гласные – источником звука являются только голосовые складки, проход в носовую полость перекрыт небной занавеской; 2.
Щелевые (фрикативные) согласные – источником звука является турбулентный шум в сужении (глухие согласные /ф/, /с/, /ш/,..), или дополнительно голосовые ск ладки (звонкие /в/, /з/, /ж/,..).
3. Взрывные согласные – источником звука является шум взрыва (глухие /п/, /т/, /к/), или дополнительно импульсы голосовых складок (звонкие /б/, /д/, /г/).
Кроме указанных существуют звуки, которые требуют отдельной классификации: 
1. Носовые согласные.
Характеризуются тем, что излучение полностью или частично осуществляется через нос.
Забегая вперед, отметим, что передаточная функция голосового тракта содержит только полюса, то есть обладает только резонансами; пр и наличии боковой полости или параллельной ветви передаточная функция содержит также нули.
2. Русское /р/ возбуждается голосовыми складками, однако звук модулируется дрожанием кончика языка.
3. Звуки, получающиеся сочетанием рассмотренных выше (при меры на основе общеамериканского диалекта): Полугласные / j/ you, /w/ we; Плавные /r/ read, /l/ let.
4. Звуки, характеризующиеся динамическим характером произнесения: дифтонги /eI/ say, /Iu/ new, / ɔI/ boy, /aU/ out, /aI/ I, /oU/ go; аффрикаты /tʃ/ chew, /d ƺ/ jar.
1.1.1. Процесс образования звуков с голосовым возбуждением 
Голосовые складки (связки) (рис. 1.3) колеблются при продувании через них потока воздуха под действием эффекта Бернулли [1].
Частота колебаний голосовых складок называется основным тоном (pitch).
Для полноты обзора следует упомянуть о таком этническом феномене, как двухголосое тувинское пение.
В данном случае имеется два периодических источника возбуждения.
Один из них – обычные голосовые складки, а второй – либо ложные складки (утолщения, расположенные над голосовыми складками), либо верхушка пищевода (известно, что люди с повреждёнными голосовыми складками овладевают «пищеводной речью»).
Частота колебаний голосовых складок при обычной речи находится в пределах 60-180 Гц для мужчин, 160-350 Гц для женщин и 200-650 Гц для детей (указанные границы чисто ориентировочные).При пении частота колебаний голосовых складок может достигать 2 кГц.
Форма импульсов объемной скорости (скорость потока, умноженная на площадь сечения в данной точке величина, сохраняющаяся вдоль всего тракта), исходящих из голосовой щели, неплохо аппроксимируется треугольником или полуволной синуса (рис. 1.4).
При этом скважность может достигать 40%, то есть складки могут смыкаться на продолжительное время за счет упругости тканей при столкновении.
Для подобных импульсов спектр спадает приблизительно со скоростью 12 дБ/окт.
Понятно, что чем более угловатую форму имеют импульсы, и чем больше разрывов имеет производная объемной скорости, тем бол ее длинный хвост будет у спектра.
Форма импульсов голосового источника, в основном, и определяет тембр голоса и «полетность» певческого голоса.
Рис.1.3. Схематическое изображение органов подгортанной системы человека [1].
Рис.1.4. Кривые изменения площади голосовой щели (а), кривые объёмной скорости для одного периода основного тона (б) [1].
1.2. Передаточная функция голосового тракта Передаточная функция голосового тракта рассчитывается, исходя из того, что для значимых для восприятия частот (<4000 Гц) акустическая волна с достаточной точностью является плоской.
Распространение звука в этом случае описывается одномерным (зависящим от координаты вдоль оси тракта) уравнением Вебстера: 1/(S(x))  ∂/∂x [S(x)  ∂p/∂x]=1/c^2   (∂^2 p)/(∂t^2 ) (1.1) где S(x) – площадь поперечного сечения как функция расстояния от голосового источника по оси тракта, p – звуковое давление, с – скорость звука, t – время.
Даже в одномерном случае для голосового тракта уравнение Вебстера можно решить только численно.
При этом не учитывается импеданс стенок тракта и потери энергии на границах и на трение.
Для волновода постоянного сечения (S(x)=const) уравнение Вебстера превращается в одномерное волновое уравнение для плоской волны в пространстве: (∂^2 p)/(∂x^2 )=1/c^2   (∂^2 p)/(∂t^2 ) (1.2) Такое же по форме уравнение справедливо для объёмной скорости u. Давление и скорость связаны уравнениями:,-∂p/∂x=p ∂u/∂t -∂u/∂x=1/(pc^2 )  ∂p/∂t (1.3) где ρ – плотность воздуха.
Общее решение уравнения (1.2) имеет вид: p(x,t)=φ(t-x/c)ψ(t+x/c) где Ψ и ϕ – функции, определяемые из начальных или граничных условий.
Если сечение голосового тракта постоянно по длине, его можно представить в первом приближении как волновод, закрытый со стороны связок и открытый со стороны губ. При этом в точке x=0 (на связках) скорость и частная производная давления по х равны 0.
В точке x=L (на губах) звуковое давление и частная производная скорости по х равны 0, где L – длина тракта.
На основании (1.2), (1.3) и (1.4) будем искать скорость и звуковое давление в виде: u(x,t)=u^+ (t-x/c)-u^- (t+x/c)  p(x,t)=〖p[u〗^+ (t-x/c)-u^- (t+x/c)] (1.5) Найдём выражение для скорости при условии, что на закрытом конце возбуждаются колебания) u(t)=sin(wt).
(1.6) Будем искать решение для скорости в виде:.u(x,t)=a[sin⁡(φ+ω(t-x/c))+sin⁡(ψ+ω(t+x/c))](1.7)
Используя формулу суммы синусов, получим: u(x,t)=2asin⁡((φ+ω)/2+ ωt)cos⁡((φ-ω)/2-  ωx/c)(1.8) 
Учитывая (1.6), находим: ϕ+Ψ =0, или ϕ=–Ψ, отсюда получаем:u(x,t)=2 asin⁡(ωt)cos⁡(φ-  ωx/c).(1.9) 
Поскольку (∂u(x,t)  )/∂x |_(x=1)=2a ω/c  sin⁡(ωt)  sin⁡(φ- ωl/c)=0  (1.10) можем положить ϕ=ωl/c.Подставляя значение ϕ в (1.9) и снова учитывая (1.6), получим формулу для скорости: u(x,t)=(ω/c  sin⁡(ωt)cos⁡(ω(l-x)/c))/(cos⁡(ωl/c)). (1.11) 
Таким образом, видим, что возбуждая объёмную скорость с единичной амплитудой на входе волновода, на выходе имеем скорость с амплитудой 1/cos(ωl/c).
Отношение выходной скорости к входной называется передаточной функцией.
Если принять скорость звука в 350 м/с (скорость во влажном воздухе при 360), а длину голосового тракта 17.5 см (длина мужского тракта), то график передаточной функции будет иметь вид (рис.1.5.):  
Рис.1.5. Передаточная функция волновода постоянного сечения без потерь [2].
Максимумам в спектре соответствуют стоячие волны с длиной волны:λ(n)=l/(1/4+n/2),n=0,1… 1.12) или частотами:F(n)=c/4l (1+2n),n-0,1.. (1.13) 
Для принятых выше скорости звука и длины голосового тракта частоты будут равны: 500, 1500, 2500, 3500 Гц.
Отметим, что многоточие не имеет особого практического смысла, поскольку выше 4000–5000 Гц длина волны становится сравнимой с поперечными размерами тракта и, следовательно, уравнение Вебстера не годится для описания процессов распространения звука.
Если учесть потери в среде, в голосовой щели и на стенках голосового тракта, излучение на губах, то максимумы перестанут быть бесконечными и слегка сместятся, но общая картина качественно не изменится.
Делаем важный вывод: передаточная функция голосового тракта и, следовательно, речевой сигнал характеризуются максимумами в спектре, отстоящими друг от друга на несколько сотен герц и зависящими, в основном, от формы голосового тракта.
Для гласных эти максимумы называются формантами.
1.2.1. Расчёт передаточной функции с помощью электроаналогий 
Голосовой тракт произвольной формы можно представить как на бор цилиндрических секций.
Каждую секцию можно описать как электрическую цепь:  
Рис.1.6. Электрический эквивалент цилиндрического отрезка трубы [1].
Аналогом звукового давления является напряжение, аналогом скорости – ток.
L=p/S(1+s/D√(μ/4πfp)), где ρ – плотность воздуха, S – площадь поперечного сечения секции, D – периметр сечения секции, f – частота, μ – коэффициент вязкости; 
R=D/S^2 √πfpμ  C=S/(pc^2) G=D n-1/(pc^2)√πλf/c_pp, где η – адиабатическая постоянная (7/5), λ – теплопроводность воздуха, cp – удельная теплоёмкость.
Нагрузочное излучение через рот аппроксимируется нагрузкой на круглый поршень в сфере или бесконечном плоском экране.
Z≈s(πar/c)^2+i 16/3  fa/c;  2πfa/c≪1, где a – радиус поршня.
Распространение звука вокруг голо вы рассчитывают как излучение пульсирующей сферы.
Звуковое давление как функция расстояния от центра сферы r имеет вид: p(r)=i (2πfpa^2 u_0)/r e^(-i 2πf/c r), где a – радиус сферы, u0 – амплитуда скорости колебаний сферы.
Звуковое давление при прочих равных параметрах растёт пропорционально частоте f, то есть со скоростью 6 децибел на октаву.
Расчёты, проводимые с вышеприведёнными формулами, дают хорошее совпадение с экспериментальными данными.
Расчётные и измеренные значения формант приведены в таблице 1.1.
Таблица 1.1.
Расчётные (для закрытой голосовой щели) и измеренные [3] значения формант гласных русского языка.
Гласные/ форманты F1 F2 F3 (расчётн.)(измер.) (расчётн.)
(измер.) (расчётн.)
(измер.) /у/ 301 300 619 625 2388 2500 /о/ 549 535 859 780 2368 2500 /а/ 686 700 1075 1080 2432 2600 /е/ 453 440 1954 1800 2737 2550 /и/ 278 240 2263 2250 2924 3200 /ы/ 326 300 1477 1480 2314 2230 1.3.
Турбулентный и импульсный источники звука При образовании звуков /ш/, /ф/, /х/, /c/… источником служит турбулентный шум в сужении голосового тракта или складок.
Спектр шумового источника имеет плоскую вершину, частота которой приблизительно равна Sv2.0, где ν – скорость потока в сужении, S – площадь сужения.
Звонкие фрикативные /ж/, /в/, /з/… образуются при одновременной работе голосового и турбулентного источников.
При этом в сужении турбулентный шум модулируется импульсами голосового источника.
Взрывные согласные /п/, /б/, /к/, /г/, /т/, /д/ образуются при полной смычке в некоторой области голосового тракта, повышении давления за смычкой и резком высвобождении воздуха в результате открытия смычки.
Взрыв сопровождается фрикативным шумом.1.4.
Носовые согласные При опускании нёбной занавески звук проникает в носовую полость и излучается через нос.
Голосовой тракт может быть полностью или частично закрыт на губах.
Так формируются носовые (назальные) согласные звуки.
Расчёт методом электроаналогий показывает, что в этом случае основной особенностью передаточной функции является ноль или антиформанта на частоте около 2 кГц.
1.5. Выводы 
Таким образом, речевой сигнал представляет собой квазипериодический сигнал для вокализованных и случайный шум в области 3–6 кГц для шумовых и взрывных звуков.
Спектральные максимумы чередуются через 300–700 Гц по частоте и через 150–200мс по времени (силлабическая частота).
В качестве иллюстрации на рис. 1.7. приведены огибающая и «видимая речь » (изображение спектра на плоскости, где по оси абсцисс отложено врем я, по оси ординат – частота, а амплитуда отображается степенью зачернения или цветом) продолжительных высказываний для широкополосного (окно=6мс) и узкополосного (окно=30мс) анализа Фурье.
Заметим, что горизонтальные полосы на узкополосном спектре представ ляют собой гармоники основного тона.
На широкополосном спектре они сливаются из-за невысокого разрешения по частоте, однако форманты при этом выделяются лучше.
Зададимся, наконец, вопросом, ради которого приводились все эти факты: какие параметры речевого сигнала являются существенными для передачи смысла сообщения, то есть являются характеристикой данного языка, а какие представляют индивидуальные особенности говорящего?
(Этот же вопрос в несколько другой плоскости будет задан в разделе «Слуховая система».)
Данные психоакустики позволяют считать установленным, что существенными для восприятия являются значения энергии колебаний в довольно широких спектральных зонах.
Так, для восприятия гласных существенны максимумы огибающей спектра, как правило, совпадающие с формантами.
Считается, что для идентификации гласной достаточно двух первых формант, поэтому гласные часто изображают на плоскости F1, F2, где они образуют вытянутый треугольник.
Возможно, третья форманта является дополнительным, избыточным признаком гласной.
Некоторым подтверждением этой точки зрения является факт, что человек может научиться читать видимую речь (см. роман А.Солженицына «В круге первом»).
Заранее отметим, что это умение никак не отразилось на создании систем автоматического распознавания речи.
Либо виртуозы чтения не могут вербализовать правила, которыми они пользуются при чтении, то есть используются столь же мало познанные процессы зрительного восприятия, либо ошибки распознавания по видимой речи больше, чем в системах автоматического распознавания (уровень ошибок распознавания по видимой речи никто не измерял).
На рис. 1.8. приведены примеры видимой речи для различных слогов.
Дополнительно приведены число переходов огибающей через ноль, полнаяэнергия и низкочастотная энергия (125–750 Гц).
На основании этих рисунков можно получить представление о характере спектров для отдельных звуков речи и их сочетаний.
Рис. 1.7. Пример широко и узкополосного анализа Фурье речевого сигнала, Fs – частота квантования, T w – длина окна анализа [4].
Рис. 1.8. Примеры спектрограмм и огибающих речевого сигнала [2].
В заключение данного раздела рассмотрим качественную сторону речеобразования и обсудим понятие «фонема».
Первоначально введенный Ф. де Соссюром в 1879 году термин «фонема» (phoneme) практически не отличался от языковедческого термина «звук», как единицы речи, подвергающейся научному анализу.
Современное понимание этого термина фонетистами ближе к определению, данному Бодуэном де Куртенэ: «Фонема есть цельное, неделимое во в ремени представление звука языка».
Отметим два момента: 
1. Фонема не есть физическая реализация звука, а является представлением звука в сознании (абстракцией).
2. Фонема воплощает идею атомарности, примененную к субъективному представлению о речи.
Явная неконструктивность данного определения с точки зрения технической реализации всегда вызывала споры и многочисленные варианты фонетической классификации.
Технические специалисты, используя термин «фонема », вкладывали в него свои представления о речеобразовании и восприятии, доводя понятие до вульгарного: «фонема – это то, что я могу определить и выделить на своем приборе».
Надо отметить, что и среди самих фонетистов нет единства в представлении о фонеме: московская и ленинградская (петербургская) школы фонетики предлагали алфавиты фонем, существенно отличающиеся по размеру.
Наверное, для того, чтобы избежать этих конфликтов, технические специалисты ввели термин «фон» (phone) – конкретная реализация фонемы.
Фоны, принадлежащие к одной фонеме, называются аллофонами.
Идея атомарности была очень привлекательной с технической точки зрения: достаточно установить характеристики или признаки составляющих речь «атомов» или «кирпичиков», и задача автоматического распознавания речи решена.
Поиски признаков и выделение инвариантных к диктору и контексту «фонем » продолжались вплоть до 90-х, но успеха не имели (в том смысле, что ни одна из систем распознавания речи, насколько нам известно, результаты этих изысканий не использует).
Попробуем объяснить отсутствие успеха в поиске локализованных во времени фонем, рассмотрев процесс речеобразования на качественном уровне.
В процессе речеобразования речевые органы человека – губы, язык, нижняя челюсть, небная занавеска совершают движения, скорость которых зависит от силы мышц и массы самого органа.
Скорость эта близка к предельной (иначе скороговорки не были бы популярны).
Исследования показывают, что в естественной речи органы практически никогда не занимают положений, характерных для изолированно произнесенных звуков, а лишь обозначают движение в нужном направлении, соответственно, и форманты обозначают движение в нужном направлении.
Очевидно, что движение в сторону, характерную для данной фонемы, зависит от предшествовавших и, как показывают эксперименты, даже последующих фонем, то есть, речевой аппарат может готовиться к произнесению некоторых звуков заранее.
Этот эффект называется коартикуляцией.
Взаимовлияние фонем не ограничивается соседями, а может распространяться на несколько соседних фонем.
Можно вычислить, насколько огромное число возможных сочетаний, скажем, хотя бы по три фонемы, существует для языка.
Если к этому добавить нерешенную проблему признаков, инвариантны х к диктору, то число возможных представлений фонемы становится настолько огромным, что о выуживании признаков вручную не может быть и речи.
Таким образом, по-прежнему используя аналогию с атомами, а лучше с квантами, можно заметить, что фонема скорее име ет «волновую » природу, то есть ее признаки «размазаны » по протяженному во времени отрезку, причем признаки различных фонем накладываются друг на друга.
В разделе «Распознавание речи» будет рассказано, как эту проблему пытаются решить с помощью теории вероятностей и искусственных нейронных сетей.
Для того чтобы минимизировать вариативность фонов, вводят понятия “трифон” и “бифон”.
Трифон, это фон, для которого определены предыдущая и последующая фонемы.
Для бифона определен а только одна из соседних фонем.
Бифоны используют в начале и конце фрагментов речи, или когда данных для надёжной оценки трифона недостаточно.
Легко подсчитать, что если количество используемых фонем равно N, то количество трифонов будет равно N3.
Аналогично вводят понятие “пентафон” для пяти последовательных фонем, однако для оценки параметров пентафонов требуются столь огромные базы данных, что в системах распознавания речи они практически не используются.
Все аспекты проблем, связанных с оценкой и использованием трифонов и бифонов будут рассмотрены в разделах 6, 7, 8, посвящённых использованию марковской модели для распознавания речи.
2. СЛУХОВАЯ СИСТЕМА 
2.1. Строение уха человека 
Изучение слухового анализатора важно для задачи автоматического распознавания речи, поскольку неадекватная обработка сигнала может привести к потере части полезных признаков и к излишне подробному представлению другой части.
В данном разделе ограничимся поверхностными сведениями о работе периферической слуховой системы, достаточными для обсуждения вопроса о том, какие параметры звукового сигнала способна выделять слуховая система.
Традиционно периферическую слуховую систему представляют как последовательно включенные наружное, среднее и внутреннее ухо (рис. 2.1).
Наружное ухо – это звуковой проход к среднему, среднее – это система слуховых косточек, передающих звуковые колебания к внутреннему уху.
Поскольку диаметры каналов невелики, звуковую волну в интересующем нас диапазоне частот можно рассматривать как плоскую.
Амплитудно-частотные характеристики системы наружного уха приведены на рис. 2.2.
Виден максимум в районе 3–4 кГц.
Этот максимум обеспечивает наибольшую чувствительность слуховой системы в данном диапазоне.
Внутреннее ухо представляет собой очень интересный, с точки зрения спектрального анализа, прибор.
Это конусная, трехполостная, разделенная мембраной (базилярной) вдоль трубка, заполненная перилимфой, жидкостью, близкой по свойствам к плазме крови.
Длина улитки около 35 мм, и она, в соответствии с названием, закручена в спираль, делая 2.5 оборота.
Как и в случае вокального тракта, поперечными колебаниями в расчетах пренебрегают и считают, что «закрученность » не оказывает влияния на распространение колебаний.
И нтересно, что подобную конструкцию, в целях экономии места, уже давно скопировали в радиолокационных системах.
Скорость распространения звука в улитке замедляется по сравнению с воздухом почти в 100 раз, так что задержка между возбуждением на входе в улитку и в апикальном конце от одного стимула составляет 7 –8 мс.
Базилярная мембрана улитки содержит около 3–4 тыс. «внутренних волосковых клеток», которые вырабатывают нервные импульсы в ответ на возбуждение.
Возбуждение вызывается деформацией мембраны в процессе колебаний, но только в одном направлении.
Таким образом, внутренние волосковые клетки осуществляют однополупериодное выпрямление сигнала.
Можно сказать, что выпрямление «мягкое», поскольку во время второй половины колебания волосковые клетки уменьшают спонтанную активность.
Описанный механизм действует до часто т в 3–4 кГц.
Далее на возбуждение волосковые клетки отвечают повышением общей активности.
Как и нейроны, внутренние волосковые клетки имеют некоторый уровень насыщения, то есть не могут генерировать в единицу времени сколь угодно большое количество импульс ов, Рис. 2.1.
Строение периферической слуховой системы [1].
и поэтому осуществляют компрессию сигнала.
Существует предположение, подкрепленное экспериментальными данными [1], что улитка – это активная система, то есть, в ответ на звуковое возбуждение она начинает совершать колебания с энергией, большей, чем ей доставляется извне звуковой волной.
Ответственность за этот механизм возлагают на «наружные волосковые клетки», которые также размещаются на базилярной мембране и которых в несколько раз больше, чем внутренних.
Активность улитки проявляется только на малых уровнях возбуждения; видимо, это механизм нормализации уровня звука.
Не вдаваясь в хитросплетения восходящих нервных путей, поскольку это выходит за рамки рассматриваемой темы, отметим одну важную особенность слуховой системы – ее «тонотопическую» организацию.
Этот термин означает, что области возбуждения, соответствующие близким частотам звукового стимула, находятся в близких (в прямом топологическом смысле) областях базилярной мембраны и сохраняют эту близость вплоть до высших разделов слуховой системы.
Очевидно, данный факт является самым веским аргументом в пользу рассмотрения слуховой системы как спектрального анализатора.
Интересной особенностью улитки является то, что колебания различных частот проникают в нее на разную глубину.
Высокочастотные (10 кГц и более) очень быстро затухают около входа в улитку.
Чем ниже частота, тем дальше проходит сигнал.
Сигналы с частотой 800 Гц и ниже проходят до конца улитки.
Рис. 2.2. Амплитудно-частотные характеристики системы наружного уха [6]  
Рис. 2.3. Зависимость амплитудно-частотной характеристики точки базилярной мембраны улитки мартышки от уровня звукового давления входного сигнала у барабанной перепонки [6] 
Амплитудно-частотная характеристика элемента улитки с некоторой характеристической частотой имеет пологий подъем (6 дБ/окт) со стороны низких частот (то есть все частоты ниже характеристической представлены в колебании данного участка базилярной мембраны, но с уменьшающимся весом) и резкий спад (по различным данным от 100 до 300 дБ/окт) в сторону высоких частот (рис. 2.3.).
Таким образом, главный элемент периферической слуховой системы, не обладая сильными резонансными свойствами, представляет скорей линию задержки или временной анализатор.
2.2. Маскировка. Восприятие высоты звука 
Под маскировкой понимают повышение порога слышимости звука (стимула) в присутствии других звуков (маскеров).
Маскирующие звуки могут предшествовать (прямая), действовать одновременно (одновременная) и следовать за сигналом (обратная маскировка).
Стимулы и маскеры могут иметь различную структуру.
Обычно используют узкополосный шум, либо тональные посылки.
Результаты экспериментов довольно трудно распространить на произвольные сигналы, поскольку для процессов слуховой обработки характерны нелинейности.
Эксперименты с тональными стимулами и маскерами позволили построить кривые, определяющие пороги слышимости по частоте и времени, которые использовались при разработке алгоритмов сжатия MPEG.
Рассмотрим два эксперимента по маскировке, которые дают представление об особенностях восприятия звука на разных частотах.
Зафиксируем частоту стимула и будем маскировать его узкополосным шумом с центром на частоте стимула, постепенно расширяя полосу маскера, оставляя неизменной спектральную плотность энергии.
Оказывается, что, начиная с некоторой ширины, дальнейшее расширение маскера по спектру не приводит к существенному увеличению порога восприятия, то есть незначительно усиливает маскировку.
Ширина такой полосы как функция частоты называется критической полосой.
Результат можно грубо интерпретировать так, как если бы в слуховой системе присутствовали близкие к прямоугольным или трапециевидным частотные фильтры, в границах которых стимулы суммируются, при этом стимулы, разделённые более чем на критическую полосу, обрабатываются независимо.
В диапазоне от 100 Гц до 16 кГц насчитывается 24 критические полосы (см. табл. 2.1.).
Шкала критических полос называется шкалой «барк».
Второй эксперимент состоит в том, что слушателю предъявляют гармонический сигнал и просят выставить частоту второго сигнала так, чтобы на его субъективный взгляд она была в два раза выше или ниже, чем частота предъявленного.
Полученная таким об разом шкала называется шкалой « мел» (см. табл. 2.1.).
Таблица 2.1.
Шкалы частот барк и мел [4] Частоты в барках и мелах можно рассчитывать по следующим формулам:Bark(f)=13 arctan⁡(0.00076f)+3.5arctan⁡((f/7500)^2). Mel(f)=1125ln⁡(1+f/700) (2.1) 
Восприятие высоты звука зависит от его интенсивности (рис. 2.4.), поэтому, для получения однозначных результатов, интенсивность стимулов во втором эксперименте фиксируют в 40 дБ.
Рис. 2.4. Зависимость высоты звука от его интенсивности [5].
Из данных таблицы 2.1 следует, что слуховая система склонна рассматривать низкочастотные компоненты речи более подробно, чем высокочастотные – начиная с 1000 Гц, шкалы можно считать близкими к логарифмическим.
Отсюда следует, что при обработке речи для распознавания можно сэкономить на представлении высоких частот в наборе признаков.
2.3. Восприятие громкости звука.
Кривая равной громкости Чувствительность слуховой системы к различным частотам различна.
Из всего диапазона 20 –20000 Гц самые низкие пороги восприятия относятся к диапазону 2 –5 кГц, в основном, благодаря передаточной функции слухового канала (рис. 2.2.).
Рис. 2.5. Кривые равной громкости (http://hyperphysics.phy- astr.gsu.edu/hbase/sound/eqloud.html).
Громкость – это субъективная оценка интенсивности звука.
Ощущение громкости зависит н е только от частоты, но и от длительности звукового стимула.
Для количественной оценки абсолютной громкости была принята специальная единица сон.
Громкость в 1 сон – это громкость синусоидального звука с частотой 1000 Гц и уровнем 40 дБ относительно звуков ого давления 2 ·10-5 Па.
Количественно зависимость воспринимаемой громкости звука S (в сонах) и его звукового давления может быть представлена в следующем виде:,Cp^0,6 где С – постоянная, зависящая от частоты сигнала.
Отсюда следует, что при увеличении звукового давления на 10 дБ, громкость возрастает в 2 раза.
Таким образом, зависимость между звуковым давлением и ощущением громкости носит логарифмический характер.
2.4. Адаптация 
Реакция слуховой системы на продолжительный стимул начинается резким всплеском, далее следует спад с выходом на постоянный уровень.
При выключении стимула система на некоторое время снижает спонтанный уровень импульсации (рис. 2.6.).
На рис. 2.7 представлена простейшая модель адаптации.
Здесь блок 1 – безынерционная компрессионная нелинейность, например:  Рис. 2.6.
Огибающая реакции на посылку тона с прямоугольной огибающей.
Параметр кривых – интенсивность входного сигнала в дБ от условного порога [6].
Рис. 2.7. Простейшая модель адаптации [6].
y=(1+Alogx/x_0)^p при x>=x0, A и p – константы, использовались 0,5 и 4,6, y = x при 0<= x<=x_0, y = 0  при x<0; блок 2 – фильтр нижних частот (интегратор): t∂r/∂t + r=y, или в дискретном виде: r_i =(1-T/t)r_i-1 + T/t y_i, где T – период квантования, τ – постоянная времени; блок 3 – блок переменного коэффициента передачи:g=y/(α+βr), где α и β – константы.
Адаптация является важным свойством всех физиологических систем.
При восприятии звуков адаптация позволяет повысить помехоустойчивость сообщения за счёт подавления стационарных шумов.
2.5. Физиологические методы обработки сигналов 
Возникает вопрос: каким образом, обладая столь низк ой спектральной избирательностью на уровне каждого участка базилярной мембраны, слуховая система в целом демонстрирует очень высокую избирательность?
Ведь эксперименты по восприятию тональных стимулов, а также характер музыки, сформировавшейся у всех народов, наличие людей с абсолютным слухом и присутствие хоть какого-то слуха у остальных не оставляют сомнения, что разрешающая способность по спектру слуховой системы достаточно высока.
Для объяснения этого феномена привлекается уже упомянутый факт активного возбуждения улитки.
Кроме того, обострение спектра можно объяснить, используя нелинейные методы параллельной обработки, присущие нервной системе вообще.
Исключительно для того, чтобы стало понятно, какие интересные возможности предоставляют эти методы, при ведём следующий механизм: В 1984 г. С. Сенеф [7] предложила, как тогда казалось, довольно искусственный, но эффективный метод обострения спектральных максимумов для гребенки фильтров (рис. 2.8.).
Метод заключался в том, что в каждом спектральном канале после однополупериодного детектирования делалось ответвление, сигнал в котором задерживался на половину периода 1/(2* Fc), где Fc – характеристическая частота данного канала.
После этого сигнал в задержанном канале вычитался из сигнала в основном канале с последующим детектированием и сглаживанием фильтром нижних частот (ФНЧ).
Очевидно, что если частота сигнала равна характеристической частоте данного фильтра, то ослабления сигнала не произойдет, поскольку сдвинутый на половину периода сигнал будет вычитаться в те отрезки времени, когда в основном канале сигнал и так равен нулю по причине предварительного детектирования.
В остальных каналах сигнал будет ослабляться.
Понятно, что этот метод позволяет добиться более высокой разрешающей способности гребенки фильтров без увеличения времени переходных процессов.
Покажем, что этот метод может реализоваться в периферической слуховой системе без привлечения искусственного построения, связанного с ответвлением и задержкой в каждом канале.
Действительно, в соответствии с рассмотренным механизмом работы улитки, каждая частотная компонента присутствует во всех областях улитки и в Рис. 2.8.
Обобщённый синхронный детектор [7], τ = 1/(2 Fc).
соответствующих нервных каналах для участков базилярной мембраны с характеристическими частотами выше рассматриваемой, то есть, ближе к входу в улитку (рис. 2.9.).
Рис. 2.9. Пространственно-временной отклик слуховой системы на чистый тон 1,5 кГц 
Вопрос в том, как подводится сигнал, задержанный на половину периода относительно характеристической частоты к данному каналу?
В нервной системе существует универсальный механизм «латерального торможения », согласно которому сигнал в каждом канале собирает возбуждения в непосредственной близости от себя со знаком плюс и вычитает сигналы, проходящие по каналам в некотором отдалении.
Весовую функцию, как функцию от частоты, или, в соответствии с принципом тонотопической организации, расстояния от данного канал а, можно представить как разность двух Гауссовых функций с различной дисперсией (рис.2.10).
Таким образом, каждый канал своим сигналом старается подавить соседей, которые соответствуют минимуму весовой функции латерального торможения, и,  Рис.2.10.
Весовая функция латерального торможения  аналогично, подавляется какими-то другими каналами.
Остается убедиться, что для улитки минимумы весовой функции латерального торможения могут соответствовать сигналу, сдвинутому на половину периода характеристической частоты.
Заметим, что низкочастотная ветвь весовой функции роли не играет, поскольку она соответствует участкам базилярной мембраны, удаленным от входа по отношению к рассматриваемому участку, а туда сигнал с рассматриваемой характеристической частотой не доходит по причине быстрого затухания (рис. 2.3).
Экспериментальные данные показывают, что характерные для улитки ширины спектральных полос каналов полностью соответствуют описанному механизму, то есть, минимум весовой функции латерального торможения для участка базилярной мембраны с рассматриваемой характеристической частотой вполне может приходиться на участок мембраны, для которой время прихода сигнала меньше на половину периода данной характеристической частоты.
Механизм компрессии или ограничения амплит уды усиливает обостряющий эффект данного механизма, поскольку основной и задержанный сигнал ы сближаются по амплитуде, и подавление сигналов в каналах происходит более эффективно.
Попытаемся понять, каким образом в нейронных сетях слуховой системы могут возникать довольно экзотические весовые функции типа латерального торможения.
Надо отметить, что в зрительном восприятии были обнаружены весовые функций ещё более изощрённого вида, названные «габоровскими» по имени их первооткрывателя.
Габоровские функции напоминают двумерные вейвлеты.
Основой нейронных сетей является нейрон, упрощённая модель которого изображена на рис.2.11 В качестве функции активации F(s) могут использоваться: 1. линейная функция, 2. пороговая функция, 3. сигмоидальная функция (1/(1+ exp(-(ks-a)), гиперболический тангенс,…) рис.2.12.
Рис. 2.11. Модель нейрона  
Рис. 2.12. Сигмоидальная функция 
Нейроны могут объединяться в нейронные сети самым произвольным образом.
Наиболее распространённой структурой в моделях является «перцептрон» – несколько плоских слоёв нейронов, в которых каждый нейрон собирает сигналы со всех нейронов предыдущего слоя и передаёт на все нейроны следующего.
Связи между нейронами одного слоя и обратные связи запрещены.
Подробнее о нейронных сетях будет рассказано в разделах, посвящённых современным методам распознавания.
В слуховой системе нейроны первого слоя собирают информацию с волосковых клеток на некотором протяжении базилярной мембраны.
Плотность синапсов (см. рис. 2.11), то есть их количество на единицу длины базилярной мембраны, убывает по мере удаления от нейрона приблизительно в соответствии с гауссовой функцией.
Ширина захвата нейронов, или дисперсия этой гауссовой функции, различна для различных нейронов.
Допустим, что все входы некоторых нейронов первого слоя возбуждающие.
Уже на втором слое (первом скрытом) могут быть нейроны, которые суммируют сигналы от нейронов первого слоя с различными знаками.
Если ширины захвата этих нейронов различны, то произойдёт вычитание гауссовых функций, что и приведёт к образованию весовой функции типа латерального торможения относительно сигналов волосковых клеток.
Нетрудно представить, что на следующих слоях нейронной сети с помощью этого же механизма можно получить весовые функции типа габоровских или вейвлетов.
Также очевидно, что нейроны всё более высоких слоёв получают информацию о колебаниях всё более широких участков базилярной мембраны, то есть могут анализировать и сравнивать всё более широкие полосы спектра.
Данное рассмотрение не претендует на точность с точки зрения физиологии, но даёт представление о возможных методах обработки сигналов слуховой системой.
2.6. Выводы 
Требования к признакам и процедурам обработки на основе первых двух глав руководства можно сформулировать следующим образом: • использовать спектральный анализ с логарифмической шкалой; • использовать логарифмическую компрессию громкости; • разработать процедуру адапта ции/АРУ; • использовать совместно спектральные и временн ые признаки; • использовать совместно долговременный анализ (до 500 мс) и кратковременный анализ (20 –25 мс).
Вернёмся к вопросу о признаках, которые содержат информацию, достаточную для автоматического распознавания речи.
Хотя само изложение материала подсказывает, что этот вопрос уже решён в пользу спектрального преобразования (или связанных с ним методов), остановимся на нём подробнее.
То, что преобразование Фурье, как и любое другое об ратимое преобразование, сохраняет информацию, заключённую в исходном сигнале, конечно, не является аргументом в пользу спектра Фурье.
Важно, чтобы выделяемые признаки несли в каком-то смысле инвариантную к дикторам и внешним условиям информацию о словесном содержании сообщения и отбрасывали нерелевантную информацию.
Отметим, что для распознавания используется только амплитудная составляющая спектра, то есть исходное количество информации безболезненно уменьшается в два раза, поскольку фазовая составляющая н е воспринимается слуховой системой.
К сожалению, используемые при распознавании речи признаки не реализуют в полной мере идею инвариантности и, по-видимому, никогда не смогут её реализовать, поскольку расщепление информации на словесное содержание, индивид уальность диктора и внешние шумы – это работа «высших уровней».
Спектр Фурье, по-видимому, является единственным кандидатом на роль первичных признаков системы распознавания.
Этот вывод представляется естественным, если сопоставить параметры речевой систем ы, которые контролирует человек и параметры акустического сигнала, к которым слуховая система относится особенно «бережно».
Вспомним, как происходит постановка произношения при обучении иностранным языкам – преподаватель обращает внимание на форму и вытяну тость губ, положение нижней челюсти (зубов) относительно кончика языка, положение тела языка и положение нёбной занавески при произнесении назализованных звуков.
Все эти факторы определяют форму голосового тракта, положение смычек и сужений, то есть параметров, определяющих текущую огибающую спектра сигнала.
Слуховая система, в свою очередь, с помощью улитки производит спектральный анализ сигнала.
Что особенно важно, информация о спектральных компонентах проходит до соответствующих отделов центральной нервной системы, не перемешиваясь и подвергаясь лишь некоторой очистке и обострению.
Эта особенность периферической слуховой системы, получившая название «тонотопической организации», доказывает, что амплитудный спектр сигнала является основой для распознавания речи человеком и, следовательно, для автоматических систем распознавания речи.
Аргументы, указывающие, что можно получить признаки абстрактными методами, не опираясь на изучение слуховой системы, поскольку человек научился выполнять некоторые функции живых существ лучше них, используя другие методы, например: «самолёты ведь не машут крыльями!», в данном случае, по-видимому, не проходят [8].
Надо учесть, что до сих пор человек моделировал взаимодействие живых существ с внешним миром в соответствии с хорошо изученными физическими законами.
Очевидно, что человек полетел бы, даже если бы на Земле не водились птицы и прочие летающие, к которым он испытывал зависть.
Аналогичное утверждение относительно распознавания речи полностью лишено смысла.
Автоматическое распознавание речи является уникальной задачей моделирования системы, развившейся в процессе филогенеза за несколько сотен тысяч лет.
В этой системе «передатчик» и «приёмник» сигналов управляются одним органом – мозгом, и в течение этих тысячелетий они нашли «общий язык», который и надо расшифровать.
Очень сомнительно, что расшифровка допускает альтернативные варианты, тем более сомнительно, что они лучше «натуральных».
Очевидным следствием этих рассуждений является также то, что перспективные системы распознавания речи должны в максимальной степени использовать достижения физиологии в области слухового анализа.
Однако следует иметь в виду, что слепое копирование открытых механизмов восприятия может даже ухудшить распознавание, поскольку в живых системах механизмы обработки редко функционируют изолированно друг от друга.
Скорее речь может идти об общих принципах обработки информации в живых систем ах – многоэтапной иерархической обработке с использованием большого количества нейронов.
3. ПРИЗНАКИ РЕЧЕВОГО СИГНАЛА ДЛЯ РАСПОЗНАВАНИЯ РЕЧИ 
В данном разделе будут рассмотрены некоторые методы цифровой обработки речевых сигналов, в частности: 
1. Спектр Фурье.
2. Спектр Фурье в шкале мел.
3. Выход гребёнки цифровых фильтров.
4. Коэффициенты линейного предсказания.
5. Кепстр.
Для получения спектра Фурье используется алгоритм БПФ с длиной окна, соответствующей 2 –4 периодам основного тона, то есть около 20 мс.
При частоте квантования 10 –16 кГц окно обычно выбирается размером 256 отсчётов.
Обычно окна сдвигают на 10 мс, обеспечивая частоту следования векторов признаков 100 Гц.
Полезно использовать окно Хэмминга для ослабления искажений сигнала, вызванных применением к непрерывному сигналу конечного окна анализа, по формуле: S'(n) = [0.54 – 0.46 * cos(2*PI*n / (N–1))]*S(n),    (3.1) где n = 1,…,N, N – размерность окна, S(n) – отсчеты речевого сигнала.
Для перехода в шкалу м ел спектральные отсчёты в границах каждой спектральной полосы суммируют с некоторыми коэффициентами, представляющими окно, обычно, треугольное (рис.
3.1.).
Рис. 3.1. Гребёнка фильтров для суммирования спектральных отсчётов 
В качестве гребёнки цифровых фильтров используются рекурсивные фильтры второго порядка: yi=xi + c 1* yi-1 + c 2* yi-2,   (3.2) где c1 = 2*R*cos(2π*fp/F), c2 =-R*R, xi – отсчёты входного сигнала, yi – отсчёты выходного сигнала, F – частота квантования, fp – частота полюса фильтра, R – радиус полюса.
Ширина фильтра на уровне 0.5 от максимума по энергии приблизительно равна: f=F/2pi 1-R/sqrt(R)  (3.3)  
Рис. 3.2. Амплитудные характеристики гребёнки цифровых фильтров для δ=1-R<<1, с точностью до величин первого порядка по δ: f=F/2pi (1-R).
(3.4) Радиус полюсов фильтра R может равняться 1, что соответствует границе неустойчивости фильтра.
В этом случае анализ аналогичен оконному: через фильтр пропускается необходимое количество отсчётов, оценкой спектра является сумма модулей или квадратов выходов фильтра yi, после чего значения y обнуляются для приёма следующего фрагмента сигнала.
Если радиус меньше 1, то с его помощью можно регулировать добротность, или ширину фильтра.
Преимуществом гребёнки цифровых фильтров является то, что её можно сразу организовать в шкале мел.
На рис. 3.2. изображены характеристики гребёнки цифровых фильтров, использовавшиеся в системе распознавания команд, разработанной в Центр е Речевых Технологий.
Другим направлением спектрального анализа речи, отличным от Фурье анализа, является использование метода линейного предсказания.
Уже в конце 70-х годов многие зарубежные системы распознавания строились на использовании стандартных коэффициентов линейного предсказания (LP C).
Модель линейного предсказания речи предполагает, что передаточная функция голосового тракта представляется полюсным фильтром с передаточной функцией [9]:H(z)=1/(∑_(i=0)^p▒〖a_i z^(-i) 〗).
(3.5) где p – число полюсов и a0 = 1; Фильтр с такой передаточной функцией позволяет описать поведение сглаженного спектра речевого сигнала с хорошей точностью, за исключением назализованных звуков.
Коэффициенты фильтра { ai} – выбираются путем минимизации среднеквадратичной ошибки предсказания, просуммированной на окне анализа.
Автокорреляционный метод, позволяющий выполнить эту оптимизацию, заключается в следующем.
Для заданного окна отсчетов речевых сигналов {sn, n= 1,N}, первые p+1 членов автокорреляционной последовательности вычисляются по формуле: r_i=∑_(j=1)^(N-j)▒〖s_j s_(j+1) 〗,   (3.6) где i = 0,…, p; Коэффициенты фильтра вычисляют рекурсивно с использованием множества вспомогательных коэффициентов {kj}, которые могут быть интерпретированы как коэффициенты отражения эквивалентной акустической трубы и ошибки предсказания E, которая изначально равна r0.
Пусть { kj(i-1)} и { aj(i- 1)} будут коэффициентами отражения и коэффициентами для фильтра i-1 порядка соответственно, тогда фильтр порядка i может быть вычислен за три шага.
Вначале вычисляется новое множество коэффициентов отражения: kj(i) = kj(i-1)    (3.7) для j от 1 до i-1 и k_i^((i))={r_i+∑_(j=1)^(i-1)▒〖a_j^((i-1) ) r_(i-j) 〗}/E^((i-1)) (3.8) 
Затем пересчитывается энергия предсказания: E^((i) )=(1-k_i^((i) ) k_i^((i) ))E^((i-1) ). (3.9) 
В заключение вычисляются новые коэффициенты фильтра:a_j^((i) )=a_j^((i-1) )-k_i^((i) ) a_(i-j)^((i-1) ) (3.10) для j = 1, i-1 и a_i^((i) )=-k_i^((i) ).
(3.11) Этот процесс продолжается от i=1 до i = p, где p – требуемый порядок фильтра.
Обычно используется p = 12.
Альтернативой параметрам, основанным на коэффициентах линейного предсказания, является кепстр, полученный из спектра Фурье или коэффициентов линейного предсказания (LPCC).
Кепстр линейного предсказания может быть эффективно вычислен с помощью простой рекурсии: .
(3.12) Число кепстральных коэффициенто в необязательно должно быть равно числу коэффициентов фильтра.
Преимущество кепстральных коэффициентов в том, что они, как правило, декоррелированы.
Кроме того, кепстр позволяет раздел ить передаточную функцию передающего тракта и речь, поскольку они перемножаются в спектральной области и после логарифмирования оказываются аддитивными.
Однако существует небольшая проблема в том, что старшие коэффициенты кепстра имеют малые числовые значения, что может быть компенсировано введением весовых коэффициентов в соответствующую метрику сравнения.
Кепстр сигнала на основе спектра Фурье вычисляется путем применения косинусного Фурье преобразования к логарифму спектра: где si – логарифм спектра, N – количество отсчётов спектра, Ci,j – унитарная матрица косинусного преобразования.
Кепстральные коэффициенты, полученные приведённым способом из мел спектра Фурье (рис. 3.1), широко используются для распознавания с помощью марковских моделей (см. следующие разделы) и носят название MFCC (Mel- frequency cepstral coefficients).
Для того чтобы учесть динамику процесса, кепстральные коэффициенты дополняют дельта и дельта-дельта признаками, имеющими смысл дифференциала, коррелирующего со скоростью изменения признака.
Дельта признак для некоторой кепстральной «полосы» с номером j вычисляется следующим образом: где t – момент времени, k обычно принимает значение 2 или 3.
Аналогичная операция, применённая к дельта-признакам, даст дельта-дельта признаки.
Нетрудно заметить, что формула (3.1 4) описывает КИХ-фильтр (фильтр с конечной импульсной характеристикой).
Амплитудно-частотнаяхарактеристика такого фильтра для частоты следования признаков 100 Гц изображена на рис. 3.3.
Рис. 3.3. Амплитудная характеристика дельта преобразования второго порядка 
Заметим, что основными особенностями АЧХ являются: 1. устранение постоянной составляющей, 2. небольшое усиление компонент в области 10 –15 Гц, 3. небольшое ослабление высокочастотных компонент.
Полезность этих особенностей понятна – устранение постоянной составляющей увеличивает динамический диапазон, устраняет влияние АЧХ канала передачи, усиление в области 10 –15 Гц в некоторой степени соответствует идее усиления естественной силлабической (слоговой) частоты речи, ослабление высокочастотных компонент подавляет шумы в признаках.
Явное преследование этих целей позволяет достичь лучших результатов в распознавании, что доказал Х. Германский своей систем ой RASTA [10].
Обычно векторы признаков имеют большие размерности, причём многие их компоненты коррелируют, то есть признаки избыточны, что приводит к дополнительным ненужным вычислениям.
Для устранения этого недостатка часто используются методы понижения размерности (метод Карунена-Лоэва или метод главных компонент, факторный анализ, линейный дискриминантный анализ).
Линейный дискриминантный анализ, в отличие от метода Карунена- Лоэва, в явном виде моделирует различия между классами и пытается их усилить.
Факторный анализ строит признаки, основываясь на различиях между классами (используется, в основном, в задачах гуманитарного направления).
Методы понижения размерности были рассмотрены в разделе «Распознавание образов».
Отметим, что процедура получения кепстра в некоторой степени декоррелирует признаки.
Было замечено, что функции, определяющие линейные комбинации спектральных компонент, полученные методом Карунена-Лоэва, напоминают косинусы (по крайней мере, для первых компонент).
Это и навело на мысль использовать косинусное преобразование (3.13).
4. КОЛИЧЕСТВЕННАЯ ОЦЕНКА СИСТЕМ РАСПОЗНАВАНИЯ РЕЧИ 
Существуют различные по сложности и прикладному значению задачи распознавания: изолированных слов (команд); ключевых слов в потоке речи; связанной речи (тщательное проговаривание текста с паузами между словами); слитной речи (разделяют диктовку в узкой тематической области, и спонтанную речь, например, в диалоге между людьми).
Оценка системы, распознающей отдельные команды, не представляет каких-либо трудностей – количество неправильно распознанных команд делится на общее количество испытаний и получается процент ошибки.
Для систем, распознающих слитную речь, ситуация не столь проста.
Задача оценки систем распознавания речи нетривиальна, так как различные алгоритмы сравниваются на ограниченных базах данных, и каждый из них имеет настраиваемые параметры, да и результаты распознавания можно интерпретировать по-разному.
При этом объективное оценивание и сравнение систем распознавания речи важны как для разработчиков, так и для конечных пользователей систем.
Существует количественная методика оценки, которая применяется для сравнения и сопоставления различных систем распознавания, в ней различают такие понятия как: критерий, показатель и метод.
Критерий – предмет оценки или то, что нам нужно оценить (например, точность распознавания речи, скорость, робастность к шумам и т.д.).
Показатель (мера, метрика) определяет конкретное свойство, которое мы оцениваем для выбранного критерия оценки (например, процент правильно распознанных слов, время обработки сигнала, уровень максимально допустимого шума при сохранении работоспособности и т.п.).
Метод – способ определения соответствующего значения для данного показателя (сравнение распознанных слов с последовательностью сказанных слов, оценка времени обработки в секундах и т. д.).
Обычно при разработке систем автоматического распознавания речи используются три разных набора данных: обучающий (“train”), отладочный (“dev”) и оценочный /тестовый (“ eval”).
Обучающий набор данных (обычно это наибольшая часть речевых данных) используется только для создания и обучения моделей системы.
Отладочный набор данных используется для настройки и адаптации параметров автоматической системы перед финальной стадией оценки, этот набор данных должен иметь тот же формат, что и тестовые данные.
Оценочные данные содержат речевые данные, которые не использовались для обучения и настройки системы, и доступны только при финальной оценке системы.
Выделают два основных критерия при оценке работы систем распознавания речи, которые далее рассмотрены детально: качество распознавания и скорость обработки [11].
4.1 Показатели оценки качества распознавания речи Для систем автоматического распознавания речи основным показа телем оценки по критерию качества является точность распознавания, которая определяется как процент правильно распознанных слов (WRR — Word Recognition Rate) или, наоборот, неправильно распознанных слов (WER — Word Error Rate).
Иногда также используется показатель ошибок распознавания фраз/предложений (SER — Sentence Error Rate), который является важным в диалоговых системах, где корректировка гипотезы распознавания невозможна в отличие от задачи диктовки текста.
В последнее время в качестве основного показателя точности работы систем распознавания речи используется WER (его абсолютное или относительное значение), если сравниваются различные системы распознавания речи.
Поскольку с развитием речевых технологий показатель WER все более приближается к нулю, т о значение улучшения WER более наглядно, чем улучшение точности распознавания слов.
Метод определения WER состоит в выравнивании двух текстовых строк (первая — это результат распознавания, а вторая — запись того, что было сказано в действительности) путем алгоритма динамического программирования с вычислением расстояния Левенштейна [12].
Расстояние Левенштейна представляет собой “стоимость” редактирования текстовых данных (минимальное количество или взвешенная сумма операций редактирования [ 13]) для преобразования первой строки во вторую с наименьшим числом операций ручной замены (S), удаления (D) и вставки (I) слов: WER =(S+D+I)/T * 100%(4.1) где Т — количество слов в распознаваемой фразе.
Также для оценки качества распознавания речи используется показатель процента корректно распознанных слов (WCR — Word Correctly Recognized), он не учитывает ошибочные вставки слов, сделанные системой: WCR=H/T*100% H=N-D-S, (4.2) где H — количество правильно распознанных слов, а N — количество произнесенных диктором слов.
Очевидно, что WER – это интуитивно понятный и адекватный показатель качества распознавания для аналитических естественных языков (класс языков, обладающих достаточно простой морфологией и системой словообразования), в которых грамматические значения однозначно выражаются самим словом (например, английский или французский).
Однако другой класс синтетических языков (например, агглютинативные языки: финский, турецкий, венгерский или флективные языки: русский, украински й, казахский и т.д.), напротив, отличается богат ой морфологи ей и развитой систем ой словообразования.
Такие языки могут синтезировать достаточно длинные словоформы из нескольких составных частей (морфем или слогов), которые определяют грамматические признаки. При этом в беглой речи конец слова произносится не так четко как начальная часть, что приводит к акустической неопределенности и в среднем к более высоким значениям WER по сравнению с аналитическими языками.
Кроме того, многие азиатские языки (например, китайский, корейский и т.п.) используют слоги взамен слов, а тайский и некоторые другие языки не имеют явных разделителей границ слов.
С целью оценки систем распознавания речи для синтетических языков могут дополнительно применяться и другие показатели: ошибка распознавания букв/символов (LER или CER) [14] или ошибка распознавания фонов (звуков речи) [15], ошибка распознавания слогов (SylER) [16] или ошибка распознавания морфем [17].
Кроме того, для некоторых синтетических языков (например, русского) адекватным показателем является также флективная ошибка распознавания слов (IWER — Inflectional Word Error Rate) [18], которая определяется следующим образом: 1≤0;1≥ ; IWER = (S_hard x C_hard + S_soft x C_soft + D + I)/ T (4.3) IWER приписывает вес Chard всем неверным заменам слов, которые привели к изменению лексемы слова, т.е. полного слова (количество грубых ошибок распознавания Shard — замен лексем) и меньший вес Csoft – всем негрубым ошибкам в словах, где было неверно распознано окончание словоформы, но лексема (или основа) слова распознана правильно (количество негрубых ошибок Ssof t — замен окончания слова).
Оценка автоматического распознавания речи по показателю WER предполагает, что все слова во входной фразе одинаково информативны и важны, однако, ясно, что в задачах, отличных от диктовки текста, например, диалоговые системы или понимание (смысла) речи, некоторые значащие слова (ключевые слова) более важны, чем остальные (функциональные слова, предлоги, заполнители и т.п.).
В [ 19] предложено оцени вать точность распознавания, используя взвешенный показатель неправильно распознанных слов (WWER — Weighted Word Error Rate), который определяется как:  (4.4),,,,s ˆiWv — вес слова iW, которое является i-м словом во входной фразе, и iWvˆ —вес слова iWˆ, которое является i-м словом в гипотезе распознавания, js — j-й замененный фрагмент фразы (или одно слово) и jsv — вес данного сегмента js.
Таким образом, в показателе WWER, каждое слово может иметь различный вес(установленный экспертом или автоматически) в соответствии с его влиянием на последующее понимание смысла сказанной фразы.
Национальный институт стандартов и технологий (NIST) предложил также показатель количества неправильно распознанных слов по отношению к диктору (SAWER — Speaker Attributed Word Error Rate) для задачи стенографирования речи на совещаниях [20], в которых предполагается одновременное участие нескольких различных людей.
Данная задача объединяет технологии автоматического распознавания речи и диаризации (сегментации) речи дикторов (разметке звукового сигнала на фрагменты «кто когда говорил» — “Who Spoke When ”).
Результатом работы объединенной системы является текстовая транскрипция входного одноканального звукового сигнала с указанием говорящего для каждого распознанного слова.
SAWER определяется следующим выражением:  %,100TSEIDSSAWER (4.5) где SE — число слов (или иных языковых единиц), правильно распознанных системой распознавания речи, но с неправильным указанием диктора в ходе диаризации речи дикторов.
Нужно отметить, что разработчики и пользователи должны понимать, что процент неправильного распознавания слов речи – это, в действительности, только количественный показатель точности распознавания (количество ошибок распознавания на фразу или слово), но не вероятность распознавания (вероятность неправильного распознавания слова во фразе), потому что он не ограничивается интервалом вероятности [0; 1] и не имеет верхнего предела.
Например, представим, что диктор произнес фразу, состоящую из 10 слов, но система ее полностью распознала неправильно и предложила гипотезу из 1 2 других слов.
В этом случае, WER =120 % (S=10, I=2, H=D=0), и это означает, что показатель точности WRR отрицательный (-20%), что не имеет смысла с точки зрения теории вероятностей.
Для того чтобы обойти эту проблем у, были также предложены другие показатели качества распознавания речи, в частности, ошибка распознавания соответствий (MER — Match Error Rate) и показатель потери информации для слов (WIL — Word Information Lost) [21], основанные на вычислении относительной потери информации, и определяемые следующим образом:  IDS H еслиTTHWILIDSHIDSMER O, 1,2, (4.6) где OT — число слов в гипотезе распознавания, T — число слов во входной фразе.
Однако оба этих показателя на практике применяются довольно редко, так как они обычно показывают несколько меньшую точность распознавания по сравнению со стандартными показателями, что не нравится разработчикам.Все упомянутые выше показатели имеют дело только с одной наилучшей гипотезой распознавания каждой произнесенной фразы, и совсем не обязательно, что этот единственный результат распознавания окажется действительно правильным.
Однако многие системы распознавания речи способны выдавать сразу несколько гипотез распознавания с наибольшими вероятностями, так называемый список N лучших гипотез (N-best list).
Дополнительным показателем для оценки таких результатов является показатель ошибок распознавания слов в списке из N лучших гипотез [22], который оценивается путем выбора из N гипотез предложений, ранжированных распознавателем по уменьшен ию оценки правдоподобия, единственной гипотезы, дающей наименьший уровень ошибок.
WER для гипотезы с минимальным уровнем ошибок для каждой входной фразы выбирается как основной результат распознавания, и процент ошибок распознавания списка N лучших гипотез вычисляется для набора из этих выбранных гипотез.
При вероятностном моделировани и и распознавани и речи также иногда используются доверительные интервалы для того, чтобы показать значимость результатов.
При оценке автоматического распознавания речи доверительный интервал (“confidence interval”) иногда указывается вместе со средним значением WER (например, WER =18,5  2,3 %).
В общем случае, доверительные интервалы показывают: 1) какое значение WER мы можем ожидать при изменении набора тестовых данных; 2) нас колько значимым является предложенное улучшение модели распознавания.
Однако на практике доверительные интервалы WER часто оказываются довольно широкими, что объясняется высокой дикторской вариативностью и речевыми сбоями (некоторые дикторы или фразы распознаются с нулевым WER, но другие дают очень высокий уровень ошибок).
Большинство производимых разработчиками улучшений в системах распознавания речи не приводят к улучшению результатов, выходящих за пределы доверительного интервала WER из-за ограниченности наборов тестовых данных, что несколько снижает значимость результатов.
Однако как новые, так и базовые методы распознавания речи обычно оценив аются разработчиками на одних и тех же оценочных данных (т.е. речевые данные не являются независимыми для разных сравниваемых моделей распознавания), в этом случае при количественной оценке точности распознавания доверительные интервалы могут не рассматрив аться.
Но в том случае, когда некоторые модели распознавания тестируются на различных и независимых тестовых наборах, требуется вычисление доверительного интервала дополнительно к среднему значению WER [23].
4.2 Показатели оценки скорости распознавания речи Второй важный критерий оценки систем распознавания речи — скорость обработки речи, которая особенно важна в он-лайн системах распознавания речи с использованием микрофона.
Она, как правило, вычисляется с использованием меры, называемой показателем скорости (SF — Speed Factor), также известнойкак показатель реального времени (RT – Real Time) [20].
Он определяется как отношение общего времени обработки, требуемого для анализа всей записанной речи к длительности исходного анализируемого аудиосигнала.
Например, если 10-минутный аудиофайл обрабатывается системой распознавания ровно 5 минут, то SF=0,5 реал ьного времени, если он обрабатывается в течение 20 минут, то тогда SF=2,0 реального времени, что значительно хуже.
Скорость обработки может быть также указана в абсолютных значениях времени (например, количество минут/секунд для обработки входного сигнала), что, однако, не является наглядным.
Другим показателем скорости автоматического распознавания речи является период ожидания обработки отсчета (SPL – Sample Processing Latency).
Этот показатель означает максимальное количество аудиоданных, которое алгоритм распознавания должен обработать до выдачи результата для первого отсчета сигнала.
5. МЕТОД ДИНАМИЧЕСКОГО ПРОГРАММИРОВАНИЯ ДЛЯ РАСПОЗНАВАНИЯ РЕЧИ 
Для распознавания команд до сих пор иногда используют метод динамического программирования (ДП), впервые предложенный в 60-х годах прошлого века.
Это объясняется простотой, быстродействием и отсутствием необходимости собирать речевую базу данных.
Неизвестная команда в виде последовательности векторов признаков сравнивается с набором эталонов, представленных в таком же виде.
Основная проблема – различный темп и нелинейность темпа произнесения.
При принятии решения руководствуются критерием минимума расстояния от неизвестного произнесения до эталона.
Метод подразумевает, что эталоны, принадлежащие одной команде (одному классу), группируются в кластер, то есть в компактную группу точек в некотором пространстве, в котором существует мера близости.
Идея метода проста и допускает рассмотрение на качественном уровне.
Задача состоит в том, чтобы сравнить две совокупности векторов различной длины, причем на пространстве векторов есть метрика или мера близости.
Представим, что мы сравниваем эталон сам с собой: отложим векторы признаков эталона по оси X и Y. На плоскости XY на пересечении координат, соответствующих вектора м i и j, построим вертикальный отрезок, равный расстоянию (степени близости) между этими векторами.
Тогда на квадрате со стороной, равной количеству векторов в эталоне (N), возникнет "гористый ландшафт", симметричный относительно диагонали (0,0) (N,N), однако по диагонали будет пролегать абсолютно прямая "долина" с высотой, равной 0 (поскольку расстояние от вектора до самого себя равно 0).
Если мы сравниваем два различных эталона, принадлежащих одному и тому же слову, то "картина местности" исказится, однако, если используемые признаки адекватно отражают процесс восприятия, можно надеяться, что некоторая долина по-прежнему будет пролегать по ломаной, близкой к диагонали, теперь уже прямоугольника (рис. 5.1).
Метод динамического программирования позволяет сосчитать минимальную сумму высот, набираемую при движении из точки (0,0) в точку (N,M) и, если это требуется, восстановить путь, по которому эта сумма набрана.
Полученную сумму обычно нормируют на количество пройденных узлов, либо на сумму длин слов или дли ну более короткого слова и рассматривают как расстояние между двумя произнесениями.
Конечно, используемые в практических системах реализации имеют множество управляемых параметров, оптимизирующих качество распознавания и уменьшающих время счета.
Рассмотрен ный метод позволяет в дикторозависимом варианте распознават ь 100 – 300 слов с вероятностью 90 –98%.
Для придания системе дикторонезависимых качеств, для каждого слова записывают несколько эталонов от разных дикторов (в процессе обучения добавляют эталон от нового диктора, если он не распознался).
Кроме того, существуют схемы нормализации эталонов относительно дикторов, а также кластеризации дикторов.
Рис. 5.1. Схема метода динамического программирования А
лгоритм распознавания команд методом ДП прозрачен и не требует подробного рассмотрения.
В зависимости от топологии модели (разрешённых переходов) суммарное расстояние очередного узла матрицы [ M,N] (рис.5.1.) подсчитывается, исходя из минимума набранного расстояния:) (min),(,,,, lklkRlkji Sw ji Dist S  ,  (5.1) где Sn,m – суммарное расстояние в узле (n,m), Dist(i,j) – расстояние между вектором i эталона и вектором j тестового слова, wk,l – вес, который присвоен узлу (k,l) относительно узла (i,j) (например, недиагональные переходы [(i-1,j)->(i,j) и (i,j-1)->(i,j)] могут «штрафоваться» бОльшим весом, чем диагональный переход [(i-1,j-1)->(i,j)]), R – множество разрешённых для перехода узлов (обычно это три ближайших узла [(i-1,j),(i-1,j-1) и (i,j-1)]).
Кроме суммарного расстояния, каждый узел матрицы [ M,N] может содержать информацию об узле, откуда совершён переход – эта информация нужна, если требуется восстановить путь.
Оценкой близости эталона и тестового слова является нормированное суммарное расстояние правого верхнего узла матрицы.
В качестве результата распознавания выбирается эталон с наименьшим расстоянием до тестового Рис. 5.2.
Область подсчёта накопленных расстояний для матрицы [ M,N] слова, если расстояние не превосходит некоторого эмпирического порога, возможно, зависящего от слова.
Очевидно, что представленный алгоритм не решает задачу определения начала/конца слова.
Фрагмент речи, содержащий слово, должен быть найден алгоритмом определения речь/не речь – Voice Activity Detector (VAD).
Альтернативой является гораздо более трудоёмкий алгоритм ДП со скользящими концами.
Для сокращения количества вычислений можно предложить усовершенствования первоначал ьной модели: не рассматривать эталоны, которые отличаются по длине от тестового слова больше, чем в n раз (n обычно равно 2), не подсчитывать суммарное расстояние для узлов матрицы, далеко отстоящих от диагонали (см. рис. 5.2), прекращать вычисления, если минимальное накопленное расстояние для некоторого столбца или строки превышает порог, зависящий от номера столбца или строки.
5.1. Меры близости в пространстве признаков 
В задачах распознавания речи методом ДП приходится сравнивать "похожесть" фрагментов р ечевого сигнала.
Поскольку оценка близости акустических событий не требует введения строгой метрики, на соблюдение второй (симметричность) и третьей (треугольника) аксиом, котор ым должно удовлетворять понятие метрики, в задачах распознавания речи не обраща ют внимания.
Более того, можно представить "физиологическую" меру близости, где третья аксиома будет нарушаться закономерно, что может являться выражением того факта, что из положения артикуляторного тракта, характерного для некоторого звука, легче достичь положения, характерного для другого звука не напрямую, а через некоторый промежуточный звук.
Однако чаще всего используются абстрактные меры близости, заимствованные из соответствующих разделов математики, для которых все аксиомы выполняются без всякого желания со стороны исследователя.
По-видимому, первая мера, которая использовалась в задачах распознавания – это обычная Евклидова метрика:  D ii iyx yx Dist 12) (),(.
(5.2) По мере совершенствования математического аппарата, применялись меры, более адекватно отражающие характер используемых признаков.
Так, использование метрики Махаланобиса:) () (),(1yx Myx yx DistT ,  (5.3) где M – матрица ковариации, позволяло учесть корреляцию и вариативность признаков.
Евклидова метрика является частным случаем ме трики Махаланобиса, когда ковариационная матрица является единичной, ее имеет смысл использовать после декорреляции признаков (например, методом Карунена-Лоэва), и последующего нормирования признаков на дисперсию.
В простейших системах используют сумму модулей разностей компонент векторов признаков (квартально-блочная метрика): i iD iyx yx Dist  1),(.
(5.4) Для кепстральных коэффициентов и коэффициентов линейного предсказания получены меры близости, отражающие характер пространств, в которых эти параметры вычисляются.
Так, для кепстральных коэффициентов используется метрика Кульбака-Лейблера: iiD ii iccc c cc Dist,2,1 1,2,1 2 1 ln) (),( ,  (5.5) где суммирование проводится по всей области определения квифренси («quefrency »).
Хансен показал [24], что взвешивание кепст ральных коэффициентов их индексом приводит к расстоянию между наклонами спектров, а не между самими спектрами.
Соответствующая мера имеет вид: 2 1,2,1 2 1) (),( D ii ic ci cc Dist.
(5.6) В [25] предложена "проекционная" мера:) cos1(),(2 2 1 c cc Dist,   (5.7)где) arccos(1 21 2 ccccT .
Показано, что эта мера более помехоустойчива.
Для коэффициентов линейного предсказания LPC используется метрика Итакуро-Саито:,]1)()(ln)()([),(2 212 21 2 1   dGG GGGG Dist         (5.8) где G(θ) =E/S(θ), Е – энергия, S(θ) – полином, построенный на коэффициентах ai (3.5–3.11), интегрирование происходит вдоль единичной окружности на Z- плоскости.
Кроме таких более или менее формальных метрик иногда вводят меры близости, основанные на данных о восприятии речи и особенностях слуховой системы.
При этом оценивают расстояние между формантными структурами в шкале барк, то есть разница в частотах считается в критических полосах.
Попытки распознава ть слитн ую речь с помощью ДП [ 26] утратили актуальность с развитием метода скрытых марковских моделей и поэтому далее рассматриваться не будут.
6. РАСПОЗНАВАНИЕ РЕЧИ С ПОМОЩЬЮ СКРЫТЫХ МАРКОВСКИХ МОДЕЛЕЙ 
В настоящее время большинство систем распознавания речи опираются на Скрытую Марковскую Модель (СММ).
СММ – мощный статистический аппа рат, представляющий спектральные свойства речи с помощью параметрического случайного процесса.
Каждому моделируемому речевому объекту – фразе, слову, слогу, фонеме или аллофону (фонеме в конкретном окружении) – сопоставляется своя СММ.
СММ фразы представляет собой конкатенацию СММ слов, которые представляются конкатенацией СММ более мелких элементов.
Рассмотрим математический формализм, определяющий СММ.
Процесс называется марковским, если для каждого момента времени вероятность любого состояния системы в следующий момент зависит только от состояния системы в настоящий момент и не зависит от того, каким образом система пришла в это состояние.
Марковский процесс называется наблюдаемым, если каждое состояние на выходе взаимно-однозначно соответствует некотором у наблюдаемому явлению.
Пример: Состояние 1: непогода (дождь, снег, град,…) Состояние 2: облачно Состояние 3: солнечно Вероятности переходов между состояниями отображены на рис. 6.1 и в матрице A (1):  Рис.6.1.
Марковская цепь, описывающая погодную модель [4]       8.01.01.02.06.02.03.03.04.0,jia A.
(6.1) Зная исходные значения вероятностей π j, можно рассчитать вероятность любой последовательности погодных условий в последующие дни, как произведение соответствующих вероятностей.
Если состояния связаны с наблюдаемыми явлениями вероятностным образом, то марковская цепь называется скрытой (СММ).
В случае распознавания речи наблюдаемыми являются векторы признаков, которые связаны с состояниями вероятностным образом, то есть один и тот же вектор признаков может принадлежать нескольким состояниям.
Таким образом, к параметрам модели добавляются распределения вероятностей состояний в пространстве признаков, которые называют вероятностями эмиссии: Bi(x) – функция плотности вероятности состояния s i в пространстве признаков или вероятность эмиссии.
Если пространство признаков проквантовано, то Bi(x) представляется матрицей Bi(m), где m – номер слова в кодовой книге.
Такие модели называются дискретными.
Для непрерывной модели используют аппроксимацию функции плотности вероятности набором стандартных функций – как правило, взвешенной суммой гауссовых функций.
Для уменьшения количества оптимизируемых параметров используют гауссовы функции с диагональными матрицами ковариации.
Существует разновидность СМ М, называемая полунепрерывной – в этой СММ для аппроксимации функций плотности вероятности всех состояний используются функции из одного пула.
Задачей распознавания является сопоставление набору акустических признаков речевого сигнала или наблюдений Х(х 1,…,х n) последовательности слов W(w 1,…,w k), имеющих наибольшую вероятность правдоподобия среди всех кандидатов: P(W|X) W Wmaxarg.
(6.2) Используя теорему Байеса, перепишем это выражение:)() ()(maxargXPWXPWPW W.
(6.3) Поскольку в процессе распознавания вероятность уже полученных акустических признаков P(X) не подлежит оптимизации:).
()(maxarg WXPWP W W (6.4) Вероятности (6.4) имеют простую интерпретацию: P(X|W) есть акустическая модель (вероятность порождения данной последовательности наблюдений X данной последовательностью слов W), а P(W) – вероятность существования в рассматриваемом языке данной последовательности слов (модель языка).
Проблемы моделей языка будут рассмотрены в разделе 13.Как будет показано в разделе «Выбор единиц распознавания фонетического уровня», акустическая модель представляет собой конкатенацию простых СММ, описывающих, как правило, аллофоны.
Таким образом, марковской моделью (A,B,) акустического события (акустической моделью), например, аллофона, называется набор из одного или нескольких состояний s i, характеризующийся следующими параметрами: N – количество состояний s:  i – начальное распределение вероятностей,.1 1 N ii A={a i,j} – вероятность перехода из состояния s i в состояние s j,,1 1, N jaji Ni1.
Bi(x) или Bi(m) – вероятность эмиссии: ,1)(dvxBi, 1 Ni где интегрирование проводится по всему объёму пространства признаков,  M mimB 1,1)(где, 1 Ni M – размер кодовой книги, то есть количество кластеров.
Если длительность реальной последовательности наблюдений равна T, обозначим состояния в моменты времени как (q1,q2,…,qT), тогда каждому состоянию модели si может соответствовать несколько последовательных значений q в соответствии с длительностью состояния.
Например, qm=si, qm+1=si, qm+p=si – в данном случае состояние si длится p тактов.
Разрешённые переходы между состояниями в различные моменты времени определяются топологией модели, заранее заданной разработчиком.
Очевидно, что переходы «назад» во времени имеет смысл запретить, то есть ai,j=0 для j<i.
Кроме того, имеет смысл запретить слишком дальние переходы, так как большая свобода переходов лишь увеличивает возможности для системы сделать ошибку.
Обычно ai,j=0 для  j-i>2, то есть разрешены «петли», «переходы» и «прыжки» (под петлёй понимают переход в текущее состояние, под переходом – переход в следующее состояние, а под прыжком – переход через одно состояние).
Как правило, систему ограничивают ещё больше, разрешая только петли и переходы.
Это особенно удобно, поскольку, благодаря нормировке вероятностей на единицу, можно хранить не ма трицу вероятностей переходов, а вектор вероятности петли ai,i, при этом вероятность перехода будет равна ai,i+1 = 1- ai,i.
Отметим, что матрица переходов, по существу, управляет временем пребывания в состояниях и управляет неадекватно.
Зададимся вопросом: какова вероятность того, что процесс пробудет в состоянии si n тактов?
Попав в состояние si, процесс должен n-1 раз остаться в нём же с вероятностью ai,i, а на такте n перейти в любое другое с вероятностью 1- ai,i.Таким образом:) 1()(,)1(, iin ii a anP ,   (6.5) то есть, распределение вероятностей носит степенной характер с максимумом при нахождении в данном состоянии n=1 такт для всех состояний.
Однако анализ длительностей пребывания в состояниях при обучении СММ показал, что реальное распределение вероятностей напоминает распределение Гаусса или Пуассона с максимумом при длительностях пребывания больше 1 такта (под тактом понимается период следования признаков, обычно около 0.01 сек).
Правильное моделирование временных параметров для моделей представляется достаточно важным, поскольку уменьшает возможность системе сделать ошибку, быстро пройдя состояния, не соответствующие исследуемому процессу – система будет вынуждена задержаться во всех состояниях некоторое время, значительно уменьшив вероятность идентификации ложной модели как правильной.
Учёт времени жизни состояния приводит к неоднородным или полумарковским моделям, поскольку требует нарушения принципа марковости – зависимости только от состояния процесса в предыдущий такт.
Полумарковские модели будут рассмотрены в разделе 7.
Рассмотрим основные проблемы, решаемые в рамках СММ, следуя [27].
1. Проблема оценки: для данной модели (A,B,) и последовательности наблюдений X(x 1,x2,…,x T) вычислить вероятность P(X|), то есть вероятность порождения последовательности X моделью .
Решается алгоритмом «Вперёд- назад» (Forward-Backward).
2. Проблема распознавания: для данной последовательности наблюдений X(x 1,x2,…,x T) и модели (A,B,) вычислить оптимальную, в некотором смысле, последовательность состояний Q(s1,s2,…,sT), принадлежащих модели .
Решается алгоритмом Витерби.
3. Проблема обучения: для данной последовательности наблюдений X(x1,x2,…,x T) и модели (A,B, ) подстроить параметры модели так, чтобы максимизировать P(X| ).
Решается алгоритмом Баума-Уэлша.
6.1. Алгоритм «Вперёд-Назад» Алгоритм «Вперёд-Назад» (или «Прямого-обратного хода», Forward- Backward) включает две процедуры в соответствии со своим названием.
Рассмотрим процедур у «Вперёд».
Введём вспомогательную переменную t(i), которая представляет собой вероятность наблюдать последовательность x1,x2,…,x t и оказаться в состоянии si в момент времени t для модели :)|,...,,()(,2 1  i t t t sqx xxPi  . (6.6) Рис. 6.2.
Процедура «вперёд» (прямого хода) [2] Рассмотрим итерационную процедуру вычисления t(i).
Инициализация:)()(1 1xB iii, Ni1,   (6.7) индукция:), ()()(1, 11     t j jiN it t xBai j  Nj Tt  1, 1, (6.8) завершение:  N iTi XP 1).
() ( (6.9) Объяснение данных формул достаточно очевидно: на первом шаге вероятность определяется начальным распределением вероятностей и соответствием наблюдения x1 данным состояниям; на втором шаге вероятность оказаться в состоянии sj в момент времени t+1 складывается из вероятностей t(i) оказаться в состоянии si в предыдущий момент времени, умноженных на соответствующие вероятности переходов в состояние sj ai,j с учётом соответствия наблюдения xt+1 состоянию sj Bj(xt+1) (рис.
6.2.); на третьем шаге подсчитывается сумма всех вероятностей в конечный момент T, поскольку это независимые события.
Аналогично функционирует процедура «Назад» (рис. 6.3.).
Введём вспомогательную переменную  t(i), которая представляет собой вероятность наблюдать последовательность xt+1,xt+2,…,xT для модели , при условии, что в момент t система была в состоянии sj:).,,...,,()(2 1  i tT t t t sqx xxPi   (6.10) Заметим, что величины t(i) и  t(i) дополняют друг друга в том смысле, что),()(),(i i sqXPt t i t , 0 Tt Ni1.
(6.11)  Рис. 6.3.
Процедура «назад» (обратного хода) [2] Отсюда искомая вероятность последовательности наблюдений X быть порождённой моделью  выражается суммой вероятностей (6.11) по всем возможным состояниям для любого момента времени :  N it t i i XP 1)()() (,, 0 Tt Ni1.
(6.12) Рассмотрим итерационную процедуру вычисления  t(i).
Инициализация (очевидна, исходя из (6.9) и (6.12)):,1)(iT Ni1.
(6.13) Индукция:   N jt t jji t j xBa i 11 1,),() ()( ,1 1 Tt Ni1.
(6.14) Объяснение аналогично алгоритму «вперёд».
Завершение:  N iii i xB XP 11 1)()() (.
(6.15) 6.2.
Алгоритм Витерби Алгоритм Витерби можно рассматривать как алгоритм динамического программирования, применённый к СММ, или как модифицированный алгоритм «вперёд», в котором вместо суммирования по всем возможным путям выбирается и запоминается наилучший путь.
Определим вероятность наилучшего пути: ],,...,,,,,...,,[ max)(2 1 1 2 1,...,,1 2 1 t i t tq qqt x xxs qq qqP i t   (6.16) где δt(i) – вероятность наиболее правдоподобной последовательности состояний, порождающей последовательность векторов признаков tX1 и заканчивающейся в момент времени t состоянием si.
Для того чтобы сохранять информацию о переходах между состояни ями, вводится массив ψt(i), который содержит, например, номер состояния, из которого процесс пришёл в состояние i в момент времени t. С введёнными обозначениями алгоритм Витерби имеет следующий вид.
Инициализация:)()(1 1 xB iii, 0)(1i, Ni1.
(6.17) Индукция:), (])([ max)(1,11 t j ji tNit xBai j , 1 Tt Nj1.
(6.18) ],)([ maxarg)(, 1 1ji t Nit ai j  , 2 Tt Nj1.
(6.19) Завершение:)]([ max)|(1j XPTNj  (6.20))].
([ maxarg 1j qT NjT   (6.21) Восстановление пути процесса:.1,...,2,1),(1 1   T Ttq qt t t (6.22) Отметим, что алгоритм Витерби получается из алгоритма «Вперёд» путём замены суммирования по состояниям на выбор максимального значения.Поскольку вероятности, фигурирующие в формулах индукции, меньше 1, их итерационное применение приводит к потере точности.
Для преодоления этой проблемы, как правило, используют логарифмы вероятностей.
В этом случае все произведения превращаются в суммы, а алгоритм Витерби с вычислительной точки зрения становится тождественен классическому алгоритму динамического программирования.
Отличие заключается лишь в том, что в алгоритме ДП ищется эталон с минимумом расстояния до неизвестного произнесения, а в алгоритме Витерби критерием является максимум логарифма вероятности.
6.3.
А лгоритм Баума-Уэлша Алгоритма нахождения глобального оптимума не существует – алгоритм Баума-Уэлша гарантирует нахождение локального оптимума.
Для того чтобы убедиться в качестве полученного решения, можно использовать многократное обучение с различными начальными параметрами.
Введём вспомогательную величину t(i,j), представляющую собой совместную вероятность находиться в состоянии si в момент t и в состоянии sj в момент t+1 для данной модели  и данной последовательности наблюдений X: ].,, [),(1  Xs qsqPjij t i t t  (6.23) Используя теорему Байеса и введённые ранее параметры алгоритма Вперёд- Назад (6.6, 6.10), перепишем выражение (6.23):   N kN mt t m mk tt t jji tj t i t t m xBakj xBaiXPXs qs qPji 1 11 1,1 1,1)() ()()() ()(]|[]|,, [),(   (6.24) Введём параметр:   N ji t t t Xs qPji i 1], [),()( ,  (6.25) вероятность находиться в момент времени t состоянии si.
Учитывая индукцию (6.14):.
)()()()()(1 N it tt t t i ii ii  (6.26)  T tti 1)( есть математическое ожидание числа попаданий в состояние si, а  T ttji 1),( – математическое ожидание числа переходов из состояния si в состояние sj.
С помощью введённых величин выразим параметры модели (A,B,) для дискретного варианта СММ:),(1*ii (6.27),)(),(11 1 *,   T ttT tt ji iji a  (6.28),)(])[()(11 *   T ttT tk t t j jvxj kB  (6.29) где vk – k-ое кодовое слово кодовой книги, [ xt=vk] обозначает, что вектор обучающей выборки xt принадлежит кодовому слову vk, символ ‘*’ обозначает то, что соответствующая величина является новой оценкой.
Доказано, что оценка вероятности с новыми параметрами не хуже, чем со старыми: P(X|λ*) >= P(X|λ).
Выведем формулы переоценки параметров вероятности эмиссии для непрерывного случая.
Представим Bj(x) в виде комбинации Mj гауссовых функций:  jM mjm jm jm j U xGc XB 1],,,[)( jMm1, (6.30) где: X – вектор наблюдений размерности D, cjm – весовой коэффициент, определяющий вклад гауссовой функции с номером m (компоненты смеси) в функцию плотности вероятности для состояния с номером j, μjm – среднее значение для компоненты смеси m состояния j, Ujm – ковариационная матрица компоненты смеси m состояния j, G – многомерная гауссова функция:),2/)] () [(exp() 2(1],,[1 2/     X U X UU XGT D (6.31) поскольку гауссовы функции и функция Bj(X) нормированы,  M mjmc 1,1 Mm1.
(6.32) Естественно также потребовать cjm >=0, 1<= j<=N, 1<= m<=M.
Модифицируем параметр ɣt(i) (6.25) для непрерывной модели.
Пусть ɣt(i,m) – доля гауссовой компоненты с номером m в вероятности находиться в момент времени t в состоянии si:. ]
,,[],,[)()()()(),(1 1            M kik ik ikim im im N jt tt t t U XGcU XGc j ji imi   (6.33) Формулы пересчёта параметров вероятности эмиссии для непрерывной модели имеют вид:,),(),(1 11 *  T tM mtT tt ik miki c  (6.34),),(),(11 *  T ttT tt t ik kixki   (6.35).
),())()(,(11* * *   T ttT tT ik t ik t t ik kix xki U   (6.36) Отметим, что обучение и пересчёт параметров возможны также в рамках алгоритма Витерби.
В этом случае вероятности попадания в состояние ɣt(i) могут принимать то лько значения 0 или 1, поэтому в формулах (6.34 –6.36) нужно использовать конкретное число векторов и сами векторы, попавшие в состояние i. Попадание в определённое состояние определяется по результатам сегментации при восстановлении пути процесса (6.22).
Акустические модели, полученные методом Витерби, практически не уступают моделям, полученным методом Баума-Уэлша.
Как уже говорилось выше, ковариационные матрицы (6.36) диагонализируют для уменьшения количества оцениваемых параметров.
Для полунепрерывной мо дели параметры гауссовых функций μjm и Ujm фиксированы и пересчёту подвергаются только весовые коэффициенты cjm.
Формулы пересчёта параметров для непрерывной модели (6.34 –6.36) не дают ответа на вопрос: какое количество гауссовых функций в смеси следует использовать.
Можно выделить три подхода к решен ию этого вопроса.
1.Фиксировать количество на каком-то приемлемом числе (1 –20).
Количество определяется объёмом обучающей выборки, вычислительными возможностями системы, сложностью конкретной прикладной задачи и т.д. 
2.Эмпирически – по результатам распознавания на тестовой выборке.
Остановить увеличение количества гауссовых функций в момент, когда улучшение распознавания изменяется на незначимую величину или начинает уменьшаться.
Данный подход практическ и не применяется из-за своей трудоёмкости.
3. Использовать оценку энтропии или логарифм правдоподобия.
Полную функцию правдоподобия можно оценить, используя параметр γt(j) (6.26), представляющий собой вероятность в момент времени t находиться в состоянии j или вес состояния j в момент t: T tN jt t j j xB L 1 1),()(log( (6.37) где L – функция правдоподобия.
Для простоты рассмотрим вариант обучения с помощью алгоритма Витерби.
В этом случае каждый вектор признаков обучающей выборки «приписан» только одному состоянию, поэтому не требуется проводить очень трудоёмкую операцию по одновременной оптимизации функций плотности вероятности для всех состояний.
Стоит задача оценить качество аппроксимации функции плотности вероятности каждого состояния по отдельности.
Логарифм правдоподобия для состояния j имеет вид:  T tjtt j j xB L 1,)), (log( (6.38) где Bj определено в (6.34), символ δtj равен 1, если в момент времени t процесс находился в состоянии j и 0 в противном случае.
Нормированный на T логарифм правдоподобия (6.38) стремится к энтропии распределения с обратным знаком при T и при улучшении качества аппроксимации.
Практика показывает, что при итерационном процессе, описываемом формулами (6.34 –6.36), быстрый начальный рост Lj довольно скоро сменяется пологой кривой.
Когда приращение Lj становится меньше некоторого порога, процесс останавливают и некоторую гауссову функцию из (6.30) (обычно функцию с наибольшим весом) расщепляют на две каким-либо способом.
После этого итерационный процесс начинают снова.
Когда дальнейшее увеличение количества гауссовых функций в формуле (6.30) не приводит к значимому увеличению Lj, количество гауссовых функций фиксируют.
Для того чтобы избежать переобучения, можно использовать контроль аппроксимации с помощью кросс-валидационной выборки (небольшой базы данных, выделенной из обучающей выборки и не участвующей в обучении), или использовать байесовский информационный критерий.
7. НЕОДНОРОДНАЯ МАРКОВСКАЯ МОДЕЛЬ 
Как был о показано в предыдущем разделе, марковское требование независимости процесса от истории, следствием которого является постоянная вероятность выхода из состояния, приводит к неадекватному описанию времени жизни состояний.
На рис.7.1 изображена нормированная гистограмма распределения времени пребывания в состоянии и различные варианты её аппроксимации.
Преодолеть данную неадекватность можно и в рамках марковской модели.
Один из применявшихся в своё время методов – расщепление состояния на несколько тождественных (с одинаковой эмиссией) состояний и запретом «прыжков» в топологии.
Очевидно, что время жизни такой модели в тактах не может быть меньше, чем количество внутренних состояний.
Однако также очевидно, что таким примитивным способом невозможно смоделировать реальную гистограмму.
Рис.7.1. Распределение времени жизни 7-го состояния в слове «seven» [28].
Сплошная кривая – экспериментальные данные; пунктир – аппроксимация гауссовой кривой; точечная кривая – аппроксимация гамма-распределением; штрихпунктирная – распределение в соответствии с постоянной вероятностью перехода Для того чтобы смоделировать реальную гистограмму времени жизни, приходится отказаться от предположения о независимости процесса от предыдущих состояний.
В алгоритм Витерби вводится дополнительная переменная, подсчитывающая количество тактов, проведённых в каждом состоян ии для каждого пути.
Полученная в процессе обучения гистограмма служит источником информации о вероятности остаться в данном состоянии, как функции количества тактов, проведённых в нём – a(ti).
Такая модель называется полумарковской или неоднородной марковской.
Рассмотрим формулы, позволяющие по гистограмме времени пребывания состояния восстановить вероятность остаться в состоянии как функцию такта времени.
Вероятность, находясь в данном состоянии, пробыть в нём n тактов, а затем покинуть его, равна:,)())(1()(1 1 n ii n n ta ta tP,1n))(1()(1 1 ta tP.
(7.1) Это аналог формулы (6.5) из предыдущего раздела, где вероятность a рассматривалась как константа.
Вероятности P(ti) представляют собой нормированную гистограмму.
Значения a(ti) вычисляются рекурсивно: ;)()(1)(.
..............................;)()(1)();(1)(1 112 21 1   n iin n tatPtatatPtatP ta (7.2) В качестве P(ti) используют аппроксимацию полученной экспериментально гистограммы распределением Пуассона, нормальным или гамма- распределением.
Это делается, чтобы избежать случайных скачков, связанных с недостаточностью обучающей выборки, особенно на краях гистограммы.
Рассмотренные расчёты и полученные вероятности переходов применяются к состояниям, соответствующим фонемам.
При разбиении состояний, соответствующих фонемам, на подсостояния использую тся вероятности переходов, пересчитанные из вероятности перехода, относящиеся к фонеме в целом.
Основанием для такого подхода является то, что точность оценки гистограмм времени жизни для подсостояний недостаточна.
Топология модели в виде диаграммы состояний и переходов между ними представлена на рисунке 7.2.
Прежде чем рассмотреть оценку вероятностей a11, a22, a33, отметим, что модель рис. 7.2. не может иметь время жизни менее трёх тактов, что может не Рис. 7.2.
Топология модели с тремя состояниями для трифона 1S, 2S, 3S – состояния модели трифона; S, E – виртуальные узлы, соответствующие начальному (S) и конечному (E) состояниям фонемы; a11, a22, a33 – вероятности остаться в соответствующем состоянии трифона.
a12, a23, – вероятности перейти в следующее состояние трифона.
a3e– вероятность выйти из трифона.
ib – плотность вероятности наблюдения вектора признаков для состояния iS (вероятность эмиссии).
соответствовать экспериментальным данным, полученным для модели «короткоживущего» трифона.
В этом случае для получения адекватного времени жизни модели трифона из трёх состояний следует изменить топологию модели и позволить прыжки из любого состояния модели в следующий трифон, минуя промежуточные состояния, однако такое решение резко увеличивает количество гипотез для декодирования.
Возможным выходом будет также отказ от столь мелкого деления короткого трифона.
Если же среднее время жизни трифона существенно превосходит среднеквадратичное отклонение, хорошей оценкой для вероятностей a11, a22, a33 будут вероятности, вычисленные по формулам (7.2) для нормированных гистограмм P1, P2, P3, сумма средних которых равна среднему, а сумма дисперсий равна дисперсии исходной гистограммы трифона.
8. ПРОБЛЕМА ВЫБОРА ЕДИНИЦ ФОНЕТИЧЕСКОГО УРОВНЯ 
В предыдущем разделе в рамках скрытой марковской модели использовалось понятие «состояние».
Понятно, что для реализации распознавания речи состояния должны быть связаны с единицами фонетического уровня.
Поскольку речь является процессом, возможно объединение (конкатенация) моделей фонетических фрагментов в непрерывное произнесение.
Таким образом, вместо создания моделей для каждого слова, что является непосильной задачей для больших словарей, создаются модели элементов нижнего уровня.
В качестве таких элементов исследовались слоги, фонемы и фрагменты фонем.
В настоящее время общепринятым является использование контекстно-независимых фонем (монофонов) для средних словарей и контекстно-зависимых фонем (дифонов, трифонов) для больших словарей.
Необходимость использовать части фонем и контекстную зависимость объясняется коартикуляцией (взаимным влиянием произносимых звуков друг н а друга), рассмотренной в первом разделе.
Взаимовлияние фонем не ограничивается соседями, а может распространяется на несколько соседних фонем.
Обычно используют информацию об одном (дифоны /бифоны) или левом и правом (трифоны) соседях (по аналогии, фонемы без учёта влияния контекста называют монофонами).
При этом количество фонетических единиц настолько возрастает, что даже очень больших б аз данных не хватает для оценки их статистики.
Приведём данные из работы [29], относящейся к английскому языку, и широко используемой базе данных Wall Street Journal Pronunciation Lexicon.
Для английского языка количество фонем составляет около 50 (количество не является фиксированным – ряд распространённых дифонов (бифонов) или трифонов можно заранее отнести к отдельным фонемам).
Полное количество трифонов составляет 503=125000.
Часть этих трифонов запрещена фонетическими правилами данного языка и никогда не встречается, остаётся 95221 трифон.
В упомянутой базе данных, которая составляет более 57 часов речи и содержит более 36000 предложений, встречается только 22804 трифон а, из них только 14545 трифонов встречаются более 10 раз. Понятно, что для обучения СММ требуется значительное количество образцов моделируемого объекта.
Число 10 можно признать минимально достаточным для обучения.
Таким образом, более 80000 трифонов являются невидимыми (unseen), но могут встретиться при эксплуатации системы распознавания.
Количество параметров для одной марковской модели может достигать 1000 –2000 (сюда входят матрицы переходов и параметры гауссовых функций, аппроксимирующих функции плотности вероятности).
Если умножить это число на количество трифонов (около 100000), общее количество параметров, которое надо оценить в процессе обучения, оказывается порядка 108–109.Таким образом, встаёт нетривиальная задача – оценить миллионы параметров, большинство из которых в обучающей базе данных не проявляются.
Для преодоления этой трудности предложено два пути – основанный на фонетических представлениях, то есть в значительной степени субъективный, метод решающего дерева (decision tree) и процесс образования трифонов,управляемый данными (data driven).
Оба метода преследуют одну цель – управлять количеством оцениваемых параметров в зависимости от объёма обучающей выборки, поскольку опыт создания систем распознавания показал, что лучше надёжно обучить систему с небольшим количеством параметров, чем разработать сложную систему с большим количеством параметров, не обеспеченных данными для обучения.
8.1. Кластеризация на основе дерева решений 
Идея метода заключается в том, что фонемы можно объединить в группы по типу влияния.
Например, можно предположить, что согласные с одним и тем же мест ом образования одинаково влияют на последующую гласную.
Тогда несколько трифонов будут описываться одной моделью.
Задача метода состоит в использовании объективных критериев для объединения или дробления трифонов и бифонов.
Рассмотрим суть метода для трифонов (бифоны строятся аналогично с учётом только левого или правого контекстов).
Каждой фонеме можно приписать ряд атрибутов, последовательно конкретизирующих её свойства и разбивающих всю совокупность контекстно- независимых фонов (монофонов) на более мелки е классы.
Тогда каждый трифон будет являться некоторой конечной ветвью дерева вопросов, спускаясь по которой, мы будем переходить ко всё более широким классам, объединяющим трифоны.
Начиная с монофонов, будем последовательно включать информацию о правых ил и левых соседях, задавая относительно них «бинарные вопросы» из списка атрибутов, например «левый сосед – фрикативный?
/ левый сосед – не фрикативный?» (разумеется, начинать надо с вопросов, находящихся «ниже» по стволу дерева вопросов).
Результатом рассматриваемой процедуры будет создание фонетического бинарного «дерева решений» (Decision tree), стволом которого является исходный монофон, а конечными ветвями или листья ми – трифоны, детализированные в той степени, которую позволяют приписанные монофонам атрибуты.
В задачу построения решающего дерева входит определение последовательности вопросов, относящихся к левому и правому контекстам.
Естественно стремиться к тому, чтобы очередной вопрос наилучшим, в некотором смысле, образом разделял обучающую выборку, относящуюся к данному трифону, на две выборки, относящиеся к двум уточнённым трифонам.
Степень улучшения можно связать с функцией логарифма правдоподобия, получаемой при очередном делении.
Функция логарифма правдоподобия системы, описываемой плотностью вероятности p(x), где x – координата в пространстве признаков, имеет вид:  N iixp L 1))(log(,   (8.1) где xi – совокупность векторов, принадлежащих расщепляемому трифону, N – количество векторов.После разделения некоторого трифона получим два новых трифона, которые описываются своими плотностями вероятности с функциями логарифма правдоподобия:     2 1 1)2(1)1(2 1 2,1)) (log()) (log(N iiN ii xp xp LL L,  (8.2) где)1(ix, N1 и)2(ix, N2 – совокупность и количество векторов, принадлежащих первому и второму трифону, N1+N2=N.
Если каждая функция плотности вероятности аппроксимируется одним и тем же количеством гауссовых функций (рекомендуется проводить операцию построения решающего дерева, используя одну гауссову функцию на каждое состояние), совместная система будет описываться точнее, и разница: L LLL 2 1,   (8.3) являющаяся приращением правдоподобия, будет положительной.
Таким образом, становится понятна процедура получения дерева решений.
1.Относительно исходного монофона для левого и правого контекстов последовательно задаём базовые вопросы: «левый сосед – гласная / левый сосед – не гласная» «правый сосед – гласная / правый сосед – не гласная» И так далее.
В дере ве вопросов все монофоны делятся на гласные и согласные, поэтому отрицательный ответ на вопрос о гласной автоматически означает согласную.
Представленная форма вопросов лишь подчёркивает их бинарную форму, требующую только ответов «да» или «нет».
Каждый во прос разбивает имеющиеся в обучающей выборке монофоны на две группы, для которых после обучения и вычисления плотностей вероятности можно вычислить логарифмы правдоподобия.
Первым вопросом в дереве решений становится тот, который даёт максимальное приращение правдоподобия (8.3).
2.Относительно трифона для левого и правого контекстов последовательно задаём оставшиеся вопросы из списка для исходного монофона.
В качестве очередного опять ставим вопрос, дающий максимальное приращение правдоподобия.
3.Процедур а для данной ветви дерева решений прекращается, когда максимальная информация, полученная на очередном шаге 2, становится меньше некоторого эмпирического порога или когда количество образцов трифона в обучающей выборке после очередного деления становится меньше некоторого порогового значения, необходимого для оценки функции плотности вероятности (этим пороговым значением в статистике часто выбирают 10, что, конечно, слишком мало для задачи оценки функции плотности вероятности в данной многомерной задаче).
Построенное фонетическое дерево решений позволяет использовать различную степень связанности состояний и, соответственно, различное количество трифонов, удовлетворяя компромисс между точностью распознавания и доступной памятью и быстродействием.
Для невидимых трифонов следует использовать наиболее близкую ветвь дерева решений.
Процедура построения решающего дерева носит чрезвычайно общий характер и не привязана исключительно к фонетике, её цель – генерация наиболее информативных единиц для распознавания.
В частности, среди расщепляющих бинарных вопросов могут быть вопросы о поле, возрасте или диалектных особенностях диктора.
И если обучающая база данных содержит ответы на данные вопросы, то некоторые ветви будут содержать различные трифоны для мужчин, женщин, детей и т.д. Конечно, следует помнить, что адекватная оценка функции плотности вероятности новых трифонов требует достаточной статистики.
Видимо, поэтому применение очевидного вопроса о поле диктора не приводит к однозначному улучшению распознавания, хотя по информативности этот вопрос оказывается одним из первых в дереве решений [29].
Понятно, что задавая этот вопрос, мы сразу уменьшаем базу данных для исследуемого трифона наполовину (если, конечно, база содержит одинаковый объём речи для мужчин и женщин).
Процедуру, аналогичную построению решающего дерева, мы использовали для оптимизации количества гаусс овых функций в смеси (предыдущий раздел).
Заметим, что более точное описание функции плотности вероятности существующего трифона в некотором смысле эквивалентно его представлению в виде двух новых трифонов.
Если достигнуто разделение плотностей вероятности различных трифонов в пространстве признаков, дальнейшее уточнение может происходить любым из этих путей.
Добавляя гауссовы функции в смесь и проводя обучение, мы можем остановиться, когда получаемая добавочная информация становится меньше некоторого порога.
Несмотря на применяемые формулы (8.1–8.3), представляющие объективный критерий, в основе метода лежит список вопросов, составляемый лингвистами.
В этой связи уместно вспомнить высказывание Ф. Джелинека, руководившего группой распознавания речи в IBM : «Every time I fire a linguist the performance of the recognizer improves».
8.2. Управляемый данными метод построения состояний 
Метод основан на процедуре об учения Витерб и. Как было сказано в предыдущем разделе, в данном случае все векторы признаков обучающей выборки однозначно приписываются тому или иному состоянию, то есть производится автоматическая сегментация (выравнивание, ”forced alignment ”) базы данных.
При этом начальная сегментация, по крайней мере, части базы данных, производится вручную для создания моделей монофонов на старте итерационного процесса.
Таким образом, все векторы признаков обучающей базы данных распределены по состояниям.
Поскольку тексты обучающей базы данных известны, векторы признаков, принадлежащие всем представленным в обучающей выборке трифонам (монофонам с известными соседями слева и справа), также доступны.Наша задача – построить объединения трифонов, то есть кластеры, таким образом, чтобы: 1. входящие в кластер трифоны были близки в соответствии с каким-либо критерием; 2. количество векторов признаков, представляющих кластер в обучающей базе, было не меньше некоторого заданного числа, чтобы обеспечить достаточную статистику для оценки функции плотности вероятности кластера.
Для кластеризации применяется кросс-энтропия, которая измеряет среднее количество информации при идентификации некоторого события, если вместо «истинного» распределения p используется распределение b:  Vdvxb xp qpH))(log()(),((8.4) Оценка кросс-энтропии на основе обучающей выборки осуществляется так же, как и оценка энтропии при выборе количества гауссовых функций – в виде нормированной функции логарифма правдоподобия с обратным знаком (см. предыдущий раздел):  jN ij i jj xbNH 1))(log(1ˆ,  (8.5) где Nj – количество векторов признаков, принадлежащих состоянию с номером j, b(x) – функция плотности вероятности (вероятность эмиссии) кластера.
Оценивается степень близости состояния с номером j с кластером, имеющим функцию плотности вероятности b(x).
Очевидно, что кросс-энтропия тем меньше, чем ближе данно е состояние к кластеру, то есть чем «лучше» накладывается собственная функция плотности вероятности распределения состояния на функцию плотности вероятности кластера.
На этом основании оценку кросс- энтропии (8.5) можно использовать в качестве меры близости при кластеризации состояний.
При кластеризации все векторы признаков данного состояния переносятся в ближайший кластер.
После перераспределения данных между кластерами производится новый расчёт вероятности эмиссии для каждого кластера.
Итерационная процедура прекращается, когда данные перестают переходить из кластера в кластер.
Описанная процедура не даёт ответа на вопрос: на сколько подсостояний разбивать начальные состояния, полученные на основе ручной сегментации?
Ответ снова можно получить, используя понятия энтропии (оцениваемой с помощью нормированной функции логарифма правдоподобия) (8.1, 8.2) и информации (оцениваемой как приращение функции логарифма правдоподобия (8.3)).
Если некоторое состояние представлено в обучающей выборке достаточным количеством векторов признаков, его мож но разбить на два или три состояния.
Начальное разбиение произвольно (при условии, что каждое состояние описывается достаточным количеством векторов).
В результате итерационной процедуры обучения будут получены уточнённые границы состояний и вычислена информация (8.3).
Если каждое из состояний описывается достаточным количеством векторов и полученная информация превышает некоторый порог, данное разбиение принимается.
Помимо моделей трифонов, обычно создают м одел и бифонов и монофонов.
Модели бифонов и монофонов необходимы по нескольким причинам.
Первая состоит в том, что даже при использовании большой обучающей выборки, остается вероятность того, что на этапе распознавания встретится трифон, для которого при построении моделей трифонов оказалось слишком мало данных, и соответствующая ему модель не была построена.
В этом случае модель требуемого трифона должна быть заменена на акустически близкую, в качестве которой может быть использована модель бифона или монофона.
Вторая причина заключается в том, что в некоторых грамматиках (например, при поиске ключевых слов) левый или правый контекст слова может быть не определен, поэтому вместо трифона необходимо использовать модель бифона с одним фиксированным контекстом и произвольным другим контекстом.
Третья причина вытекает из необходимости оптимизации сети лексикона (см. раздел, посвященный декодер у) при распознавании с большим словарем.
Оптимизация производится путем объединения фонемных узлов, имеющих одинаковые идентификаторы моделей.
На каждую фонему может приходиться до нескольких сотен моделей трифонов.
Поэтому, если использовать модели трифонов вместо начальных фонем слов, то при большом словаре количество точек входа в лексикон будет в десятки или в сотни раз больше, чем при использовании моделей монофонов, что при распознавании приведет к пропорциональному увеличению количества гипотез, падению производительности и снижению достоверности распознавания из-за неспособности декодера корректно обрабатывать возросшие объемы данных.
Модели монофонов строятся без у чета контекстов, по всем произнесениям фонемы, присутствующим в обучающей выборке.
Модели бифонов строятся с учетом только левого или только правого контекста, второй контекст остается произвольным.
В случае, когда требуемая модель трифона не найдена и должна быть заменена моделью бифона, нужно решить, какой из двух бифонов ближе к данному трифону – бифон с фиксированным левым или правым контекстом.
Для решения этой задачи, после построения моделей проводится распознавание фонограмм обучающей выборки по известным транскрипциям, с использованием моделей левых или правых бифонов и подсчетом вероятностей использования моделей каждого типа, в зависимости от контекстов.
При распознавании используется тот бифон, который на обучающей выборке показал лучшие результаты.
Схема построения акустических моделей представлена на рис. 8.1.
Рис. 8.1. Схема построения акустических моделей 
Отметим, что при построении кластеров данным методом, в отличие от метода дерева решений, принадлежность состояний тому или иному родительскому монофону никак не учитывается.
Таким образом, в один кластер могут попадать состояния от различных монофонов.
Это ещё одна положительная особенность управляемого данными метода.
Очевидно, что большое количество ветвей дерева решений перекрываются или находятся достаточно близко в пространстве признаков – если бы это было не так, то ФПВ исходных монофонов также не перекрывались бы в пространстве признаков, то есть распознавание монофонов выполнялось бы безошибочно, и проблема распознавания речи была решена уже на уровне монофонов, однако это не так. Поэтому метод построения дерева решений обычно дополняется процедурами «связывания состояний», смысл которых состоит в нахождении и объединении близких состояний, принадлежащих различным ветвям дерева решений.
Таким образом удаётся значительно уменьшить количество независимых состояний и, следовательно, количество обучаемых параметров моделей.
9. МЕТОДЫ НОРМАЛИЗАЦИИ И АДАПТАЦИИ 
Условия, в которых проходит эксплуатация систем автоматического распознавания речи, практически никогда не совпадают с условиями, в которых проходило обучение акустических моделей.
Следствием этого является то, что построенные модели не являются оптимальными для данных условий.
Перечислим основные факторы, искажающие речевой сигнал или обусловливающие его вариативность (рис.9.1.): 
1. Голосовой тракт и манера произнесения.
Этот фактор определяет вариативность сигнала.
Как бы ни была велика обучающая выборка, всегда найдутся дикторы, отличающиеся по своим характеристикам от представленных в базе.
2. Аддитивный шум, всегда присутствующий в обычных помещениях.
3.Реверберация (мультипликативный шум) – переотражённый от стен основной сигнал (рас сматриваться далее не будет).
4. АЧХ микрофона и канала передачи («свёрточный шум»).
5. Аддитивный шум канала передачи.
6. Преобразование сигнала фильтром Найквиста и шум квантования (рассматриваться не будут).
Рис.9.1. Факторы, влияющие на оцифрованный сигнал [2] 
Смысл процедур нормализации и адаптации проиллюстрируем с помощью рис. 9.2.
Бороться с источниками вариативности и искажений можно двумя способами: пытаться восстанавливать исходный речевой сигнал, модифицировать вычисленные признаки, или перестраивать акустические модели состояний в соответствии с возмущениями.
Методы восстановления исходного сигнала из зашумлённого рассматриваются в курсе, посвящённом обработке сигналов и шумоподавлению, и поэтому здесь рассматриваться не будут.
Отметим только, что обычно сигнал, прошедший процедуру шумоподавления, не обеспечивает распознавания на высоком уровне.
Это происходит потому, что операции над сигналом направлены на удовлетворение субъективных критериев качества и разборчивости звука и не настроены на приведение зашумлённых признаков к признакам, характерным для чистого сигнала.
Практика показывает, что гораздо лучшие результаты даёт обучение акустических моделей с помощью обучающей выборки, зашумлённой аналогичным шумом.
Но обучение – это трудоёмкая процедура, а разнообразие шумов огромно, поэтому задача ставится так: используя акустические модели, полученные в каких-то фиксированных условиях (обычно с минимальным шумом), научиться распознавать речевой сигнал, полученный в других шумовых условиях.
Таким образом, в дальнейшем изложении ограничимся рассмотрением методов, преобразующих признаки, или модифицирующих акустические модели.
Методы, решающие задачу первым способом, обычно называют методами нормализации, вторым – адаптации.
Отметим, что модели гласных /i/ и /e/ дикторов HXS0 и особенно DAS 1 на рис. 9.2 заметно смещены относительно дикторонезависимых моделей.
Это вызовет ошибки при распознавании.
Два предложенных выше метода сводятся к следующему.
Нормализация признаков – процедура преобразования признаков речевого сигнала данного диктора, благодаря которым индивидуальные модели данного диктора сместятся в области, соответствующие максимумам функций плотности вероятности (ФПВ) для соответствующих состояний дикторонезависимых моделей.
Адаптация моделей – процедура смещения дикторонезависимых моделей в сторону индивидуальных моделей данного диктора.
Способы адаптации можно разделить на адаптацию с учителем (когда известна текстовка дополнительного речевого материала нового диктора) и без учителя, а также на пакетную, инкрементную и мгновенную.
Пакетная – наиболее часто используемый вариант адаптации с учителем, когда имеется небольшая дополнительная база нового диктора.
Инкрементная – адаптация без учителя по каждой новой фразе диктора.
Каждая следующая фраза распознаётся с параметрами модели, адаптированными по предыдущей.
Рис. 9.2. Кривые равной плотности вероятности дикторонезависимых (ДН) и дикторозависимых моделей для монофонов /i/ и /e/ [2] 
Мгновенная – по-существу, вариант инкрементной, когда речевого материала хватает только на одну адаптацию, то есть фраза распознаётся после адаптации по самой себе.
9.1. Вычитание среднего кепстра Метод позволяет исключить АЧХ линии и микрофона, если они меняются достаточно медленно.
Рассмотрим сигнал после линейного фильтра, описывающего АЧХ: HXY,   (9.1) где X – входной сигнал, H – импульсный отклик фильтра, Y – выходной сигнал, ⊗ – символ свёртки.
После преобразования Фурье выражение (9.1) принимает вид: hxyt t,   (9.2) где xt, h, yt – векторы Фурье преобразования соответственно X, H и Y для окна, привязанного к моменту времени t. Считаем, что передаточная функция на интересующем нас интервале времени от t не зависит.
Логарифмирование приводит к выражению: lh lx lyt t,   (9.3) где lxt, lh, lyt – логарифмы, соответственно, xt, h, yt.
Применяя косинусное преобразование, получим кепстр: H X lh lxC ClyYt t t t ) (,   (9.4) где С – матрица косинусного преобразования.
Усреднение (9.4) по некоторому интервалу времени T даёт: HX H XTYTYT ttT tt    1 01 0) (1 1.
(9.5) Вычитая (9.5) из (9.4), получим: t t t t t t X X X YYY ˆ ˆ ,   (9.6) то есть избавляемся от влияния передаточной характеристики канала и микрофона.
Возникает вопрос: какова должна быть длительность усреднения Т для эффективной работы алгоритма?
Очевидно, что если это время сравнимо с длительностью стационарных фонем, то усреднение практически уничтожит соответствующие им векторы пр изнаков.
При слишком большой длительности алгоритм не сможет отслеживать изменения АЧХ, например, из-за движения источника звука относительно микрофона.
Практика показывает, что усреднение на 2–4 секундах даёт наилучшие результаты.
Метод даёт до 30% относи тельного улучшения качества распознавания на различных телефонных каналах.
Небольшое улучшение наступает даже при применении метода в неизменном окружении с тем же микрофоном.
Это можно объяснить тем, что метод «отрабатывает» движение диктора относительно микрофона, а также вычитает среднюю частотную характеристику диктора, оставляя только динамические характеристики.
Недостатком метода в описанной выше форме является то, что вычитание среднего кепстра осуществляется на всём сигнале – речи и паузах.
Корректное моделирование паузы является важной составляющей метода СММ, поэтому её искажение может привести к плохим результатам.
В усовершенствованном методе средний кепстр оценивается отдельно для речи и пауз.
Наилучшим выделителем речи является сама система распознавания, что приводит к часто встречающейся ситуации «курица-яйцо».
В качестве альтернативы двухпроходной системе распознавания предлагается, наряду с качественным детектором речи, использовать линейную комбинацию средних кепстров в пограничных зонах « речь-пауза», что позволяет уменьшить скачки кепстра при ошибках в определении границ.
Предложенная процедура получения среднего удобна при работе с файлами, однако при работе с потоком речи в реальном масштабе времени важно иметь текущую оценку среднего кепстра.
Для текущей оценки можно использовать рекурсивный фильтр первого порядка (интегратор с утечкой):), (ˆ) 1(11   tt t t tt t t YY YYYY Y Y ,   (9.7) где коэффициент α подбирается таким, чтобы постоянная времени фильтра τ была не меньше 5 сек. Если частоту квантования обозначить Fs, то α=1/ exp/(1/(τ* Fs)).
Учитывая, что, τ* Fs>>1, α≈1-1/(τ* Fs).Был предложен другой фильтр [10], который, кроме «мягкого » вычитания среднего (коэ ффициент рекурсивной части 0.98, а не 1), обладает другими полезными свойствами (см. раздел 3): 1 4 3 1ˆ98.0 5.0 5.0ˆ    t t t t t t Y Y Y Y YY.
(9.8) В статье [10] фильтр применяется к спектру, однако его свойства позволяют применять его и ему подобные фильтры непосредственно к кепстральным коэффициентам.
9.2.
Адаптация акустических моделей к шуму векторны ми рядами Тейлора Дальнейшее изложение следует работе [30].
Запишем в стандартной форме влияние передаточной функции («свёрточного шума») h[m] и аддитивного шума n[m] на сигнал x[m] (m – отсчёты времени): ][ ][ ][ ][ mn mh mx my ,   (9.9) В частотном представлении: 2 2 22)()()(|)(|i i i i fN fHfX fY  , fi – частота.
(9.10))).
)(ln)(ln)(exp(ln1ln()(ln)(ln)))()()(1()()(ln())()()(ln()(ln 2 2 2 2 22 22 2 22 2 2 2 i i i i ii ii i ii i i i fH fX fN fH fXfHfXfNfHfXfN fHfX fY        (9.11) Обозначим:),)(,...,)(,)((ln),)(,...,)(,)((ln),)(,...,)(,)((ln),)(,...,)(,)((ln 2 2 12 02 2 12 02 2 12 02 2 12 0 MMMM fY fY fYfN fN fNfH fH fHfX fX fX CyCnChCx  (9.12) где С – матрица косинусного преобразования.
Тогда, применив косинусное преобразование к (9.11), получим:,h)x g(nhxy  (9.13) где функция g(z) имеет вид:)).
exp(1ln(1zC C g(z) (9.14) Отметим, что, поскольку матрица косинусного преобразования унитарная,     C- 1=CT.
Предполагаем, что x, h и n распределены по Гауссу со средними μx, μh, μn и ковариационными матрицами Σx, Σh и Σn и что x, h и n независимы.
Найдём якобиан (9.13) по отношению к x, h и n:.)))
(exp(11())) (exp(11())) (exp(11())) (exp(11)) (exp(1())) (exp(1)) (exp((1 1),, (1 11 111 111 11),, (A ChxnCCyA ChxnCCChxnCC CICIChxnChxnCCIChxnChxnCCIxy              diaghdiagdiagdiagdiag n h xn h x   (9.15).)
)) (exp(11())) (exp(11())) (exp(11)) (exp(1())) (exp(1)) (exp((.
1 11 111 111 11),,(AI C hxnCCIC hxnCC CICC hxnChxnCCC hxnChxnCCy                diagdiagdiagdiagn n h x, где diag(a) – диагональная матрица с вектором a на диагонали.
Теперь можно приближённо оценить y (9.13) в окрестности точки μx, μh, μn с точностью до 1-го члена ряда Тейлора:))(() () () (n h x h x n h x μnАIμhАμxАμμμgμμy  (9.16) Среднее от y может быть получено из (9.16):) (h x n h x y μμμgμμμ .
(9.17) Ковариация:.)
() () ())()(())(())(()))(((T T TT T n nT T h hT T x xT y y yE АIΣАI ААΣ ААΣАIμnμnАI АμhμhА АμxμxАμyμyΣ n h x    (9.18) Если h – неизменная передаточная характеристика, то.)
() (T T y АIΣАI ААΣΣn x  (9.19) Для оценки дельта и дельта-дельта признаков используют факт, что дельта признак приближённо пропорционален производной с коэффициентом 4, а из (9.16) следует: t t xAy, кроме того, здесь считаем, что аддитивный шум стационарный (μ Δn=0),тогда: x yAμμ  (9.20) и T T) () (АIΣАI A AΣΣn x y     ,  (9.21) считаем, что 0h, передаточная функция постоянна.
Аналогично: x yAμμ , T T) () (АIΣАI A AΣΣn x y     .
(9.22) ΣΔn оценивается, исходя из независимости nt+2 и nt-2: ΣΔn= 2Σ n,   (9.23) аналогично, n2 находится, исходя из предположения о независимости nΔt+1 и nΔt-1: n =4Σn.
(9.24) Для состояния j, гауссовой функции k (в окрестности точки μ x,jk) матрица А (9.15) имеет вид: 1,1))) (exp(11(    C μμμCC A h jkx njk diag,  (9.25) а гауссово среднее (9.16) с точностью до членов ряда Тейлора 1-го порядка (см.производные (9.18), (9.21),(9.22)): T jk jkT jk jk jk jkT jk jkT jk jk jk jkjkx jk jkyjkx jk jkyn jk h h jk h jkx n h jkxh jkx n h jkx jky) () (,) () (,,),)(() () () (,,,,,,,,0, 0, 0,, 0, 0,,,,, АIΣ АI AΣAΣАIΣ АI AΣAΣμAμμAμμμ AIμμAμμμgμμμμμgμμμ n x yn x y             (9.26) Ковариационная матрица Σy,jk (9.11) имеет вид:.)
() (,,T jk jkT jk jk jk jky АIΣАI АΣАΣn x    (9.27) Для нахождения параметров шума используется ОМ алгоритм (максимизации ожидания- Expectation-maximization, EM-algorithm) со стандартной вспомогательной функцией:),|(log),,())|((log(),(_       kyp kj yP E Qt t jkt t j    , (9.28) где γt(j,k,λ) – вероятность гауссовой функции k для вектора y в момент времени t при используемых оптимизируемых параметрах модели λ.При использовании алгоритма Витерби значение состояния j определяется моментом времени t: 1),,(  j ktkj,если в момент времени t система находится в состоянии j. Для определения максимума вспомогательной функции (9.28) производные от),(_ Q по μn и μh приравниваются 0: 0] [) (),,(,1,    jky t jkyT jk t jkt jkj  y АI, (9.29).0] [),,(,1,    jk t jk t jkt jkjy yμyΣ (9.30) Подставляя μy,jk из (9.26) в (9.29), (9.30) получаем среднее шума μ n из (9.29) и среднее канала μ h из (9.30):)} ([) (),,({)} () (),,({ 0,, 0, 0,,1,1 1, 0, h jkx n h jkx t jkT jk t jktjk jkT jk t jkt n n jj kjkj μμμgμμyΣ АIАIΣ АI μμ yy           ,(9.31))} ([),,({}),,({ 0,, 0, 0,,1,1 1, 0, h jkx n h jkx t jkT jk t jktjk jkT jk t jkt h h jj kjkj μμμgμμyΣ ААΣ А μμ yy           .
(9.32) Уравнения (9.31) и (9.32) представляют шаги итерации ОМ алгоритма.
Шаги алгоритма: 1.
Положить средние канала μh,0 равными 0; 2.
Инициализировать средни й вектор шума μn,0 и диагональную ковариационную матрицу Σn,0 по первым и последним отсчётам сигнала, свободным от речи; 3.
Вычислить Ajk (9.17) и обновить параметры по формулам (9.26), (9.27); 4.
Декодировать сообщение с новыми параметрами; 5.
Пересчитать параметры γ t(j,k,λ) в соответствии с алгоритмом обучения и оценить новые значения средних шума и канала (9.31) и (9.32); 6.
Если сегментация и параметры не установились, перейти к п. 3.
В случае, когда аддитивный шум отсутствует, а свёрточный шум представ ляет собой постоянную передаточную функцию, поправки к параметрам моделей приобретают чрезвычайно простую форму.
Поскольку в выражении (9.11) N(f i)==0, в конечной строке присутствуют только 2 2)(ln)(lni i fH fX.
Проводя все вычисления согласно формулам (9.12 и 9.15), обнаружим, что матрица А, определяющая якобиан, является единичной.
Легко проверить, учитывая то, что h – неизменная передаточная характеристика, что изменению подвергнутся только средние моделей: h x yμμμ, где hμ – вектор,получающийся из вектора передаточной функции после логарифмирования и косинусного преобразования (то есть преобразования MFCC).
9.3. Байесовская адаптация Предположим, что дикторонезависимые модели построены.
Это означает, что известны средние и ковариационные матрицы гауссовых функций, аппроксимирующих функции плотности вероятности состояний в пространстве признаков.
Если новый диктор представлен речевым материалом, не достаточным для построения собственных дикторозависимы х моделей, можно, тем не менее, использовать этот материал для коррекции дикторонезависимых моделей тех трифонов, которые достаточно представлены в базе нового диктора.
Рассмотрим только преобразование средних гауссовых функций siik,, для м етода Витерби, где k – номер состояния, i – номер гауссовой функции в смеси, si – имеет смысл «дикторонезависимый» (speaker independent).
С помощью дикторонезависимых моделей мы можем отсегментировать речевой материал на участки, соответствующие выбранным моделям.
Тогда средние соответствующих гауссовых функций, описывающих состояние k для нового диктора, можно рассчитать по формулам: jksxjjik sdikNx k j,,,,,  ,   (9.33) где символ sd имеет смысл «дикторозависимый» (speaker dependent), sk – состояние k, xj – совокупность векторов дополнительной выборки нового диктора, ɣk,i,j – коэффициент, с которым вектор xj присутствует в гауссовой функции ikG, смеси:  mj mk mkj ikik jikx Gcx Gc)()(,,,,,,,  (9.34) ck,i – коэффициенты гауссовой смеси, Nk,i – эффективное количество векторов признаков, присутствующее в гауссовой функции ikG, смеси:   kjsxjik ikN,,,.
(9.35) Новое, откорректированное значение среднего предлагается рассчитывать по следующей формуле: siik iksdik ikik ikN NN,,,,,,,,ˆ .
(9.36) Параметр τ определяется эмпирически на обучающей выборке.
Смысл формулы (9.36) заключается в том, что, если количество данных для данной компоненты гауссовой смеси невелико, то новое значение среднего будет мало отличаться от исходного дикторонезависимого варианта, если же Nk,i велико, то новое значение будет приближаться к дикторозависимому варианту μk,i,sd.
Очевидно, что формула (9.36) «разрушает» структуру функции плотности вероятности – средние гауссовых функций смещаются на расстояния, определяемые количеством данных, что может быть случайным фактором, особен но для небольших объёмов речевого материала нового диктора.
Для того чтобы обойти этот недостаток, можно поступить следующим образом: параллельно полным трифонным моделям строятся монофонные модели, аппроксимированные одной гауссовой функцией.
Смещение определяется по формуле (9.36), но количество гауссовых функций в смеси равно 1.
Для каждого монофона определяется смещение: sdk k k,ˆ.
(9.37) Далее все средние гауссовых функций, описывающих модели трифонов, являющихся наследниками данного м онофона, смещаются на Δ k. Поскольку количество параметров моделей монофонов, аппроксимированных одной гауссовой функцией, довольно мало, этот метод не требователен к объёму дополнительного обучающего материала.
Данный метод получил наименование MAP – maximum a posteriori probability.
9.4.
Линейная регрессия максимума правдоподобия Данный метод адаптации позволяет получить смещение средних гауссовых функций даже для тех трифонов, которые не представлены в дополнительной обучающей выборке нового диктора.
Новые средние гауссовых функций для некоторого множества состояний предлагается искать в виде: mk k mkW,,ˆ,   (9.38) где mk,ˆ – преобразованный средний вектор гауссовой функции с номером m, принадлежащей гауссовой смеси, аппроксимирующей одно из состояний, принадлежащих множеству состояний с номером k, Wk – матрица преобразования размерности [ n+1,n], n – размерность векторов признаков, ξk,m – расширенный исходный средний вектор: T mkT nmk mk mk ],1[ ],...,,1[,,, 1,,,    .
(9.39) Таким образом, все средние векторы гауссовых функций, аппроксимирующих функции плотности вероятности для некоторого множества состояний, преобразуются одной матрицей преобразований.
Остаётся определить принцип, согласно которому состояния будут объединяться в одинаково преобразуемые множества и оптимальный, в некотором смысле, способ вычисления матрицы преобразований по дополнительной обучающей выборке нового диктора.
В качестве одинаково преобразуемых множеств, которые в рамках данного алгоритма называются классами регрессии, можно использовать множества состояний, которые образуются на определённом уровне построения дерева решений или кластеризации, управляемой данными (см. разделы 8.1., 8.2.
).
Уровень объединения трифонов, на ко тором следует остановиться, зависит от объёма дополнительного речевого материала нового диктора и определяется эмпирически.В работе [ 29] приводятся результаты эксперимента, в котором дополнительный речевой материал составлял 40 предложений, а количество классов регрессии увеличивалось от 1 (все трифоны преобразуются одинаково) до 40.
Оказалось, что минимум ошибки достигался при 15 классах регрессии, а затем начинал возрастать, что свидетельствовало о недостаточности новых данных для оценки большего количества параметров (векторов средних).
Отметим, что метод позволяет и более мелкое деление, чем описано выше.
Так, отнесение гауссовых функций одного состояния к двум или более классам регрессии в соответствии с некоторой мерой близости позволило бы не только смещать функцию плотности вероятности как целое, но и менять её форму.
Однако обычно стоит задача получить приемлемые модели с минимумом новых данных, которые не позволяют столь мелкое деление.
Рассмотрим задачу определения матрицы преобразования Wk.
В основе метода лежит принцип максимизации правдоподобия:)ˆ|(max XP W kWk,   (9.40) где X – векторы признаков дополнительного речевого материала нового диктора, ˆ – адаптированные параметры моделей, полученные с помощью преобразования (9.38).
Как обычно, максимизацию выражения (9.40) выполняют с помощью ОМ алгоритма и вспомогательной функции Q [31]:)ˆ|,(log()|,())ˆ|,((log(1   sxP sxP sXP EQt SstT t  , (9.41) где E – математическое ожидание, λ – текущие параметры моделей, S – все возможные цепочки состояний, возникшие при распознавании речевого материала, T – количество векторов признаков в речевом материале, tx – вектор признаков в момент t. Очевидно, что любое изменение параметров, определяющих ФПВ моделей, приводит к изменению сегментации (длительностей состояний), что, в свою очередь, приводит к изменениям вероятностей переходов.
Однако, влияние параметров ФПВ на вероятности переходов и вероятностей переходов на значен ие функции Q незначительно, поэтому выражение (9.41) упрощают, отбрасывая аддитивную добавку, связанную с вероятностями переходов, которую считают константой:   SsT tt s t xb sxP Q 1))(ˆ log()|,(,  (9.42) где sbˆ – адаптированная ФПВ состояния s. В сумме по состояниям участвуют все состояния данного класса регрессии.
Напомним, что согласно концепции метода Баума-Уэлша, в каждый момент времени марковский процесс проходит через все состояния с различными вероятностями, поэтому выражение (9.42) можно пер еписать так:))(ˆ log()()|(1 1tK pT tp t xb p XPQ  ,  (9.43)где ɣt(p) – вероятность посетить состояние sp в момент времени t для последовательности наблюдений X (см. формулы 6.25, 6.33), K – количество состояний.
В соответствии с формулой (6.30) представим ФПВ состояния sp в виде суммы гауссовых функций:),ˆ,()(ˆ,, 1mp mp tM mm t p U xGc xbp  .
(9.44) Подстановка (9.44) в (9.43) приводит к сумме логарифмов во вспомогательной функции, что делает затруднительной максимизацию.
Элегантный выход предлагает алгоритм ОМ [32].
Если представить отдельные гауссовы функции проявлением ненаблюдаемых случайных параметров Y, то, учитывая фо рмулу (6.33) для ɣt(p,m), формально выражение (6.43) можно представить в виде:) ())()(,()ˆ ()ˆ)()(,(,1, 1 1 1,, 1 1 11,, mpk t mpK pM mT tT mpk t tmp tK pM mT tmpT mp t t Wx U Wxtmp constx U xtmp constQ kk             .
(9.45) Дифференцируя (9.45) по Wk и приравнивая производную нулю, получим матричное уравнение: T mpmpkK pM mT tmp tT mpK pM mT ttmp t WUmp x Umpk k,, 1 1 11,, 1 1 11,),(),(       .
(9.46) В общем виде уравнение (9.46) можно решать только численно путём последовательных итераций.
Однако если прибегнуть к обычному упрощению и использовать диагональные ковариационные матрицы U, возможно аналитическое решение.
Введём матрицы: T mptmpK pM mT ttKxUmp Zk,1, 1 1 1)(),(  ,  (9.47) T mp mp mpD,,,,   (9.48)  T tmp t mp Ump V 11,,),(.
(9.49) Теперь (9.46) можно записать в следующем виде:  K pM mmp K mpK DWV Z 1 1,,.
(9.49) Используя то, что D – симметричная, а V – диагональная матрицы, уравнение (9.49) можно представить в поэлементном виде:  1 1)(,)(,,n qi qjK qi ji gw z,   (9.50) где:  K pM mqjmpiimpi qjK d v g 1 1,,,,,,)(,.
(9.51)Используя для каждой строки матрицы Z свою обратную матрицу G(i)-1, получим формулу для построчного вычисления искомой матрицы W: 1)(i i i Gz w,   (9.52) где wi и zi – векторы-строки соответствующих матриц.
Поскольку матрицы G(i)-1 сингулярные, используется алгоритм псевдообращения.
Данный метод получил название MLLR – maximum likelihood linear regression.
9.5. Метод собственных дикторов 
Рассмотрим пространство на супервекторах, образованных из средних гауссовых функций каждого диктора [33, 34].
Построим матрицу из этих векторов для обучающей выборки, содержащей речь P дикторов, для аппроксимации ФПВ состояний которых используется R гауссовых функций:       RP PR M, 1,,1 1,1 .
(9.53) Применив метод главных компонент к матрице М, получим собственные векторы, которые называются «собственными дикторами».
Первые главные компоненты обычно соответствуют полу диктора, громкости речи, монотонности, и т.д. Используя небольшое количество первых главных компонент, можно представить нового диктора в виде линейной комбинации собственных дикторов, исходя из максимума правдоподобия L наблюдений X:),|(maxarg wEXL w w,   (9.54) где Х – речевой материал нового диктора, Е – набор собственных дикторов, w – искомый вектор коэффициентов.
Максимизация, как обычно, осуществляется с помощью ОМ-алгоритма путём дифференцирования стандартной вспомогательной функции (9.28, 9.42) по искомым параметрам.
9.6. Нормализация признаков по длине голосового тракта 
В разделе 1.2., посвящённом вопросам речеобразования, было показано, что при сохранении формы голосового тракта частоты формант обратно пропорциональны длине тракта.
Это означает, что, например, для детей и, в среднем, для женщин все форманты должны быть смещены вверх относительно «среднего мужчины».
Теоретически волноводу любой длины можно придать такую форму, что собственные значения краевой задачи волнового уравнения, которые проявляются как форманты, примут любые заданные значения.
Но органы управления формой голосового тракта – нёбная занавеска, язык, нижняя челюсть, губы – имеют ограниченные возможности по управлению, поэтому указанная тенденция отчётливо проявляется в экспериментах (рис. 9.3).
Интересно отметить, что средние различия между формантами для мужских и женских голосов зависят от языка (рис. 9.4).
Это может свидетельствовать о том, что речевой аппарат человека, вообще говоря, может выставлять форманты достаточно точно, но структура языка иногда не требует этого.
Этот факт ставит интересные вопросы в области восприятия речи, которые выходят за рамки курса (и на которые мы не знаем ответов).
Отметим два интересных момента: только в русском языке различия между первыми формантами превышают о дин барк, а между вторыми – полтора.
(Из раздела 2 –барк является важной единицей, полученной в экспериментах по восприятию, определяющей качественно различные для восприятия звуки).
При этом различия между третьими формантами существенно меньше, что довольно удивительно, поскольку третью форманту считают наименее информативной и, следовательно, менее жёстко контролируемой.
Рис. 9.3. Пример произнесения слова « cat» дикторами мужского и женского пола [36].
Если предположить, что в реальной речи значения формант действительно обратно пропорциональны длине голосового тракта, то процедура приведения формант к одинаковым значениям очевидна – достаточно линейно исказить шкалу частот.
При этом даже не нужна информация о длине тракта – производится распознавание речи с различными шкалами и для дальнейшего распознавания данного диктора выбирается шкала, для которой получена наибольшая апостериорная вероятность распознавания для данного высказывания.
Однако при таком подходе требуется решить две проблемы: 1.
Преобразование Фурье охватывает частоты от 0 Гц до частоты Найквиста.
При линейном искажении шкалы (Fnorm=αF) в случае α<1 участок преобразованного спектра от αFN до FN не будет содержать информации, а для α>1 исходный спектр от FN/α до FN не будет отражён в преобразованном (FN – частота Найквиста).
2. Спектральный состав шумовых звуков языка определяется, в основном, параметрами сужения, а не длиной тракта.
Рис. 9.4. Различия между формантами для мужских и женских голосов для различных языков [ 35].
Для решения указанных проблем предложены непрерывные искажающие шкалы, начинающиеся в 0 Гц и заканчивающиеся на частоте Найквиста (рис. 9.5.).
Оказалось, что все они дают достаточно близкие результаты. В настоящее время предпочтение отдают шкалеe).
Шкалы используются следующим образом: после вычисления спектра Фурье для каждой исходной частоты спектра fi=i*Δf, где Δ f – шаг спектра (Δ f= FN/W, W – длина окна анализа), рассчитывается нормализованная частота.
Значение спектра для этой частоты получают с помощью интерполяции (обычно линейной) исходного спектра.
Далее нормализованный спектр используется по обычной схеме (см. MFCC признаки, раздел 3).
Рис. 9.5. Варианты искажающих шкал [37, 38].
Процедуру нормализации спектра можно перенести в шкалу мел.
Можно также рассчитать матрицу преобразований кепстральных коэффициентов, применение которой приближённо эквивалентно искажению шкалы частот, рассмотренной выше [3 6].
Такой метод называется «линейной нормализацией по длине голосового тракта» (рассмотренное выше преобразование шкалы частот, очевидно, приводит к нелинейному преобразованию конечных MFCC признаков).
С вычислительной точки зрения линейное преобразование более эффективно, поскольку число подлежащих интерполяции отсчётов спектра обычно равно 256, а количество кепстральных коэффициентов обычно не превышает 12 –14.
Что касается проблемы невокализованных звуков, для которых форма вокального тракта не имеет большого значения, то эксперименты по раздельному нахождению коэффициентов искажения шкалы частот для различных фонем [37] практически не дали улучшения распознавания.
Возможно это связано с тем, что частотные характеристики таких звуков лежат в верхнем диапазоне речевого спектра, где все шкалы сближаются.
Рассматривая методы нормализации признаков или адаптации моделей для новых дикторов, обратим внимание на то, что процедура получения моделей включает в себя процесс распознавания, то есть операцию, для более точного выполнения которой и применяются нормализация признаков и адаптация моделей.
Поэтому логично эти процедуры включить в модуль обучения.
Такой вид обучения называется «обучение, адаптивное к дикторам» (SAT – Speaker Adap tive Training).
Ожидаемые преимущества очевидны: во-первых, модели, полученные c применением адаптивных методов компактнее в пространстве признаков и, следовательно, требуют меньше ресурсов (гауссовых функций) для своей аппроксимации, во-вторых, благодаря компактности, области, соответствующие различным моделям, имеют меньшее перекрытие, что означает меньшую ошибку распознавания (см. рис. 9.2).
10. ДИСКРИМИНАНТНЫЕ МЕТОДЫ 
Рассмотрим основополагающие формулы (6.2), (6.3) из раздела 6:),|(maxarg XWP W W (10.1))()|()(maxargXPWXPWPW W,  (10.2) где W – последовательность слов, X – последовательность векторов-признаков речевого сигнала.
Поскольку параметры модели при распознавании не изменяются, вероятность наблюдений P(X) является константой.
Однако в процессе обучения эта вероятность зависит от параметров моделей λ. Выразим этот факт в явном виде: P(X| λ).
Поскольку различные марковские модели Wj взаимно исключают друг друга,  kk k WP WXP XP),(),|()|(  (10.3) где суммирование производится по всем возможным последовательностям моделей.
Используя (10.3), и (10.2), запишем вероятность модели Wj, явно выделяя в знаменателе соответствующий член суммы (10.3) :   ikk k i ii i iWP WXP WP WXPWP WXPXWP)(), ()(), ()(), (), ( .
(10.4) Обычно вероятность P(Wi|X,λ) максимизируют в подпространстве параметров Wi, что ведёт к критерию максимального правдоподобия, то есть к оценке параметров, максимизирующих числитель (10.4).
Вероятность P(Wi) получают из «модели языка» (раздел 13), которая позволяет оценить вероятности последовательности слов независимо от акустического декодирования.
Данный подход общеупотребителен, поскольку чрезвычайно упрощает задачу, но это достигается ценой малой дискриминантной силы алгоритма.
Под «дискриминантной силой» понимается способность ал горитма разделять гипотезы.
Достижение наилучшего разделения гипотез совсем не обязательно сопровождается увеличением правдоподобия правильной гипотезы.
С другой стороны, максимизация P(Wi|X,λ) в полном пространстве приводит к дискриминантному алгоритму, н о требует вычисления всех или наиболее вероятных конкурирующих гипотез, представленных частью знаменателя  ikk k WP WXP)(), (, которую следует уменьшать.
Существуют различные техники дискриминантного (дискриминативного) обучения, максимизирующие P(Wi|X,λ) – это «корректирующее обучение», «максимизация взаимной информации», «минимизация фонемной ошибки» или «минимизация ошибки классификации» [ 31, гл. 4].
Эти методы дают существенное улучшение распознавания на небольших словарях, однако при увеличении словаря дополнительные вычислительные затраты становятся чрезмерными, а преимущества незначительными.В настоящее время получило распространение использование нейронных сетей, которые, помимо новых возможностей, как правило, создают модели, обладающие дискриминантными свойствами.
Рассмотрим современные системы, использующие «длительные» контекстные признаки и искусственную нейронную сеть в качестве классификатора.
10.1. Долговременные признаки 
Долговременные признаки, или TRAP-признаки (TempoRAL Patterns) впервые были предложены в работах [39, 40].
В отличие от традиционных спектральных методов, основная идея предложенного метода заключается в использовании признаков, полученных путем объединения результатов вычисления энергии мел-фильтров на нескольких фреймах.
Блок-диаграмма вычисления TRAP-признаков представлена на рис. 10.1.
Процесс формирования долговременных TRAP-признаков начинается с вычисления энергии в мел- фильтрах.
Речевой сигнал разбивается на фреймы длиной 25 мс с шагом 10 мс.
Мел-фильтры эмулируются взвешиванием энергетического спектра речевого сигнала треугольными окнами, расположенными в логарифмическом масштабе.
Значения, получаемые на выходе каждого из фильтров, затем суммируются и логарифмируются.
Процедура повторяет получение MFCC коэффициентов (раздел 3.)
за исключением кепстрального преобразования.
Векторы TRAP- признаков формируются путем объединения нескольких значений внутри одной критической полосы мел-фильтра, то есть новый вектор признаков формируется из компоненты с одним номером не скольких последовательных векторов логарифма мел-спектра.
Таким образом, TRAP-признаки – это набор независимых векторов, описывающих изменение во времени энергии речевого сигнала для каждой из критических полос мел-фильтра.
Дополнительно к данному вектору признаков можно применить нормализацию по среднему и СКО (среднеквадратическому отклонению), а также взвешивание с помощью окна Хэмминга.
Полученный вектор признаков поступает затем на нейросетевой классификатор, выходы которого являются апостериорными вер оятностями классов фонем или состояний фонем.
Нейросетевой классификатор используется в каждой из критических полос мел-фильтра.
Выходные данные нейросетевых классификаторов поступают на вход merger-сети – нейронной сети, целью которой является объединение результатов распознавания, независимо полученных на различных критических полосах мел- фильтра.
В описанных выше процедурах вычисляется вероятность появления фонемы для центрального фрейма вектора TRAP-признаков.
Рис. 10.1. Блок-диаграмма системы на основе TRAP-признаков [41].
Эксперименты с TRAP-признаками показали, что система, основанная на них, существенно превосходит стандартную систему, основанную на MFCC или PLP признаках – относительное уменьшение ошибки распознавания составило более 10%.
Также было обнаружено, что ошибки систем с этими признаками не очень сильно коррелируют, что позволяет использовать их совместно, дополнительно уменьшая ошибку.
С другой стороны, системы, основанные на данных признаках, требуют больших вычислительных затрат из-за использования нейросетевых классификаторов в каждой критической полосе, а также большого объема речевых баз данных для обучения.
Длина вектора признаков TRAP может достигать 101 элемента, что соответствует длительности контекста в 1 секунду.
Эксперименты по определению оптимальной длины вектора на основе минимума фонемной ошибки [41] дали длину в 300 –400 мс, что соответствует размерности векторов TRAP-признаков в 31 –41.
(Обычно размерность выбирается нечётной, чтобы сопоставить центральному элементу вектора центр фонетического элемента и иметь одинаковые по длине контексты до и после центральной точки.)
Принимая во внимание результаты этого эксперимента, следует учесть, что на оптимальную длину векторов TRAP-признаков может оказывать влияние объём обучающей выборки – выявление статистических закономерностей в пространстве большей размерности требует соответствующего увеличения базы данных.
Очевидно, вариативность длительных временных признаков имеет ту же приро ду, что и вариативность трифонов (раздел 8.)
– количество различных траекторий экспоненциально возрастает при увеличении контекстных зависимостей, при этом резко возрастает количество не наблюдённых в базе сочетаний фонем.
Так, при использовании тестовой части базы данных TIMIT с 39 фонемами, при учёте биграмм, количество не встреченных сочетаний составляет 1104 или 2.26% от общего числа, при учёте триграмм, соответственно, 8952 и 18.83% и 4-грамм – 20681 и 54.55%.
Этот эффект получил название «проклятье размерности» (the curse of dimensionality).
В настоящее время при исследовании 3–4-граммных сочетаний фонем используются базы данных, содержащие более 1000 часов речи.
Отметим, что для русской речи не существует баз данных такого объема.
Наиболее известные б азы данных, такие как SpeechDat и SpeeCon, содержат порядка 60 –70 часов.
Для преодоления этих трудностей было предложено [41] разбить контекст на левую и правую части.
При этом части обучаются независимо друг от друга и объединяются по том на merger-сети.
Также в [ 41] показано, что за счет разбиения долговременного контекста на две составляющие существенно снижается требование к объему обучающей выборки.
Структура системы с разделенным временным контекстом представлена на рис. 10.2.
На первом шаге извлекается энергия из мел-фильтров и объединяется в 310 мс временной контекст (31 значение).
Далее временной вектор из каждой критической полосы мел-фильтра разбивается на две части — левый контекст (значения 0 –16) и правый контекст (значения 16 –31).
Обе части взвешиваются соответствующими половинами окна Хэмминга, после чего вычисляется дискретное косинусное преобразование (DCT).
Для каждой части сохраняется n коэффициентов DCT-преобразования (число коэффициентов находится экспериментальным путем).
Полученные для каждой критической полосы векторы объединяются в общий левый и правый контексты и подаются на два нейросетевых классификатора, которые формируют апостериорные вероятности аналогично TRAP-системам.
Выходы нейросетевых классификаторов логарифмируются и совместно подаются на merger-сеть, которая также обучена формированию апостериорных вероятностей.
В завершение апостериорные вероятности merger-сети декодируются с помощью Витерби-декодера, в результате чего получаются последовательности фонем.
Данная система бы ла названа авторами LC-RC-система (сокращение от Left context – Right context).
Рис. 10.2. Блок-диаграмма системы на основе LC-RC-признаков [41].
11. УСЛОВНЫЕ СЛУЧАЙНЫЕ ПОЛЯ 
Условные случайные поля (CONDITIONAL RANDOM FIELDS, CRF) – это статистическая модель, иногда применяемая в настоящее время для распознавания образов.
Первоначально модель возникла для объяснения ферромагнетизма [ 45].
Главным отличием этого подхода от метода скрытых марковских моделей (СММ) является то, что в рамках условных случайных полей не делается предположений о вероятностных распределениях моделируемых случайных процессов (как, впрочем, и в рамках моделей, использующих нейронные сети).
Использование условных случайных полей сводится к задаче максимизации энтропии и вычислению условной вероятности речевого сегмента в виде экспоненциальной модели [ 46]:)},,(exp{);(1),|(xswfxZxwp wsT   ,  (11.1) где w – речевой фрагмент (слово, фраза…), s – состояния, x – набор векторов признаков, λ – вектор оптимизируемых при обучении параметров (множители Лагранжа),  f – вектор достаточных статистик,)},,(exp{);(,xswf xZ wsw    – нормирующий множитель, сумма по всем возможным речевым фрагментам.
Форма (13.1) вытекает из решения уравнения Лагранжа при самых общих предположениях относительно достаточных статистик.
В качестве достаточных статистик обычно фигурируют статистики первого и второго порядков:)' () (),,(11)(' sss s xsw ftT ttTr ss    – статистика переходов между состояниями,  T ttOcc s ss xsw f 1) () (),,( – статистика состояний,  T ttj tM js xss xsw f 1,)1(,) (),,( N j,...2,1 – статистика первого порядка,  T ttj tM js xss xsw f 12,)2(,) (),,( N j,...2,1 – статистика второго порядка,      (11.2) где δ – индикаторная функция (1 при выполнении условия, 0 – в противном случае), T – количество векторов признаков в речевом фрагменте, N – размерность пространства признаков.
Для того чтобы прояснить смысл вышеприведённых параметров, покажем, как будет выглядеть в этих терминах вероятность фрагмента в рамках стандартной модели СММ.Полная вероятность речевого фрагмента в терминах СММ (ра здел 6) имеет вид:)|()|(1,1 t tT iss sxB a xwp t t ,  (11.3) где st – состояние в момент времени t, ass’ – вероятность перехода из состояния s в состояние s’, B(x|s) – вероятность эмиссии (функция плотности вероятности) для состояния s. Если функцию плотности вероятности аппроксимировать одной гауссовой функцией с диагональной матрицей ковариации, выражение (1 1.3) примет вид:.
)2()22exp()2()2) (exp()|(1)(212)(2)()(,2, 1,1)(212)(2)(, 1, 11            N js jNN js js js jtj tj T tssN js jNN js js j tj T tss ttt t t tttt t t x x ax a xwp  (11.4) где μj и σj – среднее и среднеквадратичное отклонения для компоненты с номером j гауссовой функции, аппроксимирующей функцию плотности вероятности для соответствующего состояния.
Выберем в качестве начального приближения для множителей Лагранжа следующие выражения [4 7]:.
,...,1,21,,...,1,,2)2 log(), log(2)()2(,)()()1(,1)(2)(1)(2) (',)(', N jN ja s jM jss js j M jsN js js jN js jN Occ sssTr ss         (11.5) Можно проверить, что, если подставить выражения (1 1.5) и (1 1.2) в выражение (1 1.1), мы получим значение условной вероятности, тождественное (11.4) с точностью до нормирующего множителя.
Таким образом, в рассмотренном случае итерации по уточнению множителей Лагранжа в процедуре обучения CRF начинаются с точки, в которой заканчиваются итерации алгоритмов обучения скрытой марковской модели, то есть результаты будут не хуже.
Однако улучшение незначительно.Использование моментов высокого порядка в рамках модели условных случайных полей очевидно.
Можно также учесть модели языка, в этом случае, например, для униграммной модели достаточная статистика и начальное приближение множителей Лагранжа будет иметь вид: ') (') (' log)' (),,(wLM wLM w pww xsw f  ,   (11.6) где pw – вероятность появления слова w. Достат очные статистики (1 1.2) приведены для случая аппроксимации функции плотности вероятности состояний одной гауссовой функцией.
При этом предполагается, что в каждый момент времени система находится в одном состоянии в соответствии с алгоритмом Витерби.
В слу чае, когда функция плотности вероятности аппроксимируется несколькими гауссовыми функциями и принадлежность к состоянию носит вероятностный характер в соответствии с алгоритмом Баума-Уэлша, достаточные статистики имеют следующий вид:  T tt tOcc ms mss xsw f 1) (,), (),,(, sM m,...,2,1  T ttj t tM jms xmss xsw f 1,)1(,,), (),,(, N j,...,2,1, sM m,...,2,1 (11.7)  T ttj t tM jms xmss xsw f 12,)2(,,), (),,(, N j,...,2,1, sM m,...,2,1, где Ms – количество гауссовых функций, применяющихся для аппроксимации функции плотности вероятности состояния s, ɣt(s,m) – вероятность находиться в момент времени t в состоянии s и гауссовой функции m (6.25, 6.23).
12. НЕЙРОННЫЕ СЕТИ Прежде чем перейти к рассмотрению ещё одной группы методов распознавания, остановимся на любопытном факте.
Технологии распознавания речи являются достаточно молодыми, но очень перспективными в коммерческом смысле, что предполагает значительное финансирование и бурный рост.
Однако, несмотря на хорошее финансирование, со времени, когда было предложено использовать марковские модели (середина шестидесятых годов XX века), прогресс в качестве распознавания на протяжении более 40 лет был довольно малым.
Новым методам не удавалось преодолеть уровень результатов, достигнутых непрерывной марковской моделью с гауссовой аппроксимацией функций плотности вероятностей состояний, либо улучшение было столь незначительным, что не стоило существенного усложнения систем.
При этом достигнутые результаты не позволяли использовать системы распознавания речи как массовый коммерческий продукт, хотя конкретные приложения в узких предметных облас тях уже давно работали.
Многим исследователям представлялось, что характер задачи соответствует возможностям искусственных нейронных сетей.
Попытки использования нейронных сетей начались довольно давно.
В качестве примера приведём статью 1990 г. [51], в которой было предложено много перспективных идей.
В частности, использовались долговременные признаки (см. раздел 10.1) в виде одного супервектора, состоящего из 9 последовательных векторов м ел-спектра, и рекуррентная связь между выходным и входным слоями, позволявшие учитывать контекстные зависимости.
Несмотря на то, что в этой системе фактически использовались те же признаки, что и в стандартной марковской модели, плюс упомянутые усовершенствования, превзойти стандартную систему на основе гауссовых смесей не удалось.
Этот факт вызвал такое недоумение в научной среде, что в 1996 вышла статья с красноречивым названием “ Towards increasing speech recognition error rates ” [52], в которой была сделана попытка объяснить длительное отсутствие прогресса в создании систем распознавания речи.
Авторы объясняли отсутствие прогресса тем, что марковская модель на основе гауссовых смесей была принята в качестве базовой в десятках научных центров во всём мире и в течение нескольких лет была предельно оптимизирована, так что любой новой, сырой системе на начальном этапе превзойти её почти невозможно.
Несмотря на то, что приведённый аргумент трудно оспорить, последние работы, использующие многослойные нейронные сети различных типов, доказывают, что есть ещё одна элементарная причина – нейронные сети не обладали достаточной информационной мощностью, поскольку мощность компьютеров не позволяла использовать сети с несколькими слоями и выходным слоем, состоящим из нескольких тысяч нейронов, соответствующих трифонам (а не нескольким десяткам монофонов, как в ранних системах).12.1.
Глубокие нейронные сети Нейронная сеть или перцептрон с любым количеством скрытых слоев является универсальным аппроксиматором [53], т.е. даже сети с одним скрытым слоем, использовавшиеся до этого этапа, могут аппроксимировать любую поверхность в пространстве признаков.
Однако успех в распознавании речи пришел только с использованием многослойных сетей.
Это объясняется невозможностью или крайней трудностью создания разумной методики инициализации весов для сетей с одним скрытым слоем, что приводит к далекому от оптимума набору весов при обучении.
Использование многослойных нейронных сетей поставило новую задачу – разработку новых алгоритмов обучения, поскольку известный алгоритм обратного распространения ошибки без разумной инициализации входных весов нейронов может приводить к неоптимальным решениям.
По-видимому, разработка новых алгоритмов обучения будет трендом работ, связанных с использованием нейронных сетей.
Одним из методов является инициализация с помощью послойного обучения, начиная с нижних слоёв [54,55].
В качестве целевой функции для первого скрытого слоя рассматривается входной вектор признаков.
Исходный вектор может содержать несколько последовательных MFCC или м ел- спектральных векторов-признаков.
Чтобы избежать тождественного преобразования, входной вектор зашумляют.
Следующий слой нейронной сети таким же образом обучают воспроизводить выходные сигналы предыдущего слоя.
Всего таким образом обучают до 5–7 слоёв.
После того, как инициализация первых слоёв проведена, включают стандартный алгоритм обратного распространения ошибки для всей сети с целевой функцией, отражающей принадлежность входного сигнала к соответствующему трифону.
Данный подход показал явное преимущество по сравнению с классическим подходом с гауссовыми смесями : результаты распознавания всегда оказывались лучше, причём многослойная сеть, обученная на речевом материале в 309 часов речи, показала лучшие результаты, чем метод с гауссовыми смесями, обученный на 2000 часах речи.
Любопытно отметить, что предлагаемый алгоритм обучения создаёт систему, напоминающую по функционированию слуховую.
В слуховой системе обнаружены нейроны, реагирующие на определённые события в акустическом сигнале [56, гл. 9].
По мере «углубления» сигнала в центральные отделы слуховой системы характер признаков, выделяемых специализированными нейронами, принимает всё более сложный и избирательный характер.
Предварительное обучение отдельных слоёв нейронной сети, выполняет ту же задачу – отдельные слои обучаются находить признаки сигнала всё более высокого уровня.
Если внутренние слои нейронных сетей выделяют признаки речевого сигнала, характерные для речи вообще, то их можно унифицировать для всех языков, обучая для каждого нового языка только выходной слой нейронной сети (рис. 12.1).
Это было бы чрезвычайно важно, поскольку для обучения только одного слоя нейронной сети требовалась бы гораздо меньшая речевая база данных, чем для обучения всех 5 –7 слоев.
Эксперименты полностью подтвердили такую возможность.
Ис пользование совместно речевых баз данных для французского, немецкого и итальянского языков позволило уменьшить ошибку распознавания на 3,3 –5,4% в относительном выражении по сравнению с моноязыковыми моделями [5 5].
Следует отметить, что содержащаяся во внутренних слоях нейросетей информация о признаках речевого сигнала может быть использована для распознавания речи на неродственных языках.
Были поставлены эксперименты по использованию внутренних слоев нейронной сети, обученной на базе данных европейских язык ов, для дообучения выходного слоя нейросети для китайского языка.
Относительный выигрыш составил от 21,1% до 8,3% при увеличении базы данных китайского языка от 3 до 139 часов [55].
Рассмотренный прием открывает возможность создавать системы распознавания для всевозможных языков, в том числе малоресурсных.
Рис. 12.1. Обучение системы, обученной четырем языкам, пятому языку [55].
Поскольку нейронные сети не могут идентифицировать динамические объекты, для сравнения моделей с сигналом по-прежнему используется формализм марковских моделей, однако теперь в качестве вектора признаков используется набор апостериорных вероятностей трифонов, полученный на выходе нейронной сети.
Такой метод использования нейронных сетей одним из первых предложил для монофонов Х. Германский с соавторами [5 7].
Отметим, что контекстная зависимость, то есть влияние фонем друг на друга, в данном случае моделируется построением входного вектора из нескольких последовательных векторов признаков, описывающих отрезок сигнала длиной около 25 мс.
Окна анализа смещаются на 10 мс.
Таким образом, для того чтобы отобразить отрезок сигнала длиной 300 мс (такие размеры контекстной зависимости были выявлены в работе [41]), требуется около 30 векторов признаков.
Таким образом, размерность результирующего супервектора может составлять от 300 до более чем 1000, в зависимости от размерности исходного вектора признаков.
Работа с векторами такой размерности требует большого количества вычислений.
Более существенным недостатком, присущим данному мето ду, является то, что глубокие нейронные сети не могут распознавать динамические объекты, из- за чего и приходится использовать алгоритм Витерби в рамках марковской модели.
Недостатки марковской модели довольно очевидны : дискретность, или независимость последовательных состояний друг от друга ; отсутствие глубоких временных связей, то есть неспособность распознавать траектории в пространстве признаков как информативные объекты.
12.2. Рекуррентные нейронные сети 
Можно предположить, что оба отмеченных недостатка можно преодолеть, используя рекуррентные нейронные сети.
Рекуррентные нейронные сети содержат нейроны, объединенные в направленный круговой процесс.
Это наделяет нейронную сеть памятью и, следовательно, способностью распознавать процессы, а не только статические объекты, как рассмотренные выше глубокие нейронные сети.
Рекуррентные нейронные сети отличаются от рассмотренных ранее многослойных тем, что при обработке очередного вектора признаков система учитывает также внутренние состояния нейронов, которые, в свою очередь, формируются предыдущими векторами признаков и состояниями в предыдущие моменты времени.
В этом смысле единичная рекуррентная нейронная сеть представляет собой более мощное образование, чем глубокая нейронная сеть.
Тем не менее, рас сматриваются иерархические комбинации рекуррентны х нейронных сетей и комбинации рекуррентных и многослойных сетей.
Это можно объяснить, как и для многослойных сетей, желанием структурировать систему, приблизить её к принципам функционирования нервной системы, упростить процедуру инициализации и обучения.
Надо сказать, что совместное использование глубоких и рекуррентных нейронных сетей открывает много возможностей для создания различных архитектур систем распознавания.
Выбор «правильной» архитектуры может существенно улучшить качество распознавания.
Так, в работе [58] рекуррентная нейронная сеть располагается после «языкового» слоя многослойной сети, или между выходным, «языковым», слоем и последним внутренним слоем (рис.12.1).
В качестве признаков используются апостериорные вероятности фонем с «языкового» слоя и (или) выходы последнего слоя глубокой нейронной сети.
Такую архитектуру можно считать грубой моделью восходящего слухового пути и нижнего уровня центральной слуховой системы.
Хотя качество распознавания по сравнению с рассмотренной выше глубокой нейронной сетью (без рекуррентной) увеличилось всего на 0,4%-0,5% (абсолютно), но самарекуррентная сеть улучшила точность распознавания фонем с 71,8% до 8 1,2% по сравнению с архитектурой, где многослойная сеть отсутствовала и на вход рекуррентной подавались исходные спектральные признаки.
Наряду с поисками архитектуры системы распознавания большое внимание уделяется усовершенствованию рекуррентных сетей.
Де ло в том, что, несмотря на улучшение качества распознавания и возможность обходиться без искусственного метода скрытых марковских моделей, они обладают и недостатками.
Главным недостатком является трудоёмкость и сложность процедуры обучения.
Обычно применяется всё тот же метод обратного распространения ошибки, но, учитывая рекуррентность, развёрнутый во времени- back-propagation-through-time (BPTT).
Основные трудности при этом связаны с обнулением градиента и очень большим временем обучения [59,60].
Рассмотрим основные усовершенствования рекуррентных нейронных сетей, использующиеся в системах распознавания речи.
Обычная рекуррентная нейронная сеть описывается уравнениями :) (1 t hh t xh tf hWxW h (12.1)) (t hy tg hW y (12.2) где: xt, ht и yt – вектор признаков, вектор внутренних состояний нейронов и выходной вектор, соответственно, в момент времени t; Wxh – матрица весовых коэффициентов, свя зывающая входной вектор с вектором внутренних состояний ; Whh – матрица, связывающая векторы внутренних состояний ; Why – матрица, связывающая вектор внутренних состояний с выходным вектором ; f – сигмоидная функция ; g – линейная или softmax функция (напомним, что softmax функция гарантирует нормированность выходного вектора на 1, что позволяет рассматривать компоненты выходного вектора как вероятности).
Размерность вектора состояний h равна числу нейронов в сети.
Размерности матриц очевидны, исходя из размерностей векторов, которые они связывают.
В рекурсии (12.1) может участвовать также выходной вектор, тогда формула (12.1) приобретает вид:) (1 1   t yh t hh t xh tf yW hWxW h,  (12.3) где Wyh – матрица, связывающая выходной вектор с вектором внутренних состояний.
Обучение такой нейронной сети, как обычно, заключается в оптимизации всех или части матриц весовых коэффициентов с целью достижения оптимума по некоторому критерию, зависящему от выходного вектора и целевого вектора для данного момента времени по всей обучающей выборке.
Одним из самых популярных вариантов рекуррентных нейронных сетей, использующихся для распознавания речи, являются сети с нейронами с «длинной кратковременной памятью» (Long Short Term Memory, LSTM) [61-66].
Нейроны в такой сети имеют более сложную структуру и содержат блок памяти, включающий гейты (gates) входа, забывания и выхода со своими векторами состояний.
Такая нейронная сеть описывается следующим набором уравнений:) (1 1 i tci t hi txi tf b cW hWxW i    (12.4)) (1 1 f tcf t hf t xf tf b cW hWxW f    (12.5)) 1 1 tanh(c t hc t xc t t t t b hWxW i cfc    (12.6)) (1 o tco t ho t xo tf bcW hWxW o   (12.7)) tanh(t t c oht (12.8) t t t ho m (12.9)) (y t ym t b mW y  ,   (12.10) где добавляются векторы состояний it, ft, ct и ot – входа, забывания, активации и выхода, соответственно, mt – вспомогательный вектор, ● – поэлементное произведение векторов, b – векторы смещений, σ – логистическая сигмоидальная функция, смысл матриц весовых коэффициентов очевиден, все они полные, кроме Wci, которая диагональна.
Размерность всех внутренних векторов одинакова и равна числу нейронов в сети.
Проблемы с экспоненциальным уменьшением градиента при обучении в данной нейронной сети обходятся благодаря тому, что сигнал ошибки захватывается блоком памяти и продолжает воздействовать на другие гейты, даже если текущий сигнал ошибки исчез.
Ещё один тип рекуррентных нейронных сетей основан на резервуарной модели [ 67-70].
Это простейший вариант рекуррентной сети, основанный на нейронах с утечкой, описывающийся уравнениями, аналогичными (12.1 и 12.2):) () 1(1 1    t hh t xh t t f hWxW h h  (12.11) t hy t hWy,    (12.1 2) где коэффициент λ определяет скорость утечки.
Выходной вектор является линейной комбинацией компонент вектора состояний.
Все компоненты матрицы Whh инициализируются случайными числами и не меняются при обучении.
Целью обучения является оптимизация матрицы Why.
Благодаря линейности выхода решение возможно в аналитическом виде, без привлечения алгоритма BPTT :) () (1DXI XX WT T hy,   (12.1 3) где X – матрица, строки которой образован ы из векторов ht для обучающей выборки, D – матрица, строки которой образованы из соответствующих целевых векторов, ε – константа регуляризации, I – единичная матрица.
Вместо формулы (12.11) можно использовать обычную формулу softmax (12.2).
В этом случае аналитическое решение невозможно, и привлекается метод градиентного спуска.
Такой подход имеет смысл, когда количество нейронов в сети столь велико, что обращение матри цы в фор муле (12.1 3) становится затруднительным.
Несмотря на крайнюю простоту таких сетей, результаты распознавания, полученные с их помощью, не сильно уступают результатам сетей LSTM.
Отметим также такую разновидность рекуррентных сетей, как autoregressiv e moving average (ARMA) рекуррентные сети.
В этих сетях в качестве входного вектора используется супервектор, состоящий из нескольких векторов в последовательные моменты времени.
Понятно, что преимущество низкой размерности входного вектора при этом теряет ся.
В работе [58] используются 13 последовательных векторов.
Процент правильно распознанных фонем по сравнению с канонической рекуррентной сетью увеличилс я с 80.2% до 81.2%.
Можно предположить, что за счёт оптимизации общей архитектуры системы распознавания можно добиться большего прогресса.
12.3. Нормализация и адаптация нейронных сетей 
Проведение параллели между системами распознавания, основанными на нейронных сетях и слуховой системой человека, может привести к неправильному умозаключению, что эти системы не нуждаются в адаптации к диктору, каналу или шумовому окружению, поскольку человек явным образом не адаптируется к новым условиям.
Однако это не так, по крайней мере по двум причинам.
Во-первых, мощность ней ронных сетей, используемых для распознавания, пока ещё очень сильно уступает мощности естественных нейронных сетей.
Во-вторых, объём речевого материала, получаемый ребёнком за 2-4 года, пока его восприятие речи не приблизится по качеству к восприятию взрослого, гораздо больше, чем объём обучающей базы данных, используемый в системах распознавания.
Возможно, существует ещё одна причина.
Дело в том, что овладение фонетической [93] и мелодической [94] структурами языка осуществляется в самом раннем детстве и ещё в утробе матери не путём обучения, а путём «импринтинг а» [ 95].
Под импринтингом понимается заполнение отфильтрованными признаками речевого сигнала готовых нейронных структур, полученных путём наследования.
В отличие от обучения, которое требует повторения и сознательных усилий, импринтинг осуществляется на инстинктивном уровне.
Далее, в течение жизни, «без употребления полученные знания быстро утрачиваются» [95], а полученные импринтингом сохраняются, даже если ребёнок в очень раннем детстве был усыновлён и получил другой язык в качестве родного [93].
Впрочем, новый язык также усваивается импринтингом, если переселение произошло в достаточно раннем возрасте.
На основании вышеизложенного можно задать вопрос: любую ли задачу распознавания можно решить с помощью произвольной нейронной сети, или некоторые задачи требуют специальной архитектуры?
Известно, что для распознавания статических образов достаточно нейронной сети с одним скрытым слоем (для распознавания линейно разделимых образов достаточно перцептрона Розенблатта с линейной активационной функцией); для распознавания динамических объектов с произвольным темпом уже имеет смысл использовать рекуррентную сеть (раздел 12.2).
Возможно, «предустановленные» нейронные сети, заполненные с помощью импринтинга, умеют выделять в каком-то смысле инвариантные признаки речевого сигнала, для чего произвольным нейронным сетям может потреб оваться гораздо большее число нейронов, превосходящее возможности современных компьютеров.
Таким образом, задача адаптации для распознавания речи на основе нейронных сетей остаётся актуальной.
Адаптация моделей на основе гауссовых смесей (GMM) заключается в смещении и иногда изменении формы функций плотности вероятности фонем в пространстве признаков (раздел 9), как правило, на основе критерия максимума правдоподобия.
Модели на основе нейронных сетей являются дискриминантными (а не генеративными, как GMM), то есть для их построения используется критерий качества распознавания (раздел 10), поэтому они не содержат структур наподобие функций плотности вероятности, которые смещаются целиком при изменении источника речи – информация в них распределена в тысяч ах весовых коэффициентов неявным образом.
Поэтому рассмотренные в разделе 9 методы адаптации не могут быть использованы напрямую.
Что же касается метода нормализации признаков по длине голосового тракта (раздел 9.6) и других методов нормализации, то ничто не мешает его использованию.
Напомним, что выбор искажающей частотной шкалы в данном методе опирается на результаты распознавания с помощью нескольких вариантов признаков, полученных с различными шкалами.
Прежде чем рассмотреть методы адаптации, применимые к системам распознавания речи на основе произвольных нейронных сетей, ра ссмотрим предложенный в [96] способ, позволяющий использовать для нейронных сетей все рассмотренные в разделе 9 методы адаптации, но ценой некоторых ограничений.
Существующие системы распознавания, основанные на нейронных сетях, используют в качестве входных признаков MFCC коэффициенты или мел-спектр (раздел 3).
В работе [96] в качестве признаков предлагается использовать, после некоторых преобразований, вектор, компонентами которого являются вероятности всех состояний монофонов, вычисленные с помощью GMM моделей (раздел 6).
Модели GMM обучаются с помощью скрытых марковских моделей (HMM) обычным образом.
Далее размерность вектор а из вероятностей монофонов уменьшается с помощью метода главных компонент и расширяется путём конкатенации 11 последовательных векторов до размерности 550, то есть описывает сигнал во временном окне 110 мс.
Этот вектор и является входным для глубокой нейронной сети.
Роль скрытых марковских моделей в данной схеме вспомогательная – после того, как функции плотности вероятности состояний, аппроксимируемые гауссовыми смесями, построены, они больше не используются.
Однако этот механизм позволяет применить весь арсенал методов адаптации, наработанный для стандартной схемы HMM-GMM (раздел 9).
Попробуем оценить этот метод качественно.
Успех нейронных сетей по сравнению с методом HMM-GMM можно объяснить тем, что нейронные сети находят оптимальную процедуру распознавания исходя из акустических закономерностей, выделяемых из большой речевой базы данных, и используя только критерий качества распознавания, а метод HMM-GMM основан на представлениях о речи, полученных косвенным путём.
Например, при получении MFCC признаков, шкала мел (раздел 2.2) основана на психоакустических экспериментах, логарифмирование энергии в полосах опирается на представления об обработке сигналов нейронами (рис. 2.11), а косинусное преобразование не имеет физиологического обоснования вообще.
Далее распознавание опирается на концепцию функций плотности вероятности в невполне адекватном признаковом пространстве.
Хотя признаки MFCC используются и в нейронных сетях, суть сказанного заключается в том, что при использовании нейронных сетей имеет смысл избавляться от любых построений, не оптимизируемых прямо с помощью критерия качества распознавания.
Так, нейронные сети находят способ распорядиться логарифмом спектра в мел- полосах лучше, чем алгоритм MFCC, что было показано в работах [55,97].
Можно предположить, что нейронные сети также смогли бы найти лучшие с точки зрения распознавания речи границы спектра, чем шкала мел, или нашли способ обходиться вообще без фиксированных границ.
Можно ожидать, что на мощную нейронную сеть в будущем можно будет подавать непосредственно огибающую речевого сигнала с минимальной предварительной обработкой, то есть нейронные сети смогут реализовать нелинейное спектральное преобразование.
В рассмотренном методе адаптации используются не только признаки MFCC, но и метод распознавания HMM-GMM, то есть нейронной сети предлагается распознавать речь на основе данных, полученных методом «вчерашнего дня», в котором, возможно, уже потеряна некоторая часть дискриминантной информации.
На основе сказанного можно признать, что данный метод адаптации я вляется очень остроумным, но временным решением проблемы, актуальным при современном уровне мощности нейронных сетей.
Рассмотрим несколько методов адаптации к диктору, применяемых непосредственно к нейронным сетям.
Адаптация к шумовому окружению и каналу с вязи осуществляется сходным образом.
Будем придерживаться классификации, предложенной в монографии [55] – методы линейного преобразования, методы огранич енного обучения и методы подпространств.
12.3.1. Методы линейного преобразования 
Данные методы объединяет то, что в уже обученную дикторонезависимую глубокую нейронную сеть добавляют ещё один слой, в котором происходит линейное преобразование признаков, то есть нейроны слоя имеют линейную, а не сигмоидальную, функцию активации (рис. 2.11).
Весовые коэффициенты линейного слоя инициализируются единичными матрицами, а смещение- нулём.
Используется обычный для глубоких нейронных сетей критерий обучения – минимизации ошибок.
При этом обучению подвергаются только нейроны линейного слоя.
Линейный слой можно внедрить перед первым скрытым слоем нейронной сети, при этом линейной трансформации подвергаются входные признаки.
Такой вариант нейронной сети называется LIN (Linear Input Network), или fDLR (Feature Discriminative Linear R egression).
Если линейный слой внедряется перед выходным (softmax) слоем, сеть называют LON (Linear Output Network).
Если линейный слой внедряется между скрытыми слоями, сеть называют LHN (Linear Hidden Network).Для LON и LHN возможны два варианта подключения линейного слоя: до применения весовых коэффициентов исходной нейронной сети (12.14), или после них (12.15).
)b b(W)xW(W b)b x(WW b xW sn linn 1n linn n lin 1n linn n 1n linn n lin      (12.14))bb(W)xW(W b)b x(WW bsW slin n lin1n n linlin n 1nn linlin n linn lin    , (12.15) где n-1 и n – номера слоёв исходной нейронной сети, между которыми внедряется линейный слой, Wn – матрица весовых коэффициентов исходной нейронной сети слоя n, Wlin- матрица весовых коэффициентов линейного слоя, bn и blin – соответствующие векторы смещений, xn-1 – вектор признаков, полученный на выходе слоя n-1, sn и snlin – соответствующие векторы состояний после суммирования (рис.2.11).
Размер матрицы Wlin для этих типов подключения может существенно отличаться.
Допустим, количество нейронов в слое n-1 равно Nn-1 а в слое n- Nn, тогда нетрудно увидеть, что в обоих случаях матрицы Wlin квадратные, но в первом случае (12.14) размерность матрицы равна Nn-1, а во втором (12.15)- Nn.
Если размер слоя n-1 намного меньше, чем слоя n, как бывает, когда используют слой «бутылочное горло», то в первом случае обучать придётся гораздо меньше пара метров, чем во втором.
Аналогичные рассуждения в пользу второго случая справедливы, если линейный слой разместить перед бутылочным горлом.
Выбор подключения зависит от величины речевой базы для адаптации – как уже говорилось выше, лучше надёжно обучить небольшое количество параметров, чем пытаться обучать большое число параметров, не имея достаточного материала для дообучения.
Для LIN сети также имеется возможность резко уменьшить количество обучаемых параметров в матрице Wlin, если дополнительная речевая база мала.
Напомним, что входной вектор признаков представляет собой супервектор большой размерности, полученный конкатенацией нечётного числа векторов признаков (фреймов), полученных на окнах длительностью 16-20 мс.
Линейный слой можно применять к отдельным фреймам этого супервектора.
Нетрудно подсчитать, что, если количество фреймов равно 2 n+1, то матрица коэффициентов линейного слоя уменьшится в (2 n+1)2 раз по сравнению с «полным» вариантом.
В результате адаптации к каждому новому диктору будет создаваться матрица Wlin и вектор смещения blin данного диктора, которые нужно хранить, если мы хотим в будущем подключать уже принятого в систему диктора без адаптации.
Предпочтительнее было бы создать некоторый набор этих параметров для быстрого подключения любого диктора к системе.
Такой метод реализован в адаптации методом подпространств (см. ниже).
12.3.2. Методы ограниченного обучения 
Методы линейного преобразования обладают не очень хорошей способностью к адаптации именно в силу своей линейности.
Их очевидное достоинство – простота и скорость.
Однако, если необходимо добиться более качественного результата, и адаптационная база речи это позволяет, имеет смысл пытаться модифицировать всю нейронную сеть.
Стандартный способ обучения здесь неприменим, поскольку адаптационная база речи обычно слишком мала для того, чтобы настроить гигантское количество параметров.
Следовательно, в процедуру обучения необходимо включить какие-то механизмы, ограничивающие возможность «испортить» уже обученную дикторонезависимую систему.
Самое простое – при обучении принимать изменения не всех коэффициентов нейронной сети, а только тех, которые изменились в результате обучения наиболее сильно.
Ранжируя коэффициенты по величине изменения, можно подобрать их оптимальное количество.
Можно также уменьшить скорость обучения и количество циклов обучения.
Другим способом является регуляризация с помощью добавки, связанной с различием новых и старых параметров нейронной сети, к адаптационному критерию.
Адаптация бу дет происходить до тех пор, пока улучшение критерия превосходит изменение параметров.
Рассмотрим два таких способа.
L2 регуляризация.
Составим супервектор из всех параметров нейронной сети – столбцов всех матриц весовых коэффициентов и векторов смещений.
Пусть WSI- такой супервектор для исходной дикторонезависимой нейронной сети, а W – супервектор для адаптированной сети.
Введём L2 норму:    L ii i SI SI SI W W vec R 12 2 2 2) () ()- (W W W W, (12.16) где L – размерность супервекторов, i – номер компоненты вектора.
Очевидно, что R2 растёт по мере увеличения различий между исходной и адаптированной сети.
К обычному оптимизируемому критерию качества распознавания, например, количеству ошибок, добавим норму (12.16): JL2(W,b;S) = J(W,b;S) + λ R2(WSI,bSI;W,b),  (12.17) где W и b – параметры адаптированной нейронной сети, WSI и bSI параметры исходной дикторонезависимой сети, S={(xm,ym)|0≤m<M} – адаптационная речевая база (xm – набор входных векторов, ym – соответствующий набор целевых векторов вероятностей состояний, M- количество векторов), λ – оптимизируемый параметр.
Обучение на адаптационной речевой базе продолжается до тех пор, пока видоизменённый критерий уменьшается.
Регуляризация Кульбака-Лейблера.
В данном методе критерий качества распознавания дополняется расстоянием Кульбака-Лейблера между распределениями вероятности состояний для дикторонезависимой и адаптированной сетей: JKLD(W,b;S) = (1-λ)J(W,b;S) + λ RKLD(WSI,bSI;W,b;S), (12.18) где RKLD- расстояние Кульбака-Лейблера:),,;|(log), ;|(1);,;, (1 1bWx bWx bWbWk SI SI kM kC iSI SI SI KLD iP iPMS R   (12.19) где PSI(i|xk;WSI,bSI) и P(i|xk;W,b) – вероятности наблюдения m принадлежать к состоянию i, полученные дикторонезависимой и адаптированной нейронной сетью, соответственно.
Если используется критерий кросс-энтропии, то:)|(log()|(1),;,(1 1k kM kC iemp iP i PMJ x x yxbW  ,  (12.20) где Pemp(i|xk) – наблюдаемая на адаптационной выборке вероятность того, что наблюдение xk принадлежит состоянию i. С использованием данного критерия, дополненного расстоянием Кульбака- Лейблера, процесс адаптации завершится, когда у меньшение кросс-энтропии в результате дообучения сравняется с увеличением расстояния между распределениями вероятностей состояний дикторонезависимой и адаптированной нейрон- ных сетей.
Методы ограниченного обучения ставят проблему сохранения параметров системы ещё более остро, чем линейные методы – в рассмотренном виде надо хранить все параметры нейронной сети для каждого диктора.
Конечно, можно адаптировать только один слой нейронной сети, но эксперименты показали, что адаптация в таком случае может значительно уступать полному варианту.
Поскольку матрицы коэффициентов адаптированной к диктору нейронной сети не очень сильно отличаются от матриц коэффициентов дикторонезависимой сети, можно ожидать, что дельта матрицы (разности соответству ющих матриц) имеют низкий ранг и могут быть аппроксимированы матрицами низкой размерности стандартными методами с помощью сингулярного разложения [98].
Если ограничиться небольшим количеством наибольших сингулярных коэффициентов, порядок матриц можно существенно уменьшить.
Таким образом можно уменьшить объём сохраняемой для каждого диктора информации в 10 раз без существенного ухудшения качества адаптации.
Ещё один метод предполагает, что исходные весовые матрицы имеют низкие ранги.
Тогда каждую такую матрицу можно факторизовать: 1 2 nr rm nm   W W W,   (12.21) где Wm×n – исходная матрица размерности m×n и r<<m, r<< n. Тогда можно внедрить между матрицами W2 и W1 матрицу W3r×r, как это делалось в линейном методе, и адаптировать только её.
Для исходной дикторонезависимой сети матрицы W3r×r единичны.
Таким методом можно уменьшить объём запоминаемой информации для каждого диктора в 100 раз. Рассмотренная процедура адаптации естественным образом приводит к ещё одному методу, который уже не связан с рангом исходной матрицы.
Применимсингулярное разложение к матрице коэффициентов между некоторыми слоями сети: T nnnm mm nm   VΣ U W,  (12.22) где U и V – унитарные матрицы, состоящие из левых и правых сингулярных векторов, Σ – матрица, у которой на главной диагонали находятся сингулярные числа, а все остальные элементы равны нулю.
Будем подвергать адаптации только диагональ матрицы Σ, более того, если речевого материала для адаптации недостаточно, будем адаптировать несколько верхних сингулярных чисел (количество определяем эмпирически).
Поскольку запоминать требуется только диагональные элементы, а количество нейронов в слоях сети может достигать нескольких сотен, экономия становится ещё существеннее.
12.3.3. Методы подпространств 
В результате использования любых рассмотренных выше методов адаптации мы получаем некоторое количество матриц и векторов, которые позволяют улучшить распознавание речи для одного диктора.
Если мы адаптируем таким образом дикторонезависимую систему распознавания для S дикторов, и S достаточно велико, можно пытаться построить пространство дикторов, в котором каждый диктор будет представлен точкой.
Для этого из всех матриц и векторов, характеризующих каждого из дикторов, составим один супервектор.
Для всей совокупности дикторов эти супервекторы образую т матрицу с S столбцами.
Используя метод главных компонент, найдём S собственных векторов этой матрицы.
Тогда каждый новый диктор может быть представлен в виде линейной комбинации собственных векторов.
Если ограничиться несколькими собственными векторами, отвечающими наибольшим собственным числам, размерность пространства можно уменьшить.
Логично было бы включать информацию о дикторах в виде вектора в пространстве дикторов в процесс обучения.
Тогда адаптация заключалась бы лишь в нахождении проекции нового диктора на это пространство.
Такой вид обучения называется дикторозависимым (SAT – Speaker-Aware Training).
Напомним, что аббревиатуру SAT мы уже встречали в разделе 9.6, стр. 90.
Там она обозначала обучение, адаптивное к диктору – Speaker Adaptive Trainin g. Отличие этих методов состоит в том, что при адаптивном обучении информация о дикторе теряется, и каждый новый диктор приводится к некоторому среднему.
При дикторозависимом обучении информация о дикторе включается во входной вектор нейронной сети (рис.
12.2.).
Рис. 12.2 Дикторозависимое обучение и распознавание [55].
Отметим, что наряду с дикторозависимым обучением и распознаванием, можно использова ть такой же подход к адаптации к шуму и каналу связи.
Такие системы называются NAT (Noise-Aware Training) и DAT (Device-Aware Training).
Преимущество дикторозависимого обучения и распознавания заключается в том, что процесс адаптации явно включён в алгоритм и не требует отдельной процедуры.
Единственная проблема – надёжная оценка информации о дикторе (рис. 12.2.).
Современным методом введения информации о дикторе является использование i-векторов (identity vector).
Формализм i-векторов изучается в курсе по идентификации и верификации дикторов.
Важной особенностью этого метода с точки зрения распознавания дикторов является то, что оценка i-вектора, характеризующего диктора, осуществляется независимо от обучения нейронных сетей, лишь на основе статист ических особенностей речевой выборки для данного диктора.
Ещё одной полезной особенностью является то, что размерность вектора может выбираться произвольно, в зависимости от размеров речевой выборки.
Так, в работе [99], где адаптационная выборка достаточно велика, размерность i-вектора составляет 400, в работе [100] с небольшой выборкой размерность i-вектора составляет 50.
13.МОДЕЛИ ЯЗЫКА Вернёмся к формуле (10.2).
На её основании можно сделать вывод, что задачу распознавания речи можно разбить на три.
Первая из них имеет дело с анализом речевого сигнала, выделением и моделированием акустических признаков.
Вторая отражает зависимости, существующие между словами в языке и определяющими возможные схемы следования слов друг за другом.
Наконец, задачи третьей группы связаны с определением наилучшего кандидата на распознавание среди всех возможных с использованием той информации, которая создается в ходе решения задач первых двух групп.
На основании такого разделения образуются три основных модуля любой системы распознавания слитной речи: акустическая модель, модель языка и декодер.
До сих пор рассматривались вопросы, относящиеся к первой задаче.
Основным понятием лингвистического описания речи является понятие модели языка.
Произвольная модель языка позволяет формально описать язык, а точнее, те из его аспектов, которые необходимы для повышения качества автоматического распознавания речи.
Определяя возможную последовательность слов, мы поднимаемся на более высокие уровни описания языка по сравнению с фонетическим и, как следствие, должны учитывать системные отношения высших порядков.
Используемая модель описания слова в предложении может быть сложной, учитывающей синтаксическую и семантическую структуру высказывания, а может быть очень простой, полагающей, что появление любых слов равновероятно (в таком случае мы, по сути, отказываемся от лингвистического анализа и учета закономерностей и особенностей естественного языка).
Языковая модель – обязательная часть систем распознавания слитной речи.
Не любая последовательность слов является предложением (в особенности для языков типа немецкого – с жёстким порядком слов), между словами есть грамматические и семантические связи.
Языковая модель позволяет узнать, какие последовательности слов в языке более вероятны, а какие менее.
В однопроходных декодерах обычно информация от языковой модели учитывается одновременно с информацией от акустической модели (каждая со своим весом), в двухпроходных декодерах языковая модель обычно включается на втором этапе.
Использование языковой модели помогает сократить пространство поиска и снять неоднозначность при выборе из нескольких близких по стоимости акустических гипотез (для русского языка, например, помогает правильно распознать слово в нужном падеже).
Общепринятой мерой оценки моделей языка в отрыве от акустической модели является перплексия (или коэффициент неопределенности – perplexity), которая соответствует среднему коэффициенту ветвления после каждого слова, согласно модели языка.
Перплексия представляет собой меру способности модели предсказывать неизвестные последовательности слов, является функцией кросс-энтропии и вычисляется по формуле: m mw wwP m HwwwP PPm1 2 1)... (log1)()... (2 221 2   W, (13.1) где H – кросс-энтропия текста, m – количество слов в тексте, а P(w1w2…wm) – вероятность, приписываемая тексту моделью языка.
Для N-граммы вероятность)... (2 1 mwwwP рассчитывается как произведение вероятностей всех встреченных в базе данных последовательностей N слов во фразах:    m iNi i i m w wwP wwwP 11 1 2 1),..., |()... (,  (13.2) при этом для слов, начинающих фразу, вводится специальный «токен» (метка) <s>, обозначающий начало фразы.
Для первых слов во фразе вероятности последовательностей рассчитываются так:),,..., | (),...,,|(), |(1 2 1 1 2 1     s w w wP s wwPs wPN N (13.3) Аналогично учитываются токены в конце фразы:)|'(),...,,...,|'(),,...,|'(2 1 K NK K NK K wsP w wsP w wsP     (13.4) где K – количество слов во фразе.
Чем ниже перплексия, тем лучше модель языка.
Несмотря на то, что прямой зависимости между уменьшением перплексии и улучшением качества распознавания нет, уменьшение перплексии больше, чем на 10% обычно отражается и на качестве распознавания.
Очевидно, что для модели языка, где все слова равновероятны и вероятность появления слов не зависит от окружения, перплексия равна размеру словаря.
По мере учёта зависимостей между словами, перплексия уменьшается до некоторого предела.
Еще одной характеристикой модели языка является процент незнакомых (внесловарных) слов (OOV – Out of Vocabulary).
Он говорит о том, сколько слов из тестового текста не были найдены в произносительном словаре системы и, следовательно, не имеют никаких шансов быть распознанными.
(Методы обработки OOV слов будут рассмотрены в разделе 15).
13.1.
Использование условных вероятностей Формула вычисления априорной вероятности всех N слов в предложении по полному левому контексту (то есть, на основании уже распознанных слов) может быть разложена на произведение условных вероятностей:    N ii i N wwwwP wwwP WP 11 2 1 2 1)... |()... ()(.
(13.5) Понятно, что вычислить такую вероятность практически невозможно – это потребовало бы огромных вычислительных мощностей и невообразимого размера тренировочного корпуса.
Вычисление этой вероятности потребовало бы оценки и хранения Vi-1(V-1) независимых парам етров (где V – объем словаря), а поскольку словарь хорошей системы распознавания содержит сотни тысяч слов, i может достигать значения в 100 слов и более, это становится попросту невозможным.
Однако, мы можем упростить задачу, исследуя только n ближайших слов левого контекста, придя, таким образом, к понятию N-грамм:)... ()...()... |()... |(1 11 1 1 1 2 1      ni ini i ni i i i iw wCwwCw wwP wwwwP,  (13.6) где С – количество соответствующих N-грамм (последовательностей соседних n-слов).
Подсчитав вероятности N-грамм на основании большого тренировочного корпуса (который может достигать сотен миллионов словоформ), мы можем в дальнейшем использовать их для определения вероятности следования слов друг за другом в незнакомом тексте (представляющим собой последовательность слов – кандидатов на распознавание).
Такой подход называется оценкой максимального правдоподобия (MLE – Maximum Likelihood Estimation).
В моделях языка для систем распознавания обычно используются N-граммы порядка 2 и 3, называемые биграммами и триграммами.
Данные модели (не только биграммные и триграммные, а вообще все модели, учитывающие ограниченный контекст) имеют два серьезных и сразу бросающихся в глаза недостатка.
Во-первых, подобное описание часто оказывается лингвистически недостоверным в связи с тем, что не учитывает релевантные слов а, если они находятся на расстоянии больше N от исследуемого слова, но в то же время учитывает слова с низкой предсказательной способностью, которые просто оказались ближе (например, вследствие своей высокой частотности).
Во-вторых, при желании учесть боль ший контекст, оказывается, что для этого потребуется очень серьезное увеличение тренировочного корпуса, и он может принять поистине огромный размер – что говорит о том, что тренировочный корпус используется неэффективно.
13.2. Статистическое сглаживание 
Методы статистического сглаживания позволяют учитывать факты появления N-грамм, которые ни разу не встречались в тренировочном корпусе.
Действительно, нелогично полностью отказываться от гипотезы, которая обладает очень большой акустической вероятностью толь ко на основании того, что одна из N-грамм в гипотезе не встретилась ни разу в тренировочном корпусе.
Этот факт, скорее, говорит о том, что тренировочный корпус не может охватить все возможные N-граммы языка, а не о том, что данная N-грамма невозможна в языке.
Для решения этой проблемы используются алгоритмы сглаживания (smoothing) и отката (back-off).
Идея сглаживания заключается в том, что мы берем часть вероятностной массы у встретившихся в корпусе N-грамм, и распределяем ее по всем возможным комбинациям слов из словаря, составляющим множество невстреченных (unseen) N-грамм. Известными алгоритмами сглаживания являются пересчет Гуда-Тьюринга, Виттена-Белла, сглаживание Кнезера-Нея.
Откат подразумевает использование вероятностей N- 1-грамм в том случае, если соответствующая N-грамма имеет нулевую вероятность.
Сглаживание и откат являются обязательными элементами практически любой модели языка.
Существует большое число различных алгоритмов сглаживания, однако новые разновидности лишь очень незначительно улучша ютрезультаты, достигаемые с алгоритмами, упомянутыми выше.
В принципе, можно сказать, что алгоритмы сглаживания достигли предела своей эффективности, и дальнейшие усилия по их усовершенствованию не представляются перспективными.
Кроме сглаживания и откат а существует ряд других дополнений стандартной N-граммной модели, которые являются опциональными и могут использоваться в зависимости от конкретного языка.
13.3. Классовые модели
 Одним из наиболее эффективных усовершенствований N-граммной модели является использование информации о принадлежности слов к тем или иным классам эквивалентности.
Особенно важным это оказывается, если лингвистическая модель строится на относительно небольшом тренировочном корпусе.
В таком случае может оказаться, что при использовании системы будет встречаться так много N-грамм с нулевым значением (не встретившихся в тренировочном корпусе), что даже сложные алгоритмы сглаживания не смогут обеспечить нужного приближения.
Использование N-грамм, членами которых вместо конкретных слов яв ляются классы, к которым принадлежат слова, позволяет решить эту проблему.
Это связано с тем, что количество классов, в которые можно объединять слова, несравнимо меньше количества слов, следовательно, можно быть уверенными, что даже при небольшом тренировочном корпусе охват всех возможных (классовых) N-грамм будет достаточно полным.
Обычно условная вероятность слова в чистом виде определяется как произведение вероятности класса на основ е предыдущих классов и вероятности того, что наше слово принадлежит данному классу) |()|() |(1 11 1  n Nn n n nn Nn n ccPcwP wwP,  (13.7) где с соответствует классу для каждого конкретного слова.
Данные множители могут быть вычислены по формулам)()()|(cCwCcwP и    c ii i i iccCccCccP) () () |(11 1, (13.8) где (С(x) – каунт единицы, то есть то, сколько раз она встретилась в тренировочном корпусе) Как мы видим, N-граммная модель, построенная на классах слов, дополняется вероятностями принадлежности слова к классу.
На основании способа отнесения слов к тем или иным классам классовые модели можно разделить на три основные категории:  модели, работающие с классами, построенными вручную;  модели, опирающиеся на частеречные классы слов (с использованием информации о принадлежности слов к тем или иным грамматическим категориям);  модели классов, построенных при помощи алгоритмов статистической кластеризации.
13.4. Морфемные модели 
Для синтетических языков (флективных и особенно агглютинативных языков) оказывается весьма перспективным использовать при построении модели языка информацию о морфемном составе слов (в виде традиционного морфемного членения, либо в виде членения на псевдоморфы).
Для этого сначала используются процедуры автоматического определения морфемных границ, информация о которых в дальнейшем используется при построении N-граммной модели языка.
Несмотря на то, что существуют модели, предполагающие осуществление полного морфологического анализ а, для славянских языков были показаны преимущества модели основа/флексия.
В таком случае триграммная модель, например, определяется формулой) |()...|(1 2 1 i i i i i sssP wwsP) |()...|(1 1 ii i i i eseP wweP,     (13.9) где si – основа i-того слова; ei – флексия (окончание) i-того слова.
Такие модели создавались и апробировались и для русского языка [ 71] и [42], однако, не принесли желаемого успеха в плане повышения точности распознавания речи.
Это, видимо, связано с тем, что морфемы в русском языке короткие и каждая из них имеет по несколько вариантов произнесения в зависимости от лингвистического контекста, кроме того, в русскоязычных словоформах наблюдается чередование звуков и изменение морфем (например, корневых) в зависимости от грамматических характеристик словоформ, что не позволяет легко соединять цепочки распознанных морфем в правильные слова.
Однако морфемные модели языка довольно успешно применяются для ряда агглютинативных языков, например, финского [72], турецкого [73], венгерского [74] и т.д. 13.5.
Синтаксические и семантические модели Для многих синтетических естественных языков, в том числе и русского, характерен практически свободный порядок слов в предложении.
Как следствие, использование моделей языка на основе N-грамм для распознавания речи дает гораздо более низкие результаты, что объясняется необходимостью нахождения связей между словами по принципу, отличному от простого соположения.
Для таких случаев эффективным может оказаться учет синтаксических связей слов в предложениях при моделировании языка.
Если мы хотим использовать синтаксическую информацию для распознавания речи, то для начала нам нужно автоматически выделить ее из предложения: таким образом, наша задача разбивается на две практически независимые зад ачи.
Одной из первых таких моделей стала структурированная модель языка (Structured Language Model) [43, 75].
Структурированная языковая модель применяется на стадии декодирования речи для синтаксического разбора результатов распознавания, синтаксическое дерево строится динамически в ходе распознавания.
Модель позволяет использовать дальнодействующие связи между словами и предсказывать слово не только по нескольким предыдущим лексическим единицам, но также по доступным главным словам.
Такая модель хорошо подходит для аналитических языков с жесткой грамматической структурой (например, для английского языка).
В [76] был предложен подход синтаксических N-грамм (SN-грамм).
В случае SN-грамм соседние слова выбираются в соответствии с их синтаксическими связями в синтаксических деревьях, а не в соответствии с тем, как они появились в тексте.
При этом используются традиционные N-граммы слов, а также метки и характеристики частей речи.
В д ругой работе [ 77] была предложена стохастическая морфо-синтаксическая модель для системы распознавания венгерской речи, эта модель описывает допустимые в венгерском языке словоформы (комбинации морфем).
Кроме того, в [ 78] предложены составные языковые моде ли с введением понятия категорной языковой модели и, в частности, категорных n-грамм. Каждому слову в словаре приписываются 15 атрибутов, определяющих грамматические свойства словоформы.
Множество значений атрибутов определяет класс словоформы.
Каждое слов о в предложении рассматривается как его начальная форма и морфологический класс.
В итоге языковая модель разбивается на две составляющие: изменяемую часть (основанную на морфологии) и постоянную часть (основанную на начальных формах слов), которая строится как n-граммная языковая модель.
Кроме того, для того чтобы учесть дальнодействующие связи между словами во фразе, недавно была также предложена синтаксическо-статистическая модель языка системы распознавания русской речи со сверхбольшим словарем.
Такая модель позволяет объединить статистический анализ (N-граммы) и синтаксический анализ обучающего текстового корпуса [ 79].
В данном подходе статистическая N-граммная модель языка расширена (посредством интерполяции) за счет синтаксического анализа обучающего т екстового корпуса.
В ходе статистического анализа русско язычных текстов выявляются новые (потенциальные) N-граммы, содержащие грамматически связанные пары слов, которые были разделены в обучающем тексте другими словами.
Синтаксический анализ позволяет увеличить количество создаваемых в результате обработки текста различных N-грамм и, тем самым, повысить качество модели языка за счет выявления грамматически связанных пар слов и снизить процент ошибок распознавания слов в слитной речи.
Область семантики (смысла слов) же при лингвистическом анализе естественного языка является пока самой нечеткой и трудноисследуемой.
Из всех уровней языка именно семантическая информация сокрыта в тексте глубже всего и, как следствие, хуже всего поддается формальному описанию.
Как следствие, использование семантической информации в системах распознавания речи на данный момент весьма ограничено.
Задача выделения из текста достоверной семантической информации (глубокий семантический анализ) является пока нерешенной.13.6.
Модели темы высказывания Известно, что хорошее статистическое описание языка в целом требует наличия не только очень большого тренировочного корпуса, но и максимально широкого охвата те кстов различных жанров и стилей.
С другой стороны, если для определенного тестового текста мы будем знать его принадлежность к какому-либо классу (например, экономика, юриспруденция и т.п.), то использование для такого текста модели, натренированной на текстах соответствующего класса, приведет к серьезному улучшению качества распознавания.
По сути, мы используем различные модели языка для текстов с различной темой.
Основа модели остается одной и той же, но распределение вероятностей оказывается различным.
Поэтому дополнительной задачей является автоматическое выделение набора тем для тренировочного корпуса и тренировка модели для того, чтобы затем иметь возможность относить исследуемый текст к одной из таких тем.
13.7 Модели языка на основе нейронных сетей Во всех рассмотренных выше моделях языка слова представлены в дискретном простр анстве, а именно в словаре.
Такое представление не позволяет выявить «похожесть» слов и оценить вероятность не встреченных в базе N-грамм, поскольку рассмотренные выше процедуры отката и сглаживания просто не позволяют присвоить не встреченной N-грамме нулевую вероятность.
Наглядный пример, приведённый в работе [101], иллюстрирует, что понимается под похожестью.
Рассмотрим две фразы: «кошка идёт по комнате» и «собака вбежала в кухню».
Очевидно, что пары слов «кошка- собака», «комнате – кухню» и предлогов «пок» имеют сходные семантические и синтаксические значения.
Идея заключается в том, чтобы организовать непрерывное пространство, в котором подобные похожие слова были представлены в каком-то смысле близкими друг к другу векторами.
Тогда, даже если не которое сочетание слов не было встречено в обучающей выборке, система сможет восполнить недостаток знаний по аналогии с присутствующими в базе примерами и оценить его вероятность.
На рисунке 13.1 представлена нейронная сеть с двумя скрытыми слоями, реализующая модель языка в непрерывном пространстве [ 101,102,103].
На вход подаётся супервектор, составленный из векторов слов контекста (на рисунке контекст состоит из трёх слов).
Вектор, соответствующий слову строится по принципу 1-из-N, то есть все элементы вектора, кроме i-го равны нулю, элемент с номером i равен 1, где i – номер слова в словаре, N – размер словаря.
Рис. 13.1 Модель языка на основе нейронной сети [102].
Функция активации первого скрытого слоя линейна, то есть элементы состояния первого скрытого слоя cj представляют собой линейные комбинации со смещением компонент входного супервектора.
Состояния второго скрытого dj и выходного слоя oj вычисляются следующим образом:) tanh(j lljl j bcm d  ,  (13.10)  ji j ij i k dv o,   (13.11) где матрицы mjl и vij – весовые матрицы соответствующих слоёв, bj и ki – элементы векторов смещения.
Вероятность для каждого слова словаря быть следующим в этом контексте вычисляется обычным образом по формуле softmax :  N kk i i o o p 1) exp(/) exp(,  (13.12) где N – размер словаря и выходного слоя.
Отметим, что без первого линейного скрытого слоя можно обойтись, включив его матрицу преобразования во второй скрытый слой.
Для этого надо вместо элементов cl подставить их значения, полученные в результате линейного преобразования из входного вектора и поменять порядок суммирования в формуле (13.10).
Это замечание сделано для того, чтобы отсутствие линейного слоя в рекуррентной модели (см. ниже) не казалось недостатком.
Размер первого скрытого слоя обычно выбирается в диапазоне 50 – 200, второго – 400 – 1000,, в зависимости от размеров обучающей выборки.
Модель исследовалась н а словарях размером от 40000 до 200000 слов.
Использование этой модели языка позволило уменьшить перплексию с 70.2 до 67.6 и уменьшить ошибки распознавания слов с 14.24% до 14.02% и далее до 13.92% при увеличении размеров второго скрытого слоя с 400 до 100 0 [102].
Явным недостатком рассмотренной модели языка является фиксированная длина контекста.
Очевидно, что в языке существуют довольно устойчивые сочетания слов различной длины.
Рекуррентная нейронная сеть лишена этого недостатка, поскольку может хранить информацию о контекстах произвольной длины [104] (Рис. 13.2).
Рис. 13.2 Модель языка на основе рекуррентной нейронной сети [104].
В качестве входного вектора используется конкатенация 1-из-N очередного вектора слова и вектора состояния скрытого слоя нейронной сети на предыдущем шаге.
Состояние скрытого слоя отражает информацию о накопленном контексте.
Состояния скрытого dj и выходного слоя oj, а также вероятности слов вычисляются так же, как для нерекуррентной сети (13.10, 13.11, 13.12), но вместо активационной функции tanh используется сигмоидальная функция, что не принципиально.
Также отсутствуют смещения.
Модель языка исследовалась со следующими параметрами: размерность скрытого, контекстно го слоя от 30 до 500, размер словаря N – от 30000 до 200000 слов.
Отметим, что в отличие от языковых моделей, основанных на нерекуррентных нейронных сетях [101,102,103], модель языка, основанная на рекуррентной нейронной сети, имеет только один параметр, к оторый надо выбрать заранее – размер контекстного слоя.
Рассмотренная модель языка показала явное преимущество перед моделями сглаживания Кнезера-Нея (раздел 13.2) – количество ошибок распознавания слов уменьшилось на 18%, при этом база обучения составляла всего 6.4 миллиона слов вместо 37 миллионов в сравниваемой системе.
Надо отметить, что меньшая по объёму база обучения использовалась не случайно – процедуры обучения рекуррентных нейронных сетей чрезвычайно требовательны к производительности компьютеров.
Обучить такую систему на имеющихся базах, содержащих более миллиарда слов, в настоящее время можно только на суперкомпьютерах.
Таким образом, ещё раз, как и в разделе 12.2, отметим необходимость разработки новых процедур обучения рекуррентных нейронных сетей.14.
ДЕКОДЕР В ходе работы системы автоматического распознавания речи задача распознавания сводится к определению наиболее вероятной последовательности слов, соответствующих содержанию речевого сигнала.
Наиболее вероятный кандидат должен определять ся с учетом как акустической, так и лингвистической информации.
Это означает, что необходимо производить эффективный поиск среди возможных кандидатов с учетом различной вероятностной информации.
При распознавании слитной речи число таких кандидатов огромно, и даже использование самых простых моделей приводит к серьезным проблемам, связанным с быстродействием и памятью систем.
Как результат, эта задача выносится в отдельный модуль системы автоматического распознавания речи, называемый декодером.
Декодер дол жен определять наиболее грамматически вероятную гипотезу для неизвестного высказывания – то есть определять наиболее вероятный путь по сети распознавания, состоящей из моделей слов (которые, в свою очередь, формируются из моделей отдельных фонов).
Правдоподобие (likelihood) гипотезы определяется двумя факторами, а именно вероятностями последовательности фонов, приписываемыми акустической моделью, и вероятностями следования слов друг за другом, определяемыми моделью языка.
В случае распознавания слитной реч и сеть вариантов распознавания оказывается настолько большой, что исследование и оценка всех возможных вариантов представляется невыполнимой с вычислительной точки зрения в режиме, сопоставимым с режимом реального времени.
В связ и с этим, оказывается необходимой разработка как можно более эффективных алгоритмов быстрого поиска, которые уже не будут гарантировать нахождение оптимального варианта распознавания, однако будут осуществлять поиск за приемлемое время.
Как правило, поиск осуществляется в пределах « луча» (Beam Search), то есть все гипотезы, вероятность или правдоподобие которых уступает лучшей гипотезе на величину, превышающую некоторый порог, отбрасываются.
Очевидно, что чем чаще производится анализ гипотез и чем раньше лишние гипотезы отбрасываются, тем эффективнее будет работа декодера, поскольку количество гипотез на каждом узле веерообразно увеличивается, напоминая лавину.
Ещё одним способом ограничения требований к памяти и быстродействию является сохранение N лучших гипотез.
Рассмотрим математическую основу декодеров.
Отбрасывая несущественный на этапе распознавания знаменатель, перепишем (10.2):) ()(m axarg WXPWP W W,   (14.1) где NTx x xX,...,1 1 – последовательность векторов признаков входного сигнала, nnw w w W,...,1 1 – последовательность слов, принадлежащих словарю размером NW.
Первый множитель P(W) описывает вклад лингвистического модуля, второй P(X|W) – лексического, фонетического и акустического источников знаний.
Всоответствии с концепцией марковских цепей, второй множитель представляет собой сумму вероятностей всех возможных последовательностей состояний, что приводит к уравнению:   TsN T T WwsxP WP W 1)}|,()({ maxargˆ 1 1 1,  (14.2) где Ts1 – одна из последовательностей состояний, порождаемых последовательностью слов nw1.
На практике применяется критерий Витерби – ищется последовательность состояний, дающая максимальный вклад в с умму (14.2): })] |,([)({ maxargˆ 1 1 1 1N T T sWwsxP Max WP W T .
(14.3) Отметим, что в формулу (1 4.3) введён эмпирический параметр α, оптимизируемый по обучающей выборке.
Сложность декодирования заключается в комбинаторном характере задачи и, следовательно, огромном числе переборов при полном решении, что требует внедрения эф фективных эвристик для практического решения задачи.
Структура сети, на которой осуществляется поиск, является продуктом ограничений, налагаемых на неё источниками знаний на каждом уровне (состояний, фонем, слов) как внутри слов, так и между ними.
На основ ании предыдущего материала очевидно, что диапазон влияния этих ограничений характеризуется «короткой памятью».
Этот факт позволяет оптимизировать процесс поиска на основании принципа ранней рекомбинации, который формулируется следующим образом: если несколько гипотез в сети имеют общий узел, следует оставить наилучшую гипотезу до этого узла и отбросить остальные, поскольку при дальнейшем развитии процесса у этих гипотез уже не будет возможности превзойти сохранённую Использование N-граммной модели языка имеет два явных последствия: A. сеть не имеет ограничений на ветвления – за любым словом может следовать любое другое; Б. вероятности слов зависят только от N-1 предшествующих:),...,, |(),...,, |(1 2 1 1 2 1    Nn n n n n n n w w wwP w w wwP.
(12.4) Отсюда следует, что хранить историю всех гипотез, простирающуюся далее N-1 слов, не имеет смысла, однако удаление гипотез на более ранних этапах может привести к ошибкам.
Способ сохранения, анализа и обработки гипотез является предметом исследований при создании декодеров.
14.1.
Организация лексикона в видe префиксного дерева Лексикон (словарь) определяет список слов (обычно это линейный список) с их фонетической транскрипцией в виде небольшого количества контекстно- независимых (не учитывающих коартикуляцию) фонетических символов.
Некоторые слова могут иметь варианты произнесения с приписанными им вероятностями.Представление лексикона в виде префиксного дерева обеспечивает более компактное описание с уменьшенным количеством дуг, особенно на начальных участках слов, куда приходятся основные вычислительные затраты при поиске.
Поскольку любое слово лексикона может следовать за любым другим, объединение одинаковых фрагментов деревьев сокращает количество дуг, которые необходимо рассмотреть для того, чтобы генерировать стартов ые гипотезы следующего слова.
Одной из проблем, связанных с использованием префиксных деревьев, является то, что вероятность слова, получаемая из модели языка, определяется только в последнем узле и не оказывает влияние на формирование гипотез до этого мо мента.
В качестве выхода предлагается распределять вероятность слова по дугам его префиксного дерева.
Префиксное дерево может быть построено на основе контекстно- независимых фонемных транскрипций, или с использованием контекстно- зависимых трифонов, что при водит к увеличению количества дуг с нескольких десятков до нескольких сотен.
Использование контекстно-зависимых межсловных трифонов ещё более усложняет задачу – в этом случае последняя дуга предыдущего слова расщепляется на множество дуг, поскольку она теперь зависит от первого трифона следующего слова.
Расширение сети, осуществляемое до декодирования (Static network expansion), было естественным решением на начальном этапе развития систем распознавания речи.
С увеличением объёма словаря и усложнением используемых источников знаний использование этого метода становится всё более затруднительным.
Временным выходом является либо переход к динамическому расширению сети (Dynamic search network expansion), либо поиск резервов уменьшения размеров сети.
В частности, используется то, что реальное количество узлов и дуг существенно (на несколько порядков) меньше, чем теоретически возможное, поскольку не все сочетания монофонов в виде бифонов или трифонов встречаются в языке, а также то, что начальные и конечные состояния различных трифонов могут связываться (заменяться одним состоянием).
14.2. Использование взвешенных конечных автоматов 
Для декодирования используется также аппарат взвешенных конечных автоматов (Weighted finite automata).
На рис. 12.1. представлен простой пример такого автомата.
Рис. 12.1. Взвешенный конечный автомат.
Метки l и веса w перехода обозначены на соответствующей направленной дуге как l/w [44].
Разрешённые слова с их вероятностями проставлены на дугах, составляющих пути.
Каждое слово представляется также автоматом.
На рис. 12.1(б) изображён граф слова “data”, с двум я вариантами произнесения.
На рис.12.1 (в) автомат описывает стандартную марковскую цепь для фонемы ‘ d’.
Полная вероятность произнесения подсчитывается как произведение вероятностей, полученных на всех вложенных автоматах.
Эти автоматы состоят из набора промежуточных состояний, начального состояния и набора конечных состояний, соединённых переходами.
Каждый переход имеет начальное и конечное состояния, метку и вес. Задачей декодера является оптимизация автомата.
Декодер находит в лексиконе варианты произнесений слов и подставляет их в грамматику.
Представление в виде фонетического дерева на данном этапе может быть использовано для уменьшения количества путей.
Далее декодер определяет контекстно-зависимые модели для каждой фонемы в контексте и подставляет их в граф.
14.3. Использование взвешенных преобразователей с конечным числом состояний 
В последние годы получил развитие подход к статическому декодированию, основанный на «взвешенных преобразователях с конечным числом состояний» (WFST – Weighted Finite State Transducer) [44].
Образец WFST с тем же лексиконом, что и на рис. 12.1., изображён на рис. 12.2.
Каждый переход на рис. 12.2 (б) имеет идентичные метки входа и выхода.
Поскольку слова кодируются выходной меткой, стало возможно объединять преобразователи для нескольких слов (слова data и dew на рис. 12.2 (б).
Аналогично можно объединять марковские модели фонем.
Это иллюстрирует основное преимущество преобразователей над взвешенными автоматами: преобразователи могут объединять различные уровни представления, на пример, уровень фонем и уровень слов.
Рис. 12.2. Пример WFST [44].
Благодаря этому подходу, удаётся объединить в одну сеть WFST различные источники знаний – марковские модели, лексиконы, N-граммные статистические модели языка.
В данной сети входными метками являются состояния марковских моделей, выходными – слова.
Разработанные в теории конечных автоматов методы детерминизации и минимизации позволяют получить чрезвычайно компактные сети.
От метим, что при поиске оптимального пути на графе декодеру не придётся обращаться к представлению фонем, лексикону, модели языка – вся информация уже заключена в структуре графа.
Благодаря этому, декодер упрощается и ускоряется – декодеру остаётся только подставлять вероятности эмиссии в соответствии с рассматриваемыми гипотезами.
Метод декодирования, в котором расширение сети интегрировано в процесс декодирования, называется «динамическим расширением сети» (Dynamic search network expansion).
Построенное на старте распознавания начальное дерево расширяется, используя виртуальные узлы и временные структуры, содержащие только информацию, необходимую для текущей гипотезы.
Разновидность метода динамически расширяемой сети, называемая синхронным по времени методом, особенно удобна для анализа вероятностей гипотез в каждый момент времени, поскольку позволяет отбрасывать гипотезы, не попавшие в луч, не дожидаясь концов слов.
15. ПРОБЛЕМА ВНЕСЛОВАРНЫХ СЛОВ 
Существующие системы распознавания слитной речи содержат модели десятков и сотен тысяч слов, однако, как и при построении моделей фонем (см. раздел 8), никакие базы данных не могут обеспечить полное покрытие словаря в условиях реальной эксплуатации.
Понятн о, что если не предусмотреть способов обработки таких случаев, внесловарное слово, или OOV-слово (Out Of Vocabulary) будет распознано, как одно из слов словаря – IV-слово (IV – In- Vocabulary).
Причём такая вставка в текст может вызвать цепочку дополнительных ошибок.
Поясним сказанное.
Согласно формулам 6.2, 6.4, вероятность того, что наблюдения X порождены моделью W и вероятность того, что модели W соответствуют наблюдения X, связаны соотношением:)|()()|(WXPWP XWP,  (15.1) где P(W) – вероятность модели, то есть произведение вероятностей слов данной последовательности, представленной последовательностью моделей фонем.
Таким образом, слова не распознаются последовательно, одно за другим – решение откладывается до момента распознавания последнего слова в цепочке, при этом сохраняется несколько вариантов цепочек (гипотез).
То, что слово не включено в словарь, означает, что его априорная вероятность равна нулю, и его участие в любой гипотезе исключено – произведение вероятностей тоже буде т равно нулю.
Вместо OOV-слова будет подставлено некое созвучное слово, либо несколько коротких IV-слов.
Поскольку сочетания слов в моделях языка имеют определённые вероятности, ошибка может распространиться на соседние слова.
Стоит отметить также, что неправильное распознавание OOV-слов может приводить к моделям с низкими вероятностями, что приводит к необходимости увеличивать количество рассматриваемых гипотез, что, в свою очередь, увеличивает объём вычислений.
Учитывая, что системы распознавания с больши ми словарями работают на пределе вычислительных возможностей существующих компьютеров, такой сценарий очень нежелателен.
Какие же слова могут оказаться внесловарными?
Анализ показывает, что наибольшую долю среди OOV-слов занимают новые термины, имена, названия.
Это как раз те слова, которые чаще всего определяют смысл высказывания, то есть, собственно, те слова, ради которых фраза и была произнесена.
Иначе говоря, OOV-слова могут нести большой объём информации.
Из вышесказанного следует, что задача обработки OOV-слов очень важна и должна включать следующие подзадачи: 1. определение наличия и положения слова во фразе; 2. распознавание последовательности фонетических единиц, составляющих слово; 3. определение написания слова (рассматриваться не будет).
Рис. 1 5.1.
Фонемный граф общей модели слова.
Решать проблему OOV-слов можно несколькими способами, или их комбинациями: Увеличение размера словаря – очевидный метод, не нуждающийся в пояснениях.
Введение общей модели слова в словарь – расширение идеи моделей заполнения (Filler models), или моделей мусора (garbage) и моделей неречевых звуков.
Использование системы с двумя фазами распознавания, на первой из которых распознаются более крупные, чем фо немы, единицы – Sub-Word Units (например, слоги, или полученные автоматически сочетания фонем).
Использование доверительных оценок, полученных различными системами распознавания.
15.1. Использование моделей заполнения 
Одним из методов обработки OOV-слов является использование моделей заполнения (Filler models) [2].
Модель заполнения представляет собой универсальную модель слова, в которой возможны произвольные последовательности фонем (рис. 1 5.1).
Эта модель подставляется в словный граф (рис. 1 5.2), как обычное слово, но вход в неё затрудняется некоторым порогом, который подбирается эмпирически на большом речевом материале, содержащем слова, не входящие в словарь системы.
Языковая модель, учитывающая OOV-слова, строится на основе очень большой текстовой ба зы данных и включает OOV-слова в n-граммы.
С такой языковой моделью можно дать доверительную оценку различных гипотез, включающих и не включающих OOV-слова.
Вероятность OOV-слова является произведением вероятностей фонем при прохождении по графу общей моде ли слова: Npppp...2 1, где N – количество фонем.
Тогда, с учётом (14.1), решение о наличии OOV-слова принимается, если)()|() () |()|(i iwPwXP OOVP OOVpPpXP  (15.2) для любого слова wi, принадлежащего словарю.
Рис. 1 5.2. Словный граф модели фразы.
Схема общей модели слова допускает усовершенствования: после распознавания и получения альтернативных цепочек фонем с различными вероятностями к ним применяются ограничения в виде фонемной грамматики.
Грамматика определяет вероятности следования фонем и эквивалентна N-граммным моделям языка.
Фонемная грамматика может определяться на том же обучающем корпусе, что и вся система, или учитывать только статистику OOV- слов (Oracle), что даёт существенное улучшение параметров системы, но, по- видимому, пригодно, в основном, для фиксированной предметной области, где фонетика OOV-слов имеет какие-то общие черты.
Отметим, что сходный приём используется для обработки так называемых «арте фактов» – неречевых звуков (кашель, мычание, звуки шагов, хлопанье двери,…) и выделения «ключевых слов».
В случае артефактов модель, конечно, строится не на основе моделей фонем, а представляет собой статистическую обработку соответствующего артефакта из д остаточной по размеру базы данных артефактов.
В задаче выделения ключевых слов для принятия решения вероятность появления произвольного слова сравнивается с вероятностью ключевого слова с наибольшей вероятностью из списка.
15.2.
Использование фиксированных комбинаций фонем Использование фиксированных комбинаций фонем, или частей слов (Sub- Word Units- SWU) [ 48] является развитием идеи ограничений на возможные фонемные цепочки.
Понятно, что фиксированный набор некоторых комбинаций фонем ограничивает возможны е цепочки существеннее, чем грамматики, которые разрешают любые комбинации, хоть и с различными вероятностями.
Для построения SWU используется уже знакомый по разделу 8.2 метод, управляемый данными (data-driven approach).
Оценивается статистика сочетаний фонем или их комбинаций на большой базе данных.
Процесс носит итеративный характер и начинается с отдельных фонем.
Критерием для объединения некоторых комбинаций фонем в новую комбинацию является взвешенная взаимная информация MIw двух комбинаций:)()(),(log),(),(j jj i j i j i wupupuupuup uu MI ,  (15.3) где ui – SWU с номером i, полученная в предыдущих циклах итераций.
На каждой итерации n пар SWU (n устанавливается эмпирически) с наибольшими взвешенными взаимными информациями объединяется.
Конечное количество SWU зависит от числа итераций.
Попутно можно получить парсинг всего словаря в терминах, полученных SWU.
Эксперименты с английским языком продемонстрировали, что после 200 итераций из получившихся 1977 SWU две трети представляли обычные слоги, а средняя длина SWU составляла 3.2 фонемы.
Метод показал существенное улучшение по сравнению с фонемными N- граммами: для уровня определения OOV-слов в 70% ошибка ложной тревоги уменьшилась с 8.7% до 3.2%.
Развитием описанных методов является мультиклассовая OOV-модель.
Идея модели заключается в том, что все слова можно разбить на грамматические классы (существительные, глаголы, прилагательные, наречия, а также имена).
Слова, принадлежащие к одному классу, могут иметь сходства в фонотактической структуре и выступать сходн ым образом в модели языка, что позволяет получить более точную модель OOV-слова в соответствии с его местом во фразе.
15.3.
Использование нескольких систем распознавания Новым подходом в детектировании OOV-слов является использование доверительных оценок, полученных распознающими системами с различными по степени ограничениями.
Например, в работах [ 49, 50] сравнивались апостериорные вероятности, полученные от системы с сильными ограничениями (система распознавания слитной речи с большим словарём и моделью языка – LVCSR – Large Vocabulary Continuous Speech Recognition system) и системы со слабыми ограничениями (система распознавания фонемных цепочек).
Метод основан на естественном предположении, что, если отсутствующее в словаре слово будет ошибочно распознано как словарное, то цепочка распознанных фонем будет содержать фрагменты, плохо согласующиеся с распо знанным словом.
Использование фонемного распознавания стало возможным в последние годы на основе применения долговременных признаков (см. 10.1) и нейронныхсетей для оценки вектора апостериорных вероятностей фонем, соответствующих фрагменту речи.
В результ ате работы двух систем распознавания для каждого момента времени t будут получены два вектора, представляющие вероятности фонем: T p tT p t tNq tiq tq QtNp tip tp P))| (),...,|(),...,|1((,))| (),...,|(),...,|1((,  (15.4) где Np – количество фонем, p(i t|) и q(i t|) – апостериорные вероятности для фонемы с номером i в момент времени t для двух систем.
Эти данные используются для получения локальных (на одном окне) доверительных оценок, на основании которых можно выносить суждение о наличии или отсутствии внесловарного слова.
Отметим, что векторы вероятностей, полученные системой с сильными ограничениями, использующими словарь и модель языка, в отличие от модели со слабыми ограничениями, содержат большое количество компонент, близких к нулю.
Это затрудняет применение стандартных метрик, использующих логарифмы, например, метрики Кульбака-Лейбрера.
Наилучший результат даёт подход, основанный на нейронных сетях [49].
Усредняя на слове локальные доверительные оценки, получим интегральную доверительную оценку для данного слова, при этом примем во внимание, что, если OOV-слово отличается от IV-слова только одно фонемой, такое усреднение не имеет смысла.
Следует отметить, что, несмотря на некоторые успехи в определении внесловарных слов, задача остаётся до конца не решённой – существуют слова, которые являются объединением словарных слов (female – fee male), определить которые может только система с мощной моделью языка, а то и с элементами понимания; возможны оговорки, неправильные произнесения незнакомых для диктора терминов и много другого брака в акустическом сигнале.
По-видимому, говорить о «полном решении» задачи определения OOV-слов можно в том же смысле, что и об «окончательном решении» задачи автоматического распознавания речи.
16. АУДИОВИЗУАЛЬНОЕ РАСПОЗНАВАНИЕ РЕЧИ 
Во многих условиях функционирования (низкое качество звукового сигнала, присутствие сильного внешнего шума или посторонних разговоров и т.д.) стандартные системы автоматического распознавания речи н е могут обеспечивать приемлемое качество работы даже при применении различных методов фильтрации и шумоподавления.
Для того чтобы повысить качество и робастность работы автоматических систем применяются также способы распознавания визуальной информации о р ечи на базе технологий машинного зрения (так называемое «чтение речи по губам »), создавая системы аудиовизуального (бимодального) распознавания речи.
Очевидно, что речь передается не только в виде звуковой волны, она поступает от человека одновременно по нескольким информационным каналам (модальностям), в том числе по звуковому и визуальному.
Так, например некоторые реализации фонем (звуков речи) очень легко спутать н а слух (например, /м/ и /н/), но легко отличить визуально (/м/ производится с закрытым ртом, а /н/ – с открытым).
При объединении потоков информации от аудио- и видеораспознавателей результат совместной обработки может превышать точность распознавания по к аждой из модальностей.
При восприятии речи человеком известен также эффект МакГурка (McGurk) [80], когда правильный элемент возникает только при объединении звуковой информации и визуальной информации, получаемой слушателем от артикуляции губ диктора.
Как известно, речь производится человеком путем взаимосвязанных действий нескольких групп анатомических органов человека (грудная клетка, легкие, трахея, голосовые связки, гортанная трубка, полость глотки, нёбная занавеска, полость рта, полость носа, язык, губ ы) [56].
В ходе комплексного процесса понимания речи органы слуха человека воспринимают звуки, в то время как глаза видят движения лица, языка и губ и вся эта информация объединяется в мозгу человека в единое представление смысла высказывания.
Слабослышащи е и пожилые люди, а также неносители языка больше опираются на визуальную информацию, выражаемую движениями губ и лицевыми органами, чем на звуковую.
Визуальные сигналы очень важны для лучшего понимания произносимой речи, так, глядя в лицо собеседнику, лег че понимать его речь, особенно если речь иностранная.
Сигналы от визуальных и слуховых каналов дублируют и дополняют друг друга, что помогает правильно воспринимать речь во многих сложных ситуациях, например, при воздействии динамических акустических шумов, или когда одновременно говорят несколько человек.
16.1.
Способы объединения аудио- и видеомодальностей речи Существу ют два основных подхода к объединению звуковой и визуальной информации (information fusion) при бимодальном распознавании речи [ 81]: 1) Первый способ называют «ранним » объединением (early fusion) – рисунок 1 6.1.
В данном подходе независимо вычисляется параметрическое представление звукового и визуального сигналов, а затем, с учетом достаточновысокой степени синхронности этих модальностей, формируется единый вектор признаков (супервектор) для каждого сегмента сигнала.
На этапе классификации (распознавания) речи используются методы, использующие Скрытые Марковские Модели (СММ) или Искусственные Нейронные Сети, при этом создаются общие модели для акустических единиц речи (фонем) и визуальных единиц речи (визем – изображений формы губ при произнесении различных фонем).
Вектор признаков Вектор признаков Вычисление аудиопризнаков Вычисление видеопризнаков Объединение модальностей Решение Классификация (СММ) Рис. 1 6.1.
Способ «раннего» объединения звуковой и визуальной модальностей.
2) Второй способ объединения информации осуществляет «поздн ее» объединение модальностей (late fusion) – рисунок 16.2.
Способ поздней интеграции использует независимые друг от друга СММ для вероятностного моделирования звуковых и визуальных сигналов речи.
Объединение модал ьностей возможно как на уровне состояний вероятностных моделей, так и на уровне потоков фонем /визем или даже гипотез распознавания фраз.
Набор гипотезНабор гипотез Вычисление аудио признаков Вычисление видео признаков Классификация фонем (СММ) Классификация визем (СММ)Объединение модальностей Решение Рис. 1 6.2.
Способ «позднего » объединения звуковой и визуальной модальностей речи.
Существуют также и различные гибридные способы объединения аудиовизуальной речевой информации.
При этом, в любом способ е объединения бимодальной информации окончательное решение о распознанном сообщении принимается с учетом весовых коэффициентов информатив ности каждой модальности, которые изменяются в зависимости от окружающих условий (уровень шума, освещения, и т.д.).
Так, например, информативность звуковой информации будет невысока в производственных помещениях, в аэропортах и вокзалах, в условиях сильног о дождя и т.д. Визуальная же информация будет практически бесполезна при слабом освещении, ночью и т.д. Объединение же модальностей позволяет получить правильный результат практически в любых условиях эксплуатации, повышая робастность к шумам и точность работы системы распознавания речи.
Реализация метода синхронизации и интеграции речевых модальностей является одной из основных задач системы аудиовизуального распознавания речи на любом языке.
Суть проблемы состоит в естественном рассогласовании двух основных речевых модальностей, т.е. в естественной человеческой речи потоки соответствующих фонем и визем (которые являются результатом артикуляции) не являются полностью синхронными по времени, хотя и значительно перекрываются [82].
Так, например, при произнесении звука /у/ мы сначала складываем губы “в трубочку”, а затем производим нужный звук или же для произнесения звука /м/ мы сначала должны сомкнуть губы.
Такой феномен, вызван динамикой процесса речеобразования (ограниченной скор остью движения органов артикуляции, которые и формируют различные звуки) и эффектом коартикуляции, который является процесс ом взаимного влияния (взаимопроникновения) определенных речевых единиц на соседние элементы речи.
Необходимо отметить, что коартикуляция по-разному проявляется на акустическом и визуальном компонентах речи, что и вызывает асинхронность между ними.
Правильная синхронизация модальностей речи имеет важное значение и при восприятии речи человеком (в том числе синтезированной речи), так как она напрямую влияет как на разборчивость, так и естественность речевого высказывания.
Исследования показывают, что д ля различных языков и культур степень синхронности потоков фонем и визем в процессе речеобразования различна.
Так, например, для японского я зыка движения губ и звуковой поток практи чески синхронны, поэтому способ раннего объединения многомодальной информации показывает наилучшие результаты [83].
Английскому же языку (особенно американскому варианту) сопутствует достаточно богатая артикуляция г уб (даже гиперартикуляция), что вызывает определенные временные расхождения между потоками фонем и визем (до нескольких сотен миллисекунд) ; поэтому модели распознавания с поздним объединением информации в этом случае предпочтительны.
В разных языках эксперты выделают разное количество визем (также как и фонем), в английском их 12-14, в русском 10-12 в зависимости от диктора.
В таблице 16.1 показаны базовые классы визем русской речи и соответствие фонемам.
В данном случае мы считаем, что в русской речи существует 47 фонем, включая ударные и безударные (редуцированные) варианты гласных; согласные звуки соответствуют фонетическому алфавиту SAMPA.
В данной таблице представлены 10 классов визем, включая нейтральное положение губ.  Таблица 16.1.
Классы визем русской речи и их соответствие фонемам русской речи.
Класс виземы Тип виземы /фонемы Соответствующие фонемы русской речи V1 Неогубленные гласные (широкое открытие рта) /а!/, /а/, /э!/, /э/ V2 Неогубленные гласные (остальные) /и/, /и!/, /ы/, /ы!/ V3 Огубленные гласные звуки /о!/, /у/, /у!/ V4 Губные согласные /б/, /б’/, /п/, /п’/, /м/, /м’/ V5 Губно-зубные согласные /ф/, /ф’/, /в/, /в’/ V6 Альвеолярные фрикативные согласные /ш/, /ж/, /ч/, /щ/ V7 Альвеолярные сонорные согласные /л/, /л’/, /р/, /р’/ V8 Зубные согласные /д/, /д’/, /т/, /т’/, /н/, /н’/, /с/, /с’/, /з/, /з’/, /ц/ V9 Заднеязычные согласные /г/, /г’/, /к/, /к’/, /х/, /х’/, /й/ V10 Пауза (нейтральное положение губ) тишина (пауза) На рисунке 16.3 показана о бщая архитектура системы аудиовизуального распознавания речи.
В системе и спользуются независимые друг от друга цифровая видеокамера и микрофон, параллельно вычисляются признаки аудио- и видеосигналов, объединение модальностей может производиться на раннем либо позднем уровне.
Поиск лица и отслеживание губ в кадрахВычисление визуальных признаков речи Вычисление акустических признаков речи Объединение модальностей и классификация Синхронизация и разделение модальностей Обработка и сегментация сигнала Рис. 1 6.3.
Архитектура системы аудиовизуального распознавания речи.
Для в ычислени я информативных признаков из аудиосигнала могут использоваться различные методы спектральной обработки (например, MFCC признаки), которые были описаны в предыдущих разделах.
Для вычисления признаков движений губ по видеосигналу могут использоваться 2 различных подхода: 1) Пиксельные признаки : нахождение прямоугольной графической области (region of interest) рта диктора и из влечение информативных признаков (например, методом анализа главных компонент PCA).2) Геометрические визуальные признаки : нахождение и описание контура (формы) губ диктора при говорении (например, используя цветовую фильтрацию изображения) ; такие признаки описывают геометрические параметры губ диктора: ширина рта, толщина верхней и нижней губ, видимость языка и зубов и т.д. 16.2 Методы аудиовизуального моделирования и распознавания речи Наиболее распространены два основных метода моделирования и распознавания аудиовизуально й речи, которые основаны на следующих модификациях скрытых марковских моделей : 1) Многопоточны е скрыты е марковски е модел и (МПСММ, Multi-stream HMM), в которых независимо используются несколько типов признаков в единой СММ.
Эти модели реализуют ранний подход к объединению модальностей (на уровне признакового описания), такие модели являются синхронными относительно аудио- и видеопризнаков речи.
2) Сдвоенные скрытые марковские модели (ССММ, Coupled HMM), в которых используются параллельные асинхронные СММ модели, а объединение информации происходит на уровне состояний ССММ моделей, реализуя поздний подход к объединению информации.
В данных типах моделей звуковые и визуальные речевые признаки разносятся по двум разным потокам, но объединен ие происходит различными способами на разных уровнях скрытых марковских моделей.
На рисунке 16.4. показан пример топологии МПСММ одной аудиовизуальной единицы речи [84], здесь видно, что состояния в моделях являются общими для двух потоков информации, а ве ктора признаков аудио- и видеосигналов вычисляются независимо и объединяются с учетом весовых коэффициентов каждой модальности.
Недостатком таких моделей является то, что они не могут обрабатывать возможную асинхронность аудио- и видеомодальностей речи.
OV1S1 S2 S3 OV2 OV3P1 OA3 P1 OA2 P1 OA1 Рис. 1 6.4.
Топология многопоточной СММ аудиовизуальной единицы речи.
Для учета естественной для речеобразования временной асинхронности потоков соответствующих акустических и визуальных признаков речи былиразработаны сдвоенные скрытые марковские модели (ССММ, Coupled Hidden Markov Model) [ 85].
На рисунке 16.5 показана топология модели аудиовизуальной единицы речи (пара фонема/визема) с несколькими состояниями для каждого потока векторов признаков.
Кругами обозначены состояния ССММ, являющиеся скрытыми для наблюдения, а квадратами – смеси нормальных распределений векторов наблюдений в состояниях.
Сдвоенная скрытая марковская модель представляет собой набор параллельных СММ, по одной на каждый информационный поток (модальность), состояния модели в некоторый момент времени t для каждой СММ зависят от скрытых состояний в момент времени t-1 всех параллельных СММ.
Таким образом, общее состояние ССММ определяется совокупностью состояний двух параллельных СММ.
Преимущество такой топологии состоит в том, что она позволяет нескольким потокам векторов признаков независимо переходить по состояниям модели, что дает возможность моделировать допустимые временные расхождения в аудио- и видеоданных.
В топологии ССММ аудиовизуа льных единиц речи применяются по три состояния на каждый параллельный поток векторов признаков, при этом считается, что первые состояния соответствуют динамическому переходу от предыдущей речевой единицы, третьи – переходу к последующей единице, а вторые с остояния объединенной модели (самые длительные) соответствуют стационарному (центральному) участку речевой единицы.
OV1A1 A2 A3 V1 V2 V3 OV2 OV3P1 OA3 P1 OA2 P1 OA1  Рис. 16.
5. Топология сдвоенной СММ аудиовизуальной единицы речи.
Для определения сдвоенной скрытой марковско й модели    ,,,BDL некоторой аудиовизуальной единицы речи необходимо задать следующие параметры: 1) Количество скрытых состояний модели – L.
2) Распределение (матрица) вероятностей переходов между состояниями- }{ijd D, Li1, Lj1.3) Распределение вероятностей появления символов наблюдения (векторов признаков аудиовизуальной речи) в состояниях-)}({Ob Bj.
Обычно применяются смеси нормальных (гауссовских) распределений вероятностей:),,()(1jm jmM mjm j ONc Ob  , 1 1 M mjmc,  (16.1) где О- моделируемый вектор параметров (аудио или видеосигнала), Сjm- весовой коэффициент m-й компоненты в состоянии j, N- плотность вероятности (гауссовское распределение) со средним значение (математическое ожидание) jm и среднеквадратическое отклонение (дисперсия) jm для m-й компоненты смеси в состоянии j, M – количество смесей нормальных распределений в модели.
4) Веса информативности (значимость) },{V A речевых модальностей (аудио- и видеопотоков), которые могут настраиваться в ходе обучения моделей или адаптации к окружающим условиям и каналу передачи речи.. Причем, их сумма является константой: 2V A (16.2) В русской речи фонетисты выделяют несколько десятков различных фонем (от 40 до 50), поэтому и ССММ в бимодальной системе распознавания речи насчитывается столько же.
Различимых единиц видимой русской речи (визем) намного меньше (около 10).
Поэтому, как правило, в системе распознавания применяется связывание (tying) распределений векторов наблюдений визуальных компонент в состояниях разных ССММ.
На рисунке 16.6 пока заны связи параметров (распределения векторов наблюдений) визуальных моделей в рамках одного класса виземы при наличии нескольких акустических моделей (например, одна визема для двух фонем /б/ и /м/).
Таким образом, общее количество ССММ в системе равняется числу распознаваемых фонем, но для ряда моделей их параметры являются общими, что упрощает и улучшает процесс обучения моделей в условиях ограниченных обучающих данных.
Кроме того, в работе [ 86] был предложен весьма простой способ преобразования топологии сдвоенной СММ в эквивалентную лево-правую двухпоточную СММ модель (см. рисунок 16.7), которая сохраняет все свойства первой.
Результирующая СММ содержит все комбинации параллельных состояний исходной ССММ.
В ССММ оба потока независимы и распредел ения векторов наблюдений в состояниях вычисляются отдельно друг от друга, в двухпоточной СММ два распределения векторов наблюдений (для аудио- и видеосигналов) ассоциированы с каждым состоянием.
В топологии ССММ используется по 3 скрытых состояния на кажды й параллельный поток, соответственно в двухпоточной СММ будет 9 состояний (все их комбинации), поэтому, для того чтобы избежать утроения количества распределений векторов наблюдений в состояниях, используется связывание соответствующих распределений вектор ов наблюдений согласно рисунку 16.7.
OV1A1 A2 A3 V1 V2 V3 OV2 OV3P1 OA3 P1 OA2 P1 OA1 P2 OA1V1 V2 V3 A1 A2 A3 P2 OA2 P3 OA3 Рис 16.6.
Связывание двух СМММ для двух аудиовизуальных единиц русской речи из одного виземного класса.
Увеличение общего количества состояний модели аудиовизуальной единицы речи с 6 до 9 требует несколько большей оперативной памяти при программной реализации системы, однако на скорости декодирования такое преобразования не сказывается из-за большей простоты алгоритма декодирования речи (алгоритм Витерби, был описан в предыдущих разделах).
Параметры двухпоточных СММ (матрица вероятностей переходов из состояния в состояние и распределения векторов признаков аудио- и видеоданных в скрытых состояниях) аудиовизуальных единиц речи вычисляются, используя модифицированный алгоритм Баума-Уэлча (EM-алгоритм) [ 87], добиваясь максимальной оценки правдоподобия модели на обучающей выборке мультимедийных речевых записей.
A2 V1A2 V2A2 V3A3 V1A3 V2A3 V3A1 V1A1 V2A1 V3 OV1 OV2 OV3OA1 OA2 OA3  Рис 16.7.
Отображение сдвоенной СММ в эквивалентную двухпоточную СММ.
Для декодирования (распознавания) с литной речи, подаваемой на вход системы из аудиовизуального файла или с устройств, применяется модифицированный метод передачи маркеров (token-passing method) [84], основанный на оптимизационном алгоритме Витерби для многопоточных СММ, который определяет вероятность порождения символов наблюдений (последовательностей векторов признаков) данной моделью и последовательность пройденных при этом скрытых состояний модел и. Суть данного метода состоит в следующем: для моделирования потенциально возможных фраз слитной речи строится единая вероятностная модель (граф) со всевозможными вариантами переходов между СММ минимальных единиц речи (ограниченными словарем распознавания) и между СММ слов (ограниченными конечной грамматикой или вероятностной моделью языка), затем методом динамического программирования (алгоритм Витерби) производится нахождение оптимальной по критерию максимального правдоподобия последовательности/пути скр ытых состояний (несущих информацию о речевых единицах) модели для порождения обрабатываемой последовательности наблюдений.
В результате декодирования речевого сигнала автоматической системой выдается одна или несколько наилучших гипотез (N-best list) распознавания произнесенной диктором фразы.
Многие экспериментальные результаты мировых исследований по созданию систем бимодального распознавания речи, которые используют аудиовизуальную информацию, показывают, что они работают лучше (т.е. обеспечивают более высокую точность распознавания речи и лучшую робастность системы к аудиошумам), чем одномодальные системы, использующие только звуковую информацию [88-92].ЛИТЕРАТУР А 
1.Фланаган Дж. Анализ, синтез и восприятие речи. «Связь». Москва, 1968.
2. MIT Lectures 2003. http://ocw.mit.edu/courses/electrical-engineering-and- computer-science/6-345-automatic-speech-recognition-spring- 2003/download-course-materials/ 
3. Фант. Г. Акустическая теория речеобразования. «Наука». Москва, 1964.
4. Picone J. Fundamentals of speech recognition: a short course.1996. http://speech.tifr.res.in/tutorials /fundamentalOfASR _picone 96.pdf 
5. Алдошина И. Основы психоакустики. http://giga.kadva.ru/files/edu/AldoshinaPsychoacoustics.pdf 
6. Слухова я система. серия "О сновы современной физиологии". «Наука». Ленинград, 1990.
7. Seneff S. “Pitch and Spectral Analysis of Speech Based on an Auditory Synchrony Model ”, Technical Report 504, January 1985 
8. Hermansky H. (1997): “Should recognizers have ears?”, In RSR-1997, 1-10.
9. Маркел Дж.Д., Грей А.Х., Лине йное предсказание речи, Москва, «Связь». 1980.
10.Hermansky H., Morgan N., "RASTA Processing of Speech", in IEEE Transaction on Speech and Audio Processing, Vol.2, No. 4, pp.587-589, October 1994.
11. Карпов А.А., К ипяткова И.С., Методология оценивания работы систем автоматического распознавания речи // Известия вузов.Приборостроение, Т. 55, № 11, 2012, С. 38-43.
12. Левенштейн В.И., Двоичные коды с исправлением выпадений, вставок и замещений символов. Доклады Академий Наук СССР, 1965, 163.4:845- 848.
13. Khokhlov Y., Tomashenko N., “Speech Recognition Performance Evaluation for LVCSR System ”, In Proc. 14th International Conference “Speech and Computer” SPECOM-2011, Kazan, Russia, 2011, pp. 129-135.
14. Kurimo M., Creutz M., Varjokallio M., Arsoy E., Saraclar M., Unsupervised segmentation of words into morphemes- Morpho challenge 2005 Application to automatic speech recognition. In Proc. INTER SPEECH 2006, Pittsburgh, USA, 2006, pp. 1021-1024.
15. Schlippe T., Ochs S., Schultz T., Grapheme-to-Phoneme Model Generation for Indo-European Languages. In Proc. ICASSP-2012, Kyoto, Japan, 2012.
16. Huang C., Chang E., Zhou J., Lee K. Accent modeling based on pr onunciation dictionary adaptation for large vocabulary Mandarin speech recognition. In Proc. INTERSPEECH 2000, Beijing, China, 2000, pp. 818-821.
17. Ablimit M., Neubig G., Mimura M., Mori S., Kawahara T., Hamdulla A. Uyghur Morpheme-based Language Models and ASR. In Proc. 10th IEEE International Conference on Signal Processing ICSP-2010, Beijing, China,
2010, pp. 581-584.18. Karpov A., Kipyatkova I., Ronzhin A. Very Large Vocabulary ASR for Spoken Russian with Syntactic and Morphemic Analysis.
In Proc.INTERSPEEC H 2011, Florence, Italy, 2011, pp. 3161-3164.
19. Nanjo H., Kawahara T. A New ASR Evaluation Measure and Minimum Bayes- Risk Decoding for Open-domain Speech Understanding. In Proc. ICASSP- 2005, Philadelphia, USA, 2005, pp.
1053-1056. 
20. The US NIST 2009 (RT-09) Rich Transcription Meeting Recognition Evaluation Plan, http://www.itl.nist.gov/iad/mig/tests/rt/2009/ 
21.
Morris A.C., Maier V., Green P. From WER and RIL to MER and WIL: improved evaluation measures for connected speech recognition, In Proc.
INTERSPEECH 2004, Jeju Island, Korea, 2004, pp. 2765-2768.
22.Tran B.-H., Seide F., Steinbiss T. A word graph based N-best search in continuous speech recognition. In Proc.ICSLP-96, Philadelphia, USA, 1996, pp. 2127-2130.
23.Vilar J.M. Efficient computation of confidence intervals for word error rates, In Proc. ICASSP-2008, Las Vegas, USA, 2008, pp. 5101-5104.
24. Hansen J.H., Clements M.A. "Spectral Slope based Distortion Measures for All-Pole Models of Speech", Proc. IEEE Intl. Conf. on Acoustics, Speech and Signal Processing, pp.757-760, 1986.
25.
Mansour D., Juang B.H.
"A Family of Distourtion Measures based upon Projection Operation for Robust Speech Recognition", IEEE Transactions on Acoustics, Speech and Signal Processing., Vol.37, No.11, pp.
1659-1671, November 1989.
26.
МIT lectures “Automatic Speech Recognition”, Lecture 9, “Dynamic Time Warping & Search”, http://ocw.mit.edu/courses/electrical-engineering-and- computer-science/6-345-automatic-speech-recognition-spring-2003/lecture- notes/lecture9.pdf.
27.
Рабинер Л. Скрытые марковские модели и их применение в избранных приложениях при распознавании речи: Обзор.
ТИИЭР, 1989, т. 77, № 2, с. 86-120.
Rabiner L.R., A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition.
Proceedings of the IEEE, Vol.
77, No.
2, February 19 89, pp.
257-286. http://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf 28.
Burshtein D., “Robust Parametric Modeling of Durations in Hidden Markov Models”, IEEE Transactions on Speech and Audio Processing, Vol.
, No.
3, May 1996, pp.
240-242.
29.
Odell J.J., “The Use of Context in Large Vocabulary Speech Recognition”, Dissertation, 1995. http://mi.eng.cam.ac.uk/reports /svr-ftp/auto- pdf/odell _thesis.pdpdf /odell _thesis.pdf 30.
Huang X., Acero A., Hon H.
-W. Spoken language processing.
2001.
31.
Legetter C.J., “Improved Acoustic Modelling for HMMs Using Linear Transformations”, Ph.D.
thesis, Cambridge University, 1995. ftp://svr- ftp.eng.cam.ac.uk/pub/reports/auto-pdf/leggetter_thesis.pdf 32.
Jeff A. Bilmes, “ A Gentle Tutorial of the EM Algorithm and its Application to Parameter Estimation for Gaussian Mixture and Hidden Markov Models ”,International Computer Science Institute Berkeley CA, 94704 and Computer Science Division Department of Electrical Engineering and Computer Science, U.C.
Berkeley, TR-97-021, April 1998.
33.
Nguen P., “Fast Speaker Adaptation”, Rapport de these professionnelle, Institut Eurecom, June 18, 1998.
34.
Kuhn R., Junqua J.
-C., Nguen P., Niedzielski N., “Rapid Speaker Adaptation in Eigenvoice Space”, IEEE Transactions on Speech and Audio Processing, Vol.
8, No.
6, November 2000.
35.
Jonson K., “Speaker Normalization in Speech Perception”, Ohio State University, 2005, pp.
1-45.
36.
Panchapagesan S., “Frequency Warping by Linear Transformation of Standard MFCC,” in Interspeech 2006, Pittsburgh, USA, 2006.
37.
Molau S., Kanthak S., Ney H., “ Efficient Vocal Tract Normalization in Automatic Speech Recognition”.
Konf.
Elektron.
Sprachsignalverarbeitung, Cottbus, pp.
209-216, Sep.
2000.
38.
Hain T., Woodland P., Niesler T., Whittacker E., “The 1998 HTK System For Transcription of Conversational Telephone Speech”, in: Proceedings International Conference on Acoustics, Speech and Signal Processing, Mar 1999, pp.
57 – 60, vol.1.
39.
Hermansky H., Sharma S., "Temporal patterns (traps) in asr of no isy speech", in Proc.
IEEE Int.
Conf.
Acoust., Speech, Signal Processing (ICASSP), Phoenix, Arizona, USA, Mar.
1999. http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.
5036 40.
Hermansky H., Jain P., "Beyond a single critical-band in trap based asr", in Proc.
Eurospeech, Geneva, Switzerland, Sep.
2003.
41.
Schwarz P., "Phoneme recognition based on long temporal context", Ph.D.
thesis, Brno University of Technology, 2008. http://www.fit.vutbr.cz/~schwarzp/publi/thesis.pdf 42.
Oparin I., Talanov A.
“Stem-Based Approach to Pronunciation Vocabulary Construction a nd Language Modeling of Russian”, Proc.
of the 10th Interna tional conference on Speech and Computer, SPECOM-2005.
Patras, Greece, 2005. pp.
575-578.
43.
Jelinek F., Chelba C. Recognition Performance of a Structured Language Model.
Eurospeech 1999. http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.2129 44.
Mohri M., Pereira F., Riley M., “ SPEECH RECOGNITION WITH WEIGHTED FINITE-STATE TRANSDUCERS ”, Springer Handbook on Speech Processing and Speech Communication.
45.
Kinderman R., Snell J.L., “Markov Random Fields and Their Applications”, American Mathematical Society, 1980. http://www.cmap.polytechnique.fr/~rama/ehess/mrfbook.pdf 46.
Abdel-Haleem Y.H., “Conditional Random Fields for Continuous Speech Recognition”, 2006. http://homepages.inf.ed.ac.uk/srenals/yasser-thesis.pdf47.
Gunawardana A., Mahajan M., Acero A., Platt J. C., “ Hidd en conditional random fields for phone classificati on”// In Proc.
INTERSPEECH 2005, pp.
1117 –1120.
48.
Parada C., Dredze M., Sethy A., Rastow A., “ Learning Sub-Word Units for Open Vocabulary Speech Recognition”, Proc.
Of the 49th Annual Meeting of the Associa tion for Computational Linguistics, June 19-24, 2011, pp.
712-721.
49.
Burget L., Schwarz P., et al., “ COMBINATION OF STRONGLY AND WEAKLY CONSTRAINED RECOGNIZERS FOR RELIABLE DETECTION OF OOVS ”, IEEE International Conference on Acoustics, Speech and Signal P rocessing, 2008.
ICASSP 200 8, pp.
4081-4084.
50.
Hannemann M., “Combinations of Confidence Measures for the Detection of Out-of-Vocabulary Segments in Large Vocabulary Continuous Speech Using Differently Constrained Recognizers”, Otto-von-Guericke-Universitat Magdeburg, 21.
April 2008.
51.
Bourlard H., Wellekens C.J.
, “Links between Markov models and multilayer perceptrons ”,  IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol.
12,  No.
12, 1990, pp.
1167-1178.
52.
Bourlard H., Herman sky H., Morgan N., “Towards increasing speech recognition error rates”, Speech Communication, V ol.
18, 1996, p.p.
205 –231.
53.
Hornik K., Stinchcombe M., White H., “Multilayer feedforward networks are universal approximators”, Neural Netw.
Vol.
2(5), 1989, pp.
359 –366.
54.
Hinton G., Deng L., Yu D., Dahl G., Mohamed A., Jaitly N., Senior A., Vanhoucke V., Nguyen P., Sainath T., Kingsbury B., “Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups”, IEEE Signal Process.
Mag.
, Vol.
29, No.
6, Nov.
2012, pp.
82 –97.
55.
Dong Yu, Li Deng, “ Automatic Speech Recognition.
A Deep Learning Approach”, Springer-Verlag, London.
2015, 321 p. 56.
Чистович Л.А. и др., «Руководство по физиологии.
Физиология речи.
Восприятие речи человеком», «Наука», Ленинград, 1976.
57.
Hermansky H., Ellis D., Sharma S., “Tandem connectionist feature extraction for conventional HMM systems”, Proc.
ICASSP-2000, Istanbul.
2000.
V.
3. pp.
1635 –1638.
58.
Deng, L., Chen, J., “Sequence classification using hi gh-level features extracted from deep neural networks.” In: Proceedings of the International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2014, pp.
6894-6898.
59.
Hochreiter S., Schmidhuber J., “Long short-term memory.” Neural Computation, V.
9(8), 1997, pp.
1735 –1780.
60.
Pascanu R., Mikolov T., Bengio Y., “On the difficulty of training recurrent neural networks”, Cornell University Library, arXiv:1211.5063 [cs.LG], 2013.
61.
Graves A., Fernández S., Schmidhuber J., “Bidirectional LSTM Networks for Improved Phoneme Classification and Recognition ”, Chapter: “Artificial Neural Networks: Formal Models and Their Applications” – ICANN 2005, pp 799-804.62.
Wollmer M., Eyben F., Schuller B., Rigoll G., “Recognition of Spontaneous Conversational Speech using Long Short-Term Memory Phoneme Predictions”, In: INTERSPEECH 2010, pp.
1946-1949.
63.
Graves A., Mohamed A., Hinton G., “Speech recognition with deep recurrent neural networks”, Cornell University Library, arXiv:1303.5778 [cs.NE], 2013.
64.
Graves A., Jaitly N., “Towards End-to-End Speech Recognition with Recurrent Neural Networks”, Proceedings of the 31st International Conference on Machine Learning, Beijing, China, 2014.
JMLR: W&CP V.
32.
65.
Sak H., Senior A., Beaufays F., “Long short-term memory recurrent neural network architectures for large scale acoustic modeling”, INTERSPEECH 2014, pp.
338-342.
66.
Sak H., Vinyals O., Heigold G., Senior A., McDermott E., Monga R., Mao M., “Sequence discriminative distributed training of long short-term memory recurrent neural networks”, In: INTERSPEECH 2014.
67.
Triefenbach F., Jalalvand A., Schrauwen B., Martens J.
-P., “ Phoneme Recognition with Large Hierarchical Reservoirs”, Conf: Advances in Neural Information Processing Systems 23, 2010, pp.
2307-2315.
68.
Triefenbach F., Demuynck K., Martens J.
-P., “Improving large vocabulary continuous speech recognition by combining gmm-based and reservoir-based acoustic modeling”, Spoken Language Technology Workshop (SLT), 2012 IEEE, pp.
107-112.
69.
Triefenbach F., Demuynck K., Martens J.
-P., “Large vocabulary continuous speech recognition with reservoir-based acoustic models”, IEEE Si gnal Processing Letters, Vol.
21, No.
3, March 2014, pp.
311-315.
70.
Jalalvand A., Demuynck K., De Neve W., Van de Walle R., Martens J.
-P., “Design of Reservoir Computing Systems for Noise-Robust Speech and Handwriting Recognition ”, Multimedia Lab, ELIS, Ghe nt University.
Ghent 9000, Belgium, 2015.
71.
Ronzhin A., Karpov A., “Implementation of morphemic analysis for Russian speech recognition ”, In Proc.
9th International Conference on Speech and Computer SPECOM-2004, St.
Petersburg, Russia, 2004, pp.
291-296.
72.
Creutz M., Hirsimaki T., Kurimo M., Puurula A., Pylkkonen J., Siivola V., Varjokallio M., Arisoy E., Saraclar M., Stolcke A., “Morph-based speech recognition and modeling of out-of-vocabulary words across languages ”, ACM Transactions on Speech and Language Processing, 5(1), 2007.
73.
Sak H., Saraclar M., Güngör T., “Morphology-based and sub-word language modeling for Turkish speech recognition ”.
In Proc.
ICASSP-2010, pp.
5402- 5405.
74.
Tarjan B., Mihajlik P., “On Morph-Based LVCSR Improvements ”, In Proc.
2nd International Workshop on Spoken Languages Technologies for Under- resourced Languages SLTU-2010, Malaysia, 2010, pp.
10-16.
75.
Chelba C., Jelinek F., “Structured language model ” // Computer Speech and Language, 2000.
Vol.
10. pp.
283-332.76.
Sidorov G., Velasquez F., Stamatatos E., Gelbukh A., Chanona-Hernández L., “Syntactic Dependency-based N-grams as Classification Features ”, Springer LNAI 7630, Mexico, 2012. pp.
1-11.
77.
Szarvas M., Furui S., “Finite-state transducer based modeling of morphosyntax with applications to Hungarian LVCSR ” // Proc.
ICASSP’2003, Hong Kong, China, 2003. pp.
368–371.
78.
Холоденко А.Б., “О построении статистических языковых моделей для систем распознавания русской речи ” // Интеллектуальные системы, 2002.
Т.6.
Вып. 1-4.
С. 381-394.
79.
Karpov A., Markov K., Kipyatkova I., Vazhenina D., Ronzhin A., “Large vocabulary Russian speech recognition using syntactico-statistical language modeling ” // Speech Communication.
2014, Vol.
56, pp.
213-228.
80.
McGurk H., MacDonald J., “Hearing Lips and Seeing Voices // Nature, 264, 1976, pp.
746-748.
81.
Карпов А.А., “Реализация автоматической системы многомодального распознавания речи по аудио- и видеоинформации ” // Автоматика и телемеханика.
2014, Т. 75, № 12, С. 125-138.
82.
Кипяткова И.С., Ронжин А.Л., Карпо в А.А., “Автоматическая обработка разговорной русской речи ”.
– СПб.: ГУАП, 2013.
– 314 с. 83.
Sekiyama K., “Differences in auditory-visual speech perception between Japanese and America: McGurk effect as a function of incompatibility ” // Journal of the Acousti cal Society of Japan, Vol.
15, 1994, pp.
143-158.
84.
Young S. et al.
“The HTK Book (Version 3.5)”.
Cambridge University Engineering Department, 20 15.
85.
Nefian A.V.
, Liang L.H., Pi X., Xiaoxiang X., Mao C., Murphy K., “A Coupled HMM for Audio-Visual Speech Recognition ”, In Proc.
International Conference ICASSP-2002, Orlando, USA, 2002, pp.
2013 –2016.
86.
Chu S., Huang T., “Multi-Modal sensory Fusion with Application to Audio- Visual Speech Recognition ”, In Proc.
Multi-modal Speech Recognition Workshop 2002, Green sboro, USA, 2002.
87.
Rabiner L., Juang B., “Speech Recognition ”, Chapter in Springer Handbook of Speech Processing, NY: Springer, 2008.
88.
Potamianos G., Neti C., Luettin J., Matthews I., “Audio-Visual Automatic Speech Recognition: An Overview ”, Chapter in “Issues in Visual and Audio- Visual Speech Processing ”.
MIT Press, 2005.
89.
Bailly G., Perrier P., Vatikiotis-Bateson E., “Audiovisual Speech Processing ”, Cambridge University Press, 2012, 506 p. 90.
Stewart D., Seymour R., Pass A., Ming J., “Robust audio-visual speech recognition under noisy audio-video conditions” // IEEE Transactions on Cybernetics, Vol.
44, № 2, 2014, pp.
175-184.
91.
Noda K., Yamaguchi Y., Nakadai K., Okuno H., Ogata T., “Audio-visual speech recognition using deep learning” // Applied Intelligence, Vol.
42, 2015, pp.
722-737.92.
Katsaggelos A.K., Bahaadini S., Molina R., “Audiovisual Fusion: Challenges and New Approaches ” // Proceedings of the IEEE, Vol.
103, № 9, 2015, pp.
1635-1653.
93.
Pierce, L. J. et al.
// “Past experience s hapes ongoing neural patterns for language ”, Nat.
Commun.
6:10073 doi: 10.1038/ncomms10073 (2015).
http://www.nature.com/articles/ncomms10073 94.
Wermke, K. et al.
“Fundamental frequency variation within neonatal crying: Does ambient language matter?
” // Speech, Language and Hearing, Vol.
19, Issue 4, 2016, pp.
211-217.
95.
Дольник В. Непослушное дитя биосферы.
«Петроглиф».
СПб. 2011 96.
Tomashenko N., Khokhlov Y., “Speaker adaptation of context dependent deep neural networks based on MAP-adaptation and GMM-derived feature processing” // In Proc.
INTERSPEECH 2014, Singapore, 2014, pp.
2997-3001.
97.
Li, J., Yu, D., Huang, J.T., Gong, Y., “Improving wideband speech recognition using mixed-bandwidth training ” // Proceedings of the IEEE Spoken Language Technology Workshop (SLT), 2012, pp.
131 –136.
98.
Xue, J., Li, J., Yu, D., Seltzer,M., Gong, Y., “Singu lar value decomposition based low-footprint speaker adaptation and personalization for deep neural network”// Proc.
ICASSP’2014, Florence, Italy, 2003. pp.
6409-6413.
99.
Karafiat M., Burget L., Matˇejka P., Glembek O., ˇCernock´y J., “iVector- Based Discrimin ative Adaptation for Automatic Speech Recognition”// Automatic Speech Recognition and Understanding (ASRU), 2011 IEEE Workshop, 2011, pp.
152-157.
100.
Prudnikov A., Medennikov I., Mendelev V., Korenevskiy M., Khokhlov Yu., “Improving Acoustic Models For Russian Spontaneous Speech Recognition ”// In Proc.
17th International Conference “Speech and Computer” SPECOM- 2015, Athens, Greece, 2015, pp.
234-242.
101.
Bengio Y., Ducha rme R., Vincent P., “A neural probabilistic language model”// Journal of Machine Learning Research, Vjl.
3, 2003, pp.
1137-1155.
102.
Schwenk H., Gauvain J.
-L., “Training Neural Network Language Models On Very Large Corpora”// in Proc.
Joint Conference HLT/EMNL P, October 2005, pp.
201-208.
103.
Schwenk H., “Continuous space language models”// Computer Speech and Language Vol.
21, 2007, pp.
492 –518.
104.
Mikolov T., Karafia´t M., Burget L., Cˇernocky´ J., Khudanpur S., “Recurrent neural network based language model” //.
INTERSPEECH 2010, Chiba, Japan, 2010, pp.
1045-1048.
Миссия университета – генерация передовых знаний, внедрение инновационных разработок и подготовка элитных кадров, способных действовать в условиях быстро меняющегося мира и обеспечивать опережающее развитие науки, технологий и других областей для содействия решению актуальных задач.
КАФЕДРА РЕЧЕВЫХ ИНФОРМАЦИОННЫХ СИСТЕМ О кафедре Кафедра речевых информационных сист ем (РИС) создана в 2011 году на факультете Информационных технологий и программирования (ФИТиП).
Организатором создания кафедры выступает «Центр речевых технологий» (www.speechpro.ru).
Заведующий кафедрой – доктор технических наук Матвеев Юрий Николаевич.
Кафедра РИС обеспечивает подготовку докторантов, аспирантов и магистров.
Для тех, кто имеет высшее образование, но хотел бы связать свое будущее с речевыми технологиями, имеются курсы дополнительного профессионального образования.
Обучение на кафедре Кафед ра «Речевые информационные системы» (базовая кафедра «Центра речевых технологий») Санкт-Петербургского национального исследовательского университета информационных технологий, механики и оптики (ИТМО) в рамках направления 09.04.02 «Информационные системы и технологии» открывает прием в магистратуру по новой образовательной программе «Речевые информационные системы».
Срок обучения – 2 года.
Обучение завершается защитой магистерской диссертации.
Целевая установка магистратуры – подготовка специалистов, способ ных участвовать в исследовательской и проектной работе в области речевых информационных технологий со специализацией в направлениях распознавания и синтеза речи, распознавания личностей по голосу, мультимодальной биометрии, в области проектирования и разра ботки информационных систем и программного обеспечения.
Область профессиональной деятельности выпускников кафедры РИС включает:  исследование, разработка, внедрение речевых информационных технологий и систем;  методы и алгоритмы цифровой обработки речевых си гналов;  автоматизированные системы обработки речевых сигналов;  программное обеспечение автоматизированных речевых информационных систем;  системы автоматизированного проектирования программных и аппаратных средств для речевых информационных систем и информационной поддержки таких средств.
Объектами профессиональной деятельности выпускников кафедры РИС являются:  информационные процессы, технологии, системы и сети, предназначенные для обработки, распознавания, синтеза речевых сигналов;  инструментальное (математическое, информационное, техническое, лингвистическое, программное, эргономическое, организационное и правовое) обеспечение речевых информационных систем;  способы и методы проектирования, отладки, производства и эксплуатации информационных технологий и си стем в областях обработки, распознавания, синтеза речевых сигналов, телекоммуникации, связи, инфокоммуникации, медицины.
Широкий профиль подготовки, знание универсальных методов исследования и проектирования информационных систем, практические навыки работ ы с современным программным обеспечением – все это позволяет выпускникам кафедры найти работу в научных институтах и университетах, в фирмах, на производственных предприятиях, а также в коммерческих структурах.
Учебный план предусматривает, в частности, сл едующие курсы:  Информационные технологии:  Системный анализ и моделирование информационных процессов и систем;  Проектирование информационных систем;  Организация проектирования и разработки программного обеспечения распределенных и встроенных систем;  Тестирования программного обеспечения;  Управление качеством разработки программного обеспечения.
Речевые технологии:  Цифровая обработка сигналов;  Цифровая обработка речевых сигналов;  Математическое моделирование и теория принятия решений;  Распознавание обр азов;  Распознавание и синтез речи;  Распознавание диктора (говорящего по голосу);  Мультимодальные биометрические системы.
К преподаванию привлекаются ведущие специалисты «Центра речевых технологий», преподаватели Университета ИТМО, а также специалисты, работающие в известных научных организациях (СПИИРАН), а также производственных и коммерческих организациях.
Тампель Иван Борисович, Карпов Алексей Анатольевич АВТОМАТИЧЕСКОЕ РАСПОЗНАВАНИЕ РЕЧИ Учебное пособие  В авторской редакции Редакционно-издательский отдел Университета ИТМО Зав. РИО     Н.Ф. Гусарова Подписано к печати 07.12.2017 Заказ № 4092 Тираж 100 Отпечатано на ризографе                     Редакционно-издательский отдел Университета ИТМО 197101, Санкт-Петербург, Кронверкский пр., 49
Санкт-Петербург 2021 М. Б. Столбов ОСНОВЫ А НАЛИЗ А И ОБРАБОТК И РЕЧЕВЫХ СИГНАЛОВ    Санкт-Петербург 2021 МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ УНИВЕРСИТЕТ ИТМО М. Б. Столбов ОСНОВЫ АНАЛИЗ А И ОБРАБОТК И РЕЧЕВЫХ СИГНАЛОВ УЧЕБНО Е ПОСОБИЕ РЕКОМЕНДОВАНО К ИСПОЛЬЗОВАНИЮ В УНИВЕРСИТЕТЕ ИТМО по направлению подготовки 09.04.02 «Информационные системы и технологии» в качестве учебно-методического пособия для реализации основных профессиональных образовательных программ высшего образования магистратуры    Столбов М.Б., Основы анализа и обработки речевых сигналов – СПб. : НИУ ИТМО, 202 1.
– 101 с. Рецензент: Рыбин Сергей Витальевич, кандидат физико-математических наук, доцент (квалификационная категория «доцент практики») факультета информационных технологий и программирования, Университета ИТМО.
Пособие адресовано студентам магистратуры, обучающимся по направлению «Информационные системы и технологии» по профилю подготовки «Р е- чевые информационные системы».
В пособии изложены основы анализа и обработки речевых сигналов.
Материал пособия представляет собой базу для последующего освоения углубленных курсов обработки речевых сигналов.
Теоретический материал, подкрепляется вопросами и упражнениями.
Рекомендовано к использованию в Университете ИТМО по направлению подготовки (специальности) 09.04.02 Информационные системы и технологии в качестве учебно-методического пособия.
Университет ИТМО – ведущий вуз России в области информационных и фотонных технологий, один из немногих российских вузов, получивших в 2009 году статус национального исследовательского университета.
С 2013 года Университет ИТМО – участник программы повышения конкурентоспособности российских университетов среди ведущих мировых научно-образовательных центров, известной как проект «5 в 100».
Цель Университета ИТМО – становле- ние исследовательского университ ета мирового уровня, предпринимательского по типу, ориентированного на интернационализацию всех направлений де я- тельности.
© Университет ИТМО, 202 1 © Столбов М. Б., 202 1 © Коняхин В. В., оформление, 2021 3 ПРЕДИСЛОВИЕ В связи с бурным развитием информационных, в частности, речевых технологий (РТ) возникла значительная дифференциация различных отраслей о б- работки речевых сигналов.
К настоящему времени по различным направлениям речевых технологий издано большое число монографий.
Для их прочтения необходимы базовые представления о речевых сигналах, методах их анализа и о б- работки.
Такого издания на русском языке в настоящее время нет.
Фундаментальные монографии по цифровой обработке речевых сигналов (ЦОРС) были изданы на русском языке около четырех десятилетий назад, когда обработка речевых сигналов еще представлялась единой областью.
Предлагаемое пособие призвано восполнить существующий пробел и тем самым способствовать сокращению разрыва в развитии речевых технологий в России и за рубежом.
Цель данного пособия – прежде всего, познакомить читателя с основами анализа и базовыми методами первичной обработки речевых сигналов для дальнейшего использования в решении прикладных задач и углубленного изучения интересующих специальных вопросов.
Название книги «Анализ и цифровая об- работка речевых сигналов» должно подчеркнуть отличие данного курса от широко распространенных курсов по цифровой обработке сигналов и обозначить тот факт, что для анализа и обработки речевых сигналов в настоящее время должны применяться цифровые средства их обработки.
Книга возникла на о с- нове материалов лекций по курсу ЦОРС.
Для чтения данной книги необходимо предварительное знакомство с теорией и алгоритмами цифровой обработки сигналов (свертка, преобразование Фурье, основы линейной алгебры и др.).
В пособии рассмотрены те понятия, характеристики дискретных речевых сигналов, методы их анализа и алгоритмы их обработки, которые мы считали важными, исходя из нашего опыта.
Рассмотренные вопросы соприкасаются с различными дисциплинами, такими как обработка аудиосигналов, статистика и прикладная математика, физика и другие.
Материал пособия представляет собой базу для дальнейшего освоения углубленных курсов обработки и анализа речевых сигналов (автоматическое распознавание речи, синтез речи и др.).
Большая часть теоретических материалов в книге приведена без доказательств, поскольку строгие доказательства привели бы к громоздким математическим выкладкам, что помешало бы восприятию физического смысла.
При этом даются ссылки на фундаментальные работы.
Углубленное изучение вопросов, затронутых в главе, можно осуществить, обратившись к литературе, список которой приводится в конце пособия.
Для облегчения восприятия англоязычной литературы основные термины даются как на русском, так и на английском языке.
В конце пособия помещен англо-русский словарь терминов.
Материал, представленный в каждо й главе, подкрепляется вопросами и упражнениями.
Кроме того, навыки анализа и обработки РС закрепляются практически в ходе цикла лабораторных работ, выполняемых параллельно с прослушиванием курса лекций.
Пособие адресовано в первую очередь студентам магистратуры, обучающимся по направлению «Информационные системы и технологии» по профилю подготовки «Речевые информационные системы».
Материалы пособия будут также полезны специалистам, работающим в области информационных технологий и студентам соответствующих специальностей при изучении курсов, по- священных методам обработки данных.
Подробное изложение многих из затронутых в пособии вопросов дано в переведенных на русский язык книгах Л. Рабинера [47, 48].
В список литературы на русском языке, представленный в конце пособия, включены как научные, так и научно-популярные книги.
Надеемся, что знакомство с ними будет способствовать расширению кругозора в области ре чи и звука.
Структура пособия.
Глава 1 посвящена краткому обзору речевых технологий, месту ЦОРС в системе речевых технологий и обзору информационных источников.
В главе 2 приведены сведения по цифровым речевым сигналам.
В главе 3 излагаются необходимые основы теории линейных систем.
Главы 4 и 5 посвящены вопросам оценки базовых характеристик речевых сигналов.
В главе 6 рассматриваются простейшие и наиболее распространенные алгоритмы фильтрации речевых сигналов.
В заключение я приношу благодарность моим коллегам и друзьям, которые оказали мне неоценимую помощь при написании книги.5 1 ВВЕДЕНИЕ В ПРЕДМЕТ 1.1 Краткая история речевых технологий Речевые технологии (РТ) – это технологии, связанные с анализом и обработкой речевой информации.
История развития речевых технологий тесно связана с эволюцией методов обработки речевых сигналов (РС).
На первом этапе развития РТ основной задачей являлось создание механических устройств воспроизведения звуков человеческой речи.
13 век.
Немецкий философ Альбертус Магнус и английский учёный Роджер Бэкон пытались создать говорящие головы.
1769 г. Немецкий врач, механик и физик Христиан Кратценштейн конструирует резонансные полости, способные формировать некоторые звуки речи (гласные).
1791 г. Во́льфганг фон Ке ́мпелен конструирует механический синтезатор речи (говорящая машина, способная формировать гласные и согласные).
1831 г. Чарльз Уитстон на основе идей Ке́мпелена конструирует более совершенную говорящую машину.
На втором этапе (переход от механических к электрическим устройствам) развития РТ двигателем прогресса явилась разработка устройств передачи, запи-си и воспроизведения звука).
Здесь можно выделить следующие достижения: – телефон, Александр Белл, 1876 г.; – фонограф с записью на восковых валиках, Томас Эдисон, 1877 г.; – граммофон с записью на пластинках, Эмиль Берлингер, 1877 г.; – радио, Александр Попов, 1895 г.; – диктофон с записью на восковые цилиндры, Александр Белл, 1907 г.; – патефон, Шарль Кро, 1907 г.; – терменвокс, Лев Термен, 1920 г.; – говорящая бумага, Борис Скворцов, 1930 г.; – варифон-электрооптический синтезатор звуков, Евгений Шолло, 1931 г.; – VOCODER – устройство электронного анализа-синтеза речи, Хомер Дадли, 1939 г.; – беспроводная аналоговая телефония, 70–80 е годы.
На третьем этапе (70-годы – начало эры цифровой обработки речевых сигналов) развитие РТ значительно ускорилось.
В начале 3-го этапа основными направлениями РТ стали следующие [ 48]:6 – цифровая передача РС (цифровая телефония) ; – синтез речи ; – верификация и идентификация дикторов ; – распознавание речи ; – улучшение качества РС (компенсация искажений) ; – устранение дефектов речи.
В последующий период в связи с появлением компьютеров и микропроцессоров, обеспечивающих хранение больших объемов информации, быструю и гибкую обработку данных, РТ претерпели революционные изменения.
В на- стоящее время сфера РТ быстро расширяется.
В нее включаются когнитивные технологии, связанные с анализом и интерпретацией звуковых и акустических образов (анализ акустических сцен, обнаружение акустических событий, распознавание эмоций, интерпретация речевых сообщений и многие другие).
Современное состояние РТ можно охарактеризовать как четвертый этап развития РТ. К настоящему времени РТ нашли применение в повседневной жизни и стали неотъемлемой частью информационных технологий, включающих в себя распознавание образов, нейросети, технологии искусственного интеллекта, машинное обучение.
Основные применения РТ на современном этапе: – сжатие и кодирование речевых сигналов; – верификация и идентификация дикторов, голосовая биометрия; – речевая, текстовая и акустическая аналитика ; – автоматическое распознавание речи ; – синтез речи и клонирование голоса ; – контроль доступа ; – голосовая помощь и голосовое самообслуживание ; – коррекция нарушений слуха и речи; – распознавания языка ; – распознавание эмоций и физического состояния; – компенсация искажений РС ; – анализ акустических сцен, обнаружение и распознавание акустических событий; – восстановление звукозаписей ; – понимание текстов и естественной речи ; – диалоговое и мультимодальное взаимодействие человека и машин ; – обучение иностранным языкам.7 1.2 Предметная область цифровой обработки речевых сигналов Речь реализуется в знаковой форме (письменность, тексты) и звуковой форме (сигналы).
Поэтому РТ включают в себя как обработку звуков, так и о б- работку знаковой информации.
Данное пособие посвяще но вопросам обработки речевых сигналов.
Приведем определения базовых понятий сигнала и информации.
Информация – свойство материи, отличное от ее вещественных и энергетических свойств, являющееся содержательной характеристикой отражения.
Являясь свойством материи, информация может рассматриваться как величина.
Сигнал (от лат. Signum – знак) – материальный носитель информации.
Информация передаётся сигналом за счёт изменения характеристик или пар а- метров сигнала во времени.
Поэтому под обработкой сигналов мы будем подразумевать как непосредственно обработку сигналов, так и обработку изменяющихся во времени параметров.
Многие из РТ имеют математический, абстрактный характер и связаны с анализом и обработкой информации.
Однако первичным источником аудиоинформации являются акустические сигналы, а первичным этапом преобразования данных является анализ и обработка акустических сигналов.
Основное назначение цифровой обработки речевых сигналов (ЦОРС) – преобразование первичной аудиоинформации в форму, пригодную для дру гих областей РТ. Анализ и обработка РС обычно выполняются в цифровой форме, поэтому ЦОРС может рассматриваться как специальный раздел цифровой обработки сигналов (ЦОС).
Целью обработки акустических сигналов является оценка их параметров для дальнейшего использования в решении прикладных задач.
Цифровая обр а- ботка РС включает следующие задачи: фильтрация сигналов, компенсация ш у- мов и искажений сигналов, сегментация сигналов на информативные участки, оценка параметров.
Решение этих задач составляет основной предмет ЦОРС.
Перечисленные методы преобразования и анализа акустических сигналов принято относить к первичной обработке (предобработке) сигналов (Front-End Processing).
В целом ЦОРС можно охарактеризовать с нескольких позиций: – первичная обработка и анализ РС; – элемент РТ; – специальный раздел цифровой обработки сигналов.
В ЦОРС входит ряд задач, связанных с цепочкой преобразований акуст и- ческих сигналов.
Краткая запись основных этапов преобразования акустически сигналов дана на рисунке 1.1.
Схема преобразований приведена на рисунке 1.2.8 Источник акустического сигнала ↓ Распространение сигнала ↓ Измерение (преобразование в электрический сигнал, усиление) ↓ Представление сигнала в цифровой форме ↓ Преобразование (фильтрация) сигнала ↓ Выделение признаков ↓ Использование информации Рисунок 1.1 – Цепочка преобразований акустических сигналов Рисунок 1.2 – Схема преобразований акустических сигналов С каждым из элементов цепочки преобразований связан круг задач, относящихся к предметной области ЦОРС.
Перечислим основные задачи.
Источники акустического сигнал а Акустический сигнал несет в себе информацию об источнике его форми- рования.
В связи с этим ставятся задачи извлечения этой информации.
Так, в 9 речевых сигналах содержится следующая информация: – акустические фонетические символы, формирующие слова; – просодика (ритм, интонация) ; – гендерная принадлежность ; – возраст; – акцент; – индивидуальные признаки диктора ; – эмоции; – физиологическое и психологическое состояние диктора.
Аналогично формулируются задачи выделения информации о других источниках акустических сигналов (например, в задачах технической диагностики).
Распространение сигнала Задачи анализа акустической среды, условий формирования и распространения сигнал а (например, определение акустического «отпечатка» или «портрета» помещения).
Измерение (преобразование в электрический сигнал, усиление) Задачи оценки условий записи звука: время записи, характеристики аппаратуры записи, идентификация целостности записи.
Представление в цифровой форме Задание частоты дискретизации и диапазона квантования аналоговых сигналов, соответствующих практическим задачам извлечения и хранения ин- формации.
Преобразование цифрового сигнала Задачи фильтрации сигнала, компенсации искажений, восстановления разборчивости и др. Выделение признаков и использование информации Сюда относятся задачи прикладных методов обработки: распознавания речи, идентификации диктора и др. Эти задачи относят к прикладной (вторичной) обработке РС (Back-end pro cessing).
Обратим внимание еще на две особенности ЦОРС.
Первая – это связь ЦОРС с алгоритмами и средствами обработки цифровых сигналов, вторая – это связь понятий и методов ЦОРС с другими отраслями науки.
Развитие технологий ЦОРС неразрывно связано с развитием методов, алгоритмов и элементной базы цифровой обработки сигналов.
Многие методы ЦОРС получили развитие и практическое воплощение благодаря появлению новых средств обработки сигналов.
Развитие методов и средств обработки сигн а- лов проиллюстрировано в таблице 1.1.
Таблица 1.1 – Этапы развития методов и средств обработки сигналов Годы Методы обработки Средства обработки до 50- х Аналоговые средства фильтрации Механические и электронные аналоговые устройства 50-е Фильтр Винера (1949) Адаптивный фильтр Уидроу (1959) 1-я ЭВМ (UNIAC) на лампах (1951) 1-ый компьютер IBM (1952) 60-70-е Фильтр Калмана (1961) БПФ (1965) Спектральный анализ, методы синтеза цифровых фильтров Цифровые схемы на дискретных элементах, первые однокристальные процессоры 80-е Методы нелинейного СА, методы спектрального вычитания Алгоритмы адаптивной фильтрации Технология интегральных схем, процессоры ЦОС (ЦПОС) с фиксир о- ванной точкой 90-е RASTA и другие методы обработки РС Алгоритмы для микрофонных решеток ЦПОС с плавающей точкой Программируемые логические интегральные схемы с 2000 по настоящее время Широкое практическое использование РТ, цифровой звук, цифровая телефония, синтез и распознавание речи и пр. Универсальные процессоры ЦОС Библиотеки программ ЦОС Международные стандарты ЦОС Современный этап Методы машинного обучения, нейронных сетей, искусственного интеллекта Графические процессоры Теория анализа и цифровой обработки речевых сигналов опирается на методы и алгоритмы ряда разделов математики, физики и других смежных обла с- тей (рисунок 1.3).
Рисунок 1.3 – Пограничные области ЦОРС.
.. Статистический анализ данных Речь, слух, психоакустика Численные методы Анализ временных рядов Цифровая обработка сигналов Цифровая обработка речевых сигналов
11 Трудно быть специалистом в РТ, не обладая определенными знаниями в соседних областях.
Некоторые книги из этих областей включены в общий список литературы.
«Чистые программисты», не имеющие достаточного кругозора, создают плохие программы.
Важные мысли на эту тему можно найти в главе «Искусство вычислять для инженеров и ученых» книги Хэмминга [68].
1.3 Профессиональные сообщества и информационные ресурсы ЦОРС Профессиональные сообщества объединяют ученых и инженеров компаний и университетов, работающих в различных отраслях РТ, и занимаются организацией обмена информацией: конференций, форумов, семинаров, конку р- сов, изданием книг и журналов и формированием других информационных ресурсов.
Список профессиональных сообществ приведен в приложении А. Членство в таких сообществах помогает связям с коллегами, участию в мероприятиях и облегчает доступ к информационным ресурсам.
Перечислим некоторые из информационных ресурсов : – книги (монографии, учебники, пособия, руководства, справочники), с о- держащие систематическое изложение отдельных тем; – стандарты, описывающие общепринятые понятия, процедуры, алгоритмы (приложение Б); – журналы, статьи (аналитические обзоры по конкретной теме, прикладные – опыт применения методов и алгоритмов, научные – новые теоретические и практические результаты) (приложение В); – труды конференций, семинаров, конкурсов, содержащие текущие научные достижения в определенных областях (приложение Г); – патенты, предназначенные для охраны авторских прав в области практической реализации методов и алгоритмов; – базы и хранилища данных, содержащие общий материал для сравнения различных подход ов для решения однотипных задач; – форумы, где обсуждаются практиче ские вопросы обработки сигналов; – фреймворки и библиотеки программ, облегчающие разработку программных продуктов ; – конкурсы, имеющие целью сравнение передовых достижений по реше-нию определенных задач.
Актуальная информация по РТ также распространяется через онлайн- курсы и практико-ориентированные тренинговые курсы компаний.
В систематизированном виде информация представлена в книгах.
Список
12 научной и популярной литературы по анализу и обработке речевых и звуковых сигналов на русском языке приведен в конце пособия.
Подавляющая часть изданий по речевой тематике опубликована на английском языке.
В настоящее время по тема тике РТ в мире ежегодно издает ся несколько монографий.
Однако, наиболее полным и фундаментальным руководством по ЦОРС на данный м о- мент остается книга Benesty J., Sondhi M., Huang Y.
(Eds).
Springer Handbook of Speech Processing, Springer Verlag, 2008.
Подавляющая часть периодической литературы по речевой тематике так- же издается на английском языке.
В приложении B приведен список основных журналов.
В Российской Федерации материалы по ЦОРС регулярно публикуются в журнал ах «Речевые технологии» и «Цифровая обра ботка сигналов», а также «Труды СПИИРАН».
Список журналов приведен в приложении B.1.4 Работа с пособием Целью пособия является ознакомление с основами цифровой обработки речевых сигналов и освоение базовых практических навыков их анализа и обработки.
Материал пособия может служить основой для последующего самостоятельного освоения различных областей речевых и информационных технологий.
Пособие содержит элементарные понятия первичного анализа и первичной о б- работки РС.
Особенности пособия: – предполагается предварительное знание основ цифровой обработки сигналов ; – широкий охват тем (каждая глава посвящена отдельной теме) ; – справочный и обзорный характер материалов.
Большинство формул приводятся без доказательств ; – каждый из разделов сопровождается задачами, необходимыми для практического усвоения теоретического материала.
Целью дальнейшего изучения методов анализа и обработки речевых сигна- лов обусловлен обширный список литературы на русском языке.
Мы не рекомендуем по отдельной теме какую-то определенную книг у, полагая, что читатель воспользуется той, которая ему доступна и интересна.
Для начала можно рекомендовать книги на русском языке: Бендатта и Пирсона [6, 7], Марпла [32], Отн е- са и Эноксона [39], Рабинера и Гоулда [47], Рабинера и Шафера [48].
Для первого знакомств с англоязычной литературой может быть рекомендовано фундаментальное руководство по цифровой обработке речевых сигналов [73], написанное ведущими специалистами в области обработки речевых сигна-13 лов и охватывающее большое число вопросов, связанных с их обработкой.
Для облегчения чтения англоязычных текстов в приложении Г дан список англо я- зычных терминов.
Эти термины могут быть также полезны при формировании поисковых запросов по различным задачам ЦОРС.
Для написания текстов по речевой тематике на русском языке рекомендуем использова ть приведенные в пособии перечень сокращений и список обозначений.
Для ознакомления с программами цифровой обработки и анализа РС могут быть рекомендованы пакеты VOICEBOX, PRAAT, HTK, а также книги [2, 31, 32, 39, 54].
Параллельно с изучением теоретического материала целесообразно выполнить курс лабораторных работ, имеющих цель практического освоения р а- боты с аудиосигналами.
Указания по лабораторным работам содержатся в методическом указании [ 59].
Материалы к лабораторным работам также содержат необходимые аудиофайлы.
Лабораторные работы могут быть выполнены с использованием доступной версии программы SIS производства компании « Центр речевых технологий » [75] или частично с использованием свободно распространяемого редактора PRAAT [ 35, 74].
Необходимым элементом курса является самостоятельное решение упражнений (включающих вопросы и задачи), сопровождающих кажд ую из глав.
Только так изложенная информация может превратиться в знания!
Поскольку в этом пособии неоднократно встречаются формулы с комплексными переменными, мы рекомендуем выполнить задания, приведенные ниже.
14 Вопросы и упражнения 1.
X, Y – комплексные числа, * – символ комплексного сопряжения.
Правильно ли, что : X Y = Y X X*Y = YX* X*Y = Y* X X*Y = (Y*X)* |X Y*| = | X| |Y| 1/X = X*/|X|² (XY)* = X * Y* Если X = X*, то X – вещественное X*X = X² |X*| = |X| |X Y| = |X| |Y*| 2. a, b, g, h, θ – реальные числа.
Чему равно : (a + jb) + (g + jh) (a + jb) × (g + jh) (a + jb)² (a + jb) / (g + jh) | a + jb | exp(jθ) ln(a + jb) 3.
Докажите, что: |(a + jb)/(g + jh)| = |(a + jb)|/ |(g + jh)*| |(a + jb)* × (g + jh)| = |(a + jb) × (g + jh)*| (a + jb)* × (g + jh) = ((a + jb) × (g + jh)*)* 1 + exp(jθ) = 2 exp(jθ /2) cos(θ) 1- exp(jθ) = 2 exp(jθ /2) sin(-θ) 15 2 ЗВУК И ЕГО ЦИФРОВОЕ ПРЕДСТАВЛЕНИЕ 2.1 Звук Звук – это колебательный процесс, возникающий в воздухе (или другой упругой среде) под действием каких-либо колеблющихся предметов.
Источниками звука могут быть, например, голосовые связки человека, струны музыкальных инструментов или любой другой вибрирующий предмет, заставляющий колебаться окружающие его частицы воздуха.
Плотность воздушной среды при этом то увеличивается, то уменьшается в соответствии с колебаниями источника звука.
В простейшем случае это «чистый » тон (звук камертона), при к о- тором источник излучает только одну частоту, и изменение мгновенных знач е- ний колебания строго подчиняются за кону синуса.
Основные свойства звука перечислены ниже.
Звук – это колебательный процесс, возникающий в воздухе (или другой упругой среде) под действием каких-либо колеблющихся предметов.
Звук распространяется в пространстве в виде волн (сжатия и разряжения).
Распространение звука описывается волновым уравнением.
Звук описывается тремя основными параметрами: временем, амплитудой (звуковым давлением, интенсивностью), частотой волн.
Амплитуда сжатия и разряжения характеризуется звуковым давлением.
Интенсивность звука пропорциональна квадрату амплитуды.
Амплитуды разных волн (сжатия и разряжения) складываются, например, A + (-A) = 0.
Волны распространяются в пространстве с определенной скоростью, в разных средах скорость звука разная.
Каждой частоте соответствует длительность по времени (период) и пространству (длина волны): λ o = C × T o = C / F o. Синусоидальная звуковая волна за один период колебания To проходит путь, равный длине волны λo = C × T o. Длина волны – расстояние между «гребня- ми» (фронтами) звуковой волны, различающимися по фазе на один период.
Для одной и той же частоты длина волны в разных средах разная.
Амплитуда (интенсивность) звука в свободном пространстве уменьшается на 6 дБ при удвоении дистанции от источника (закон обратного квадрата).
Акустические приемники преобразуют амплитуду давления в амплитуду электрического сигнала.16 Интенсивность (сила звука) – это величина, равная энергии звуковой волны, переносимой через ед иницу площади в единицу времени: J = E/ (t S) = P/S [Дж/м ²с = Вт/м ²], где P – мощность звуковой волны.
2.2 Аналого- цифровое преобразование звуковых сигналов Сигнал – зависимость одной величины от другой (функция).
Например, зависимость давления воздуха в точке от времени можно рассматривать как звуковой сигнал.
Зависимость напряжения в проводнике от времени тоже может представлять звуковой сигнал [ 29].
Акустическая энергия звука преобразуется в электрический сигнал с п о- мощью микрофонов.
Электрический сигнал преобразуется в цифровой с помощью аналого-цифрового преобразователя (АЦП).
Обратное преобразование осуществляется с помощью цифро-аналогового преобразователя (ЦАП).
Аналого-цифровое преобразование – это дискретизация сигнала по времени и амплитуде.
Дискретизация по амплитуде называется квантованием сигнала.
Квантование ограничивает динамический диапазон цифрового сигнала, дискретизация по времени ограничивает частотный диапазон сигнала.
На рисунке 2.1 представлена схема аналого-цифрового преобразования сигнала.
Рисунок 2.1 – Схема аналого-цифрового преобразования сигнала 2.3 Дискретизация во времени Дискретизация непрерывного аналогового сигнала выполняется через равные промежутки Т: x[ i] = x(iT).
Выборочная функция представляет собой последовательность дискретных величин, соответствующих моментам времени (iT).
Частота дискретизации (sampling rate) измеряется в герцах (Гц).
Герцы – это количество отсчетов в секунду: Fs = 1/T.
Временной шаг дискретизации и частота дискретизации од нозначно связаны: T=1/Fs.
Пример : Fs = 8000 Гц ↔ T = 1/8000 = 125 мкс.
17 Перед дискретизацией частота сигнала ограничивается фильтром низких частот (ФНЧ) с граничной частотой Найквиста Fn = Fs/2.
информация об исходном непрерывном с сигнале частично будет утрачена (не может быть восстановлена с помощью обратного цифро-аналогового преобразования, а будет восстановлена лишь в диапазоне частот, ограниченном частотой Найквиста).
2.4 Понятие частоты Частота в герцах (Гц) – это число повторяющихся событий периодическо-го процесса в секунду.
Например: Частота вращения f – это число циклов в секунду.
Частота дискретизации сигнала Fs – это число отсчетов в секунду.
Помимо герц, используются и другие единицы измерения частоты.
Нормализованная частота (циклов на отсчет) связана с частотой f соотношением : F = f×T= f / Fs [-½, +½ ].
Радиальная (угловая) частота – это мера угловой скорости вращения, выражаемая числом радиан в секунду (рад/с).
Радиан (безразмерная величина) – это угол, при котором окружность «провернулась» на длину своего радиуса.
У г- ловая частота связана с частотой f соотношением : ω = 2 π f. Нормализ ованная радиальная частота (рад/отсчет) связана с частотой f соотношением: Ω = 2 π f /Fs = ω /Fs = ωT [-π…+π], ω = Ω Fs.
В таблице 2.1 приведены соотношения между различными частотами.
Таблица 2.1 – Соот ношение между разными частотами Переменная Единицы измерения Соотношение Интервал Радиальная частота, ω рад/с ω = 2π f-∞ < ω < ∞-2πFn < ω < 2πFn Частота вращения, f циклов в секунду, Гц f = F/T-∞ < f < ∞-Fn < f < Fn Нормализованная радиальная частота, Ω рад/отсчет Ω = 2 π F= 2 π f/Fs-π ≤ Ω ≤ π Нормализованная частота, F циклов на отсчет F = f / Fs = f×T-½ ≤ F ≤ ½18 Выбор частоты дискретизации речевых сигналов и аудиосигналов опр е- деляется, как правило, задачами дальнейшего применения цифровой информа- ции.
Наиболее распространенные частоты дискретизации – кратные 8 кГц (16, 24, 48, 96 кГц) и кратные 11025 Гц (22,050 и 44,1 кГц).
Наиболее часто в рече- вых приложениях используется частота 16 кГц.
2.5 Эффект наложения спектров Если частота сигнала больше частоты Найквиста (Fn = Fs/2), то информация о сигнале частично будет потеряна (не может быть восстановлена обратным цифро-аналоговым преобразованием).
Вместо сигнала с частотой Fo > Fn будет восстановлен сигнал с частотой Fi = Fs – Fo <Fn.
Этот эффект называется наложением спектров (aliasing).
Фильтр низких частот при дискретизации сигналов необходим, чтобы избежать эффекта наложения спектров.
Рисунок 2.2 – Эффект отражения частот На рисунке 2.2 приведена иллюстрация эффекта наложения спектров.
Периодический импульсный сигнал формирует гармоники спектра.
Выполняется его дискретизация с частотой Fs – 16 кГц.
Однако ФНЧ, ограничивающий частоту сигнала частотой Найквиста Fn = 8 кГц, не подавляет сигнал в необходимой степени, и часть сигнал а с частотой больше 8 кГц преобразуется в цифр о- вой сигнал.
При увеличении частоты следования импульсов частота гармоник выходит за границы частоты Найквиста, возникает эффект наложения спектров, который проявляется на спектрограмме в виде отраженных частот.
2.6 Квантование сигналов Квантование сигналов – это дискретизация амплитуды и представление ее в двоичном коде (битах).
При этом считается, что квантованный сигнал имеет целочисленные амплитуды, соответствующие двоичным числам.
Обыкновенно используют 8-, 16-, 24- и 32-разрядное квантование (1 байт, 2, 3, 4 байта).
В з а- Гц Время19 висимости от разрядности квантования (числа бит) диапазон кодируемых амплитуд будет быть разным.
Так, амплитуда в интервале [-2..+1] кодируется дву- мя битами : (00 = 0, 10 = +1, 11 =-1, 01-2) = [-2..+1].
В таблице 2.2 приведены интервалы квантования для разного числа разрядов квантования.
Таблица 2.2 – Интервалы квантования для разного числа разрядов квантования Длина слова, бит Диапазон чисел 2-2..+1 8-128… +127 16-32768…+ 32767 24-8388608…+8388607 M-2M-1…2M-1- 1 В некоторых (не во всех) случаях удобно считать, что старшие 16 разрядов кодируют целые амплитуды, а младшие – дробные части амплитуд.
Тогда при переходе с 16-разрядного квантования к 24-разрядному диапазоны амплитуд сигналов будут совпадать.
Децибелы – это число, выражающее в логарифмической мере отношение R двух величин (измеряемой и эталонной), употребляется при большом отнош е- нии этих величин.
Децибелы для мощностей : 10 lg(P/Pо).
Децибелы для амплитуд: 20 lg(A/Aо) = 10 lg(A/Aо) ² = 10 lg (P/Pо).
Рассмотрим, скольким дБ равно отношение 2.
Отношению 103 соответствует, согласно определению, значение 60 дБ.
Представим 103 как степень двой-ки 210.
Тогда 60 дБ ≈ 20 lg(210) = 10 x 20 lg(2).
Отсюда следует, что отношение 2 соответствует 20 lg(2) = 6 дБ.
Тогда, представляя другие отношения в виде степени двойки, можно на й- ти соответствующие им значения дБ.
Примеры.
3 дБ = 20 lg(21/2) → R=1,41 12 дБ → R= 4 18 дБ → R= 8 2 дБ = 20 дБ – 18 дБ → R= 10/8 = 1,25 8 дБ = 20 дБ – 12 дБ → R= 10/4 = 2,5 В таблице 2.3 приведены наиболее часто используемые значения дБ для различных отношений амплитуд и соответствующих им мощностей.20 Таблица 2.3 – Часто используемые отношения величин в дБ Отношение амплитуд 1000 100 10 4 2 1 0,7 0,5 0,3 0,1 0,01 0,001 Отношение мощностей 106 104 100 16 4 0 0,5 0,25 0,1 0,01 10-4 10-6 Значение дБ 60 40 20 12 6 0-3-6-10-20-40-60 Различным разрядностям квантования соответствует различный диапазон изменения амплитуд, который можно выразить в децибелах.
В качестве эталон- ной величины можно принять наименьшее кодируемое число (большее 0), н а- пример единицу.
Динамический диапазон цифровых сигналов можно опред е- лить как отношение максимальной амплитуды к минимальной: D = 20 log 10 (Amax/Amin) = = 20 log 10 (Amax/1) 20 log 10 (2M) ≈ 6 × M дБ.
Динамический диапазон связан с отношением сигнал-шум (ОСШ) зап и- санного цифрового сигнала.
Переход от непрерывных амплитуд к дискретным можно трактовать как аддитивный цифровой шум.
Таким образом, оцифрованные сигналы могут быть охарактеризованы некоторой величиной ОСШ.
Детали приведены, например, в книге [ 47].
В таблице 2.4 приведены основные сокращения, связанные с дискретизацией и квантованием сигналов.
Таблица 2.4 – Общепринятые сокращения для цифровых сигналов [17 ] Наименование Обозначение Обозначение английское Секунда с s Миллисекунда мс ms Микросекунда мкс μs Герц Гц Hz Килогерц кГц kHz Децибел дБ dB 2.7 Цифровой звук и его запись В литературе обычно проводится строгое разграничение между цифровыми и дискретными сигналами [ 32].
Дискретные сигналы – это сигналы, представляемые в виде счетных последовательностей, амплитуды которых являются непрерывными функциями.
Цифровые сигналы – это сигналы, у которых время и амплитуда дискретны.
Цифровой звук (Digital Sound) – результат дискретизации по времени и квантования по амплитуде сигналов микрофонов, то есть это сигналы, у которых время и амплитуда дискретны.
При записи и передаче цифрового звука важной характеристикой является 21 цифровой поток, зависящий от частоты дискретизации сигнала и разрядности квантования.
Цифровой поток определяется как число бит или байт, передаваемых в секунду: Цифровой поток (Bit rate) = M × Fs [bps], где bps = bit/s.
Цифровой поток позволяет оценить объем памяти (информации), необходимый для записи аудиоматериала, например при оцифровке аудиоархивов.
Объем информации вычисляется по формуле : V = Bit rate × T. Объем памяти принято характеризовать в байтах (Б).
Пример 1 Цифровой поток для стандарта MP3 составляет от 32 до 320 Кбит/c, что соответствует 4 –40 КБ/с (KBps).
Пример 2 Оценим приблизительно (считая, что 1 КБ равен 1000 байт, а не 1024) объем памяти, необходимый для непрерывной записи аудиосигнала в течение суток.
При записи в формате 16 бит ×16 кГц получим : 16 бит ×16 кГц =2 байт ×16 кГц ≈ 32 КБ/с.
32×60 =1920 КБ/мин = 1,92 МБ/мин.
1,92 ×60 = 114 МБ/час = 0,114 ГБ/час.
0,114×24 = 2,726 ГБ/сутки.
Ограничение объема пространства в файловой системе FAT16 составляет 2 ГБ.
Поэтому накопителя с FAT16 недостаточно.
Однако при записи на частоте 8 кГц карты памяти 2 ГБ хватит больше, чем на сутки.
2.8 Осциллограмма Основной формой графического представления цифровых сигналов в звуковых редакторах является осциллограмма.
Осциллограмма – это графическое представление цифрового сигнала в координатах «Амплитуда » – «Время».
В разных звуковых редакторах используются различные осциллограммы.
На рисунке 2.3 показаны осциллограммы цифровых сигналов в разных редакторах аудиосигналов.
Примечание Отметим, что соединить дискретные отсчеты сигнала на графике прямыми линиями не совсем верно, т ак как при восстановлении непрерывного сигнала
22 по дискретному используются более сложные интерполирующие функции.
К у- сочно-постоянная интерполяция представляется более предпочтительной.
Рисунок 2.3 – Осциллограммы цифровых сигналов в разных редакторах аудиосигналов Влияние частоты дискретизации на представление синусоидального си г- нала в осциллограмме проиллюстрировано на рисунке 2.4.
Примечание Отметим, что цифровые записи аудиосигнала, записанные на компьютере и цифровом диктофоне с одной той же частотой дискретизации, могут отличаться по длине и объему вследствие различия частот генераторов компьютера и диктофона (двух разных устройств).
В заголовке файла будет указана одинаковая частота, например 16 кГц, однако реально она незначительно отличается.
Поэтому фонограммы также будут отличаться.
а) Кусочно-постоянная интерполяция (редактор SIS I) в) Кусочно-постоянная интерполяция (редактор SIS II) б) Интерполяция ∑sin(x)/x (редактор Adobe Audition) Время Время Время23 Рисунок 2.4 – Осциллограммы синусоидального сигнала для Fs = 8 кГц, 10 кГц, 16 кГц Эффекты квантования заметны на осциллограмме сигнала небольшой а м- плитуды пр и небольшом масштабе времени (рисунок 2.5).
Рисунок 2.5 – Осциллограмма шума малого уровня Более детально вопросы сбора и оцифровки данных рассмотрены в книге [ 39].
Fs = 8 кГц Fs = 10 кГц Fs = 16 кГц Амплитуда Время Время Время Время 
24 Вопросы и упражнения 
1. В каких единицах измеряется фаза сигнала?
2. Скольким рад/с соответствует частота 500 Гц?
3. Сколько отсчетов сигнала приходится на длину волны 200 Гц при частоте дискретизации 16 кГц?
4. Какому расстоянию, пройденному звуком в помещении, соответствует кадр сигнала N отсчетов с частотой дискретизации 16 кГц?
5. Чему равен временной сдвиг между входным и выходным отсчетами линии задержки в N отсчетов сигнала с частотой дискретизации Fs?
6. Какой величине соответствует нормализованная частота Найквиста?
7. В каких пределах 8-разрядное двоичное число кодирует целые числа?
8. Какое отношение амплитуд соответствует 8 децибелам?
9. Скольким децибелам соответствует отношение амплитуд, равное 7?
10. Изменится ли динамический диапазон цифровых сигналов при пер е- ходе от 16-разрядного квантования к 24-разрядному?
11. Чему равен динамический диапазон 16-разрядного сигнала?
12. Скольким байтам равен один килобайт?
13. Оцените объем записанной за сутки аудиоинформации для формата записи 16 бит ×10 кГц.
14. Между двумя сигналами одной частоты f имеется фазовый сдвиг ∆Ф(f).
Каков пространственный сдвиг между этими сигналами в возду ш- ной среде (c = 334 м/с)?
15. Расстояние от источника звука до ближайшего слушателя равно Dn, до дальнего слушателя – Df.
На сколько дБ необходимо усилить сигнал дал ь- него слушателя, чтобы его громкость была такой же, как у ближнего?25 
3 СТАТИСТИЧЕСКИЕ ХАРАКТЕРИСТИКИ РЕЧЕВЫХ СИГНАЛОВ Целью оценивания параметров сигналов является установление соответствия между сигналами и их признаками (параметрами).
Другой целью является представление сигнала компактным набором параметров вместо самого оцифрованного сигнала.
Данная глава посвящена методам оценивания базовых пар а- метров сигналов, в том числе речевых сигналов.
3.1 Случайная величина и ее характеристики Статистическая изменчивость наблюдений означает то, что результаты повторных измерений случайной величины различны.
Измеренные значения можно объединить в группы, которые образуют выборочное пространство наблюдений А. Элементы (точки) этого пространства можно группировать в по д- пространства А 1, … А к, называемые событиями.
Эксперимент всегда приводит к одному из событий.
Таким образом, выборочное пространство событий может быть представлено конечным множеством групп: А = {А1 + А 2 + …А к}.
Количественной характеристикой некоторого события Ai может служить частота его появления m(Ai).
Частота появления события в случае n наблюдений определяется соотношением: P(Ai) = m (Ai)/n.
Вероятность появления события определяется как предельное значение частоты при увеличении числа наблюдений: P(Ai) = lim P(Ai), n → ∞.
Пусть измеряется некая числовая величина, то есть событием является значение измеренной случайной величины.
Функция распре деления вероятностей F(ξ) случайной величины x определяется следующим соотношением: F(ξ) = P (x ≤ ξ) ≤ 1.
Плотность вероятности случайной величины x – это вероятность распределения ее значений функции распределения по узким интервалам: 𝑓𝑓(𝜉𝜉)=𝑑𝑑𝑑𝑑(𝜉𝜉) 𝑑𝑑𝜉𝜉.
С помощью плотности вероятности можно вычислить вероятность попадания значения случайной величины в заданный интервал значений: 𝑃𝑃(𝑥𝑥≤𝑎𝑎)=∫ 𝑓𝑓(𝜉𝜉)𝑑𝑑𝜉𝜉𝑎𝑎 −∞=𝑑𝑑(𝑎𝑎)−𝑑𝑑(−∞)=𝑑𝑑(𝑎𝑎), 𝑃𝑃(𝑎𝑎<𝑥𝑥≤𝑏𝑏)=∫𝑓𝑓(𝜉𝜉)𝑑𝑑𝜉𝜉𝑏𝑏 𝑎𝑎=𝑑𝑑(𝑏𝑏)−𝑑𝑑(𝑎𝑎).26 Рисунок 3.1 – Плотность вероятности и функция распределения случайной величины x [ 8] Математическое ожидание однозначной непрерывной функции g(x) определяется следующим выражением: 𝐸𝐸{𝑔𝑔(𝑥𝑥)}=∫ 𝑔𝑔(𝑥𝑥)𝑓𝑓(𝑥𝑥)𝑑𝑑𝑥𝑥∞ −∞.
Если мы знаем вероятность распределения величины по интервалам, то можно найти параметры распределения (характеристики случайных величин): центр тяжести, степень размытости и другие характеристики.
Основные характеристики случайной величины приведены ниже.
Математическое ожидание случайной величины x: μx = E{x}.
Дисперсия Dx (Variance) и среднее квадратическое (среднеквадратическое) отклонение σx (СКО, Stanard deviation, Std): Dx = σx² = E {(x- μx)²}.
Стандартное отклонение (Std): σx = Dx½.
Среднеквадратическое значение (Mean Square): Ψx = E{x²} = μx² + σ x².
Корень среднеквадратического значения (Root Mean Square, RMS): [E{x²}]1/2.
Характеристики случайной случайных величин представляют собой неслучайные величины.
Функция плотности вероятности Функция распределения вероятностей 27 
3.2 Случайный процесс и его характеристики Процесс – это последовательность событий.
Случайный процесс – это функция x(t), мгновенные значения которой есть случайные величины.
Процесс является стационарным, если функция распределения любых n его значений F(x[i+1], …x [i+n]) не зависит от начального момента времени i. Процесс является эргодическим, если усреднение по ансамблю можно заменить усреднением по времени.
Процесс является более общим понятием, чем сигнал, однако в дальне й- шем мы будем использовать эти понятия как тождественные.
Рассмотрим частный вариант, когда случайная величина – это отсчеты амплитуды самого процесса.
Тогда можно определить его характеристики.
При описании случайного процесса обычно ограничиваются характеристиками, ана- логичными числовым характеристикам случайных величин.
Основные характеристики случайно го процесса приведены ниже.
Среднее значение μx = lim P->∞1/2P ∫-P, P x(t) dt Дисперсия процесса Dx = lim P->∞1/2P ∫-P, P [x(t) – μx]² dt Стандартное (среднеквадратичное) отклонение σx = Dx½ Среднеквадратическое значение : Ψx = μx² + σ x² 3.3 Выборочные оценки параметров и их погрешности В п. 3.2 были рассмотрены основные параметры случайного процесса.
Рассмотрим практические вопросы оценки этих параметров.
Для этого примем следующие определения.
Дискретный случайный процесс – это множество значений процесса для дискретных моментов времени nT: x [1], x[2],…, x [n]… Реализация случайного процесса – это последовательность наблюдений x[1],… Выборочные данные – измеренная реализация процесса.
Выборочная оценка параметра: – оценка, сделанная по выборочным данным (случайная величина); – оценка, сделанная по реализации процесса, а не по ансамблю; – оценка, сделанная по конечной выборке.
Свойство эргодичности при выборочной оценке позволяет заменить опе- рацию математического ожидания операцией усреднения по реализации процесса: E{x} → 1 𝑁𝑁(∑ 𝑥𝑥[𝑖𝑖]𝑁𝑁 𝑖𝑖=1)=<𝑥𝑥[𝑖𝑖]>, где E{x} – математическое ожидание случайной величины x, <x[i]> – среднее по времени значение выборки случайной величины x, < > – символ усреднения по выборке.
Выборочная оценка параметра является случайной величиной, которую можно охарактеризовать математическим ожиданием и дисперсией, что означает ее отличие от неслучайной оценки, вычисленной по бесконечному ансамблю значений.
Замена операции математического ожидания на операцию усреднения по реализации приводит к отличию выборочной оценки параметра от «истинного» значения, которое могло бы быть получено при бесконечном числе наблюдений.
Это отличие описывается следующими характеристиками.
Смещением называют разность между истинным значением параметра и математического ожидания его оценки: Δẋ = E{ẋ}- x = E {ẋ}- E{x} = E {ẋ- x}, где E{ } – оператор математического ожидания, ẋ – оценка случайной величины x. Оценка ẋ параметра x смещена, если среднее значение ẋ не совпадает с x. Оценку называют несмещенной, если смещение Δẋ = 0, и асимптотически несмещенной, если при усреднении по ансамблю с увеличением числа реализаций смещение стремится к нулю.
Дисперсией оценки называется вели чина Dẋ = σẋ² = E {[ẋ – E{ẋ}]²}, где σẋ – среднеквадратическое отклонение оценки (СКО).
Среднеквадратической ошибкой оценки называется величина: Ψẋ² = E {[ ẋ- х]²}= σẋ² + Δẋ².
Рисунок 3.2 – Смещение и дисперсия оценки вектора [ x, y] На рисунке 3.2 показаны погрешности выборочной оценки вектора [ x, y].
29 Оценка состоятельна, если её дисперсия убывает с ростом объема выборки: (σẋ²) = 0, N →∞.
3.4 Выборочные оценки основных параметров случайного процесса Речь является нестационарным процессом, значения ее параметров непрерывно меняются.
Поэтому выборочные оценки параметров берутся на последовательных (обычно пересекающихся) интервалах (кадрах данных) в предположении, что на кадре процесс является стационарным и характеризуется фиксированным значением параметра.
Такие характеристики называют кратковременными (short- time).
Обычно интервал оценки параметров РС выбирается равным 25 –30 мс.
При частоте дискретизации сигнала 16 кГц это соответствует 400–480 отсчетам.
Формулы выборочных оценок характеристик случайного процесса приведены ниже.
Оценка среднего значения: μx=1 N∑ x[i]N i=1 =〈x[i]〉 Центрирование процесса: xo[i] = x[i] – μx, Оценка дисперсии: 𝐷𝐷𝑥𝑥(𝑁𝑁)=〈𝑥𝑥02[𝑖𝑖]〉=1 (𝑁𝑁−1)∑ [𝑥𝑥[𝑖𝑖]−𝜇𝜇𝑥𝑥]2 𝑁𝑁 𝑖𝑖=1 Смещенная оценка дисперсии: 𝐷𝐷𝑥𝑥(𝑁𝑁)=1 𝑁𝑁∑ [𝑥𝑥[𝑖𝑖]−𝜇𝜇𝑥𝑥]2 𝑁𝑁 𝑖𝑖=1 Быстрая оценка дисперсии: 𝐷𝐷𝑥𝑥(𝑁𝑁)=1 𝑁𝑁∑ 𝑥𝑥2[𝑖𝑖]𝑁𝑁𝑖𝑖=1−1 𝑁𝑁∑ 𝑥𝑥[𝑖𝑖]2 𝑁𝑁𝑖𝑖=1 Оценка СКО: 𝜎𝜎𝑥𝑥=�𝐷𝐷𝑥𝑥 Оценка энергии на интервале N: 𝐸𝐸𝑥𝑥{𝑥𝑥(𝑁𝑁)}=∑ 𝑥𝑥2[𝑖𝑖]𝑁𝑁 𝑖𝑖=1 Оценка мощности: 𝑃𝑃𝑥𝑥=〈𝑥𝑥2[𝑖𝑖]〉=1 𝑁𝑁∑ 𝑥𝑥2[𝑖𝑖]𝑁𝑁𝑖𝑖=1=𝐸𝐸{𝑥𝑥} 𝑁𝑁=𝜎𝜎𝑥𝑥2+𝜇𝜇𝑥𝑥2 Корень из среднеквадратического значения: 𝑅𝑅𝑅𝑅𝑅𝑅 =�𝑃𝑃𝑥𝑥 Средний модуль: 𝑅𝑅𝑅𝑅𝑑𝑑 =〈|𝑥𝑥[𝑖𝑖]|〉=1 𝑁𝑁∑ |𝑥𝑥[𝑖𝑖]|𝑁𝑁 𝑖𝑖=1 Обратим внимание на следующие свойства дисперсии.
Если сигнал является суммой или разностью сигналов независимых источников, тогда его дисперсия равна сумме дисперсий этих сигналов: 𝐷𝐷𝑥𝑥±𝑦𝑦 = <(𝑥𝑥[𝑖𝑖] ± 𝑦𝑦[𝑖𝑖])²> = <𝑥𝑥[𝑖𝑖]² ± 2𝑥𝑥[𝑖𝑖] 𝑦𝑦[𝑖𝑖] + 𝑦𝑦[𝑖𝑖])²> = =<𝑥𝑥[𝑖𝑖]² + 𝑦𝑦[𝑖𝑖])²> = 𝐷𝐷𝑥𝑥 + 𝐷𝐷𝑦𝑦, если x[i] = y[i], то Dx+y = 4Dx.30 3.5 Выборочная оценка функции распределения Гистограмма – оценка вероятностной функции распределения, вычис- ленная по одной реализации процесса.
Параметры оценки гистограммы – интервал измерения величины a<x[i]<b, число K интервалов группировки равной длины Δ = (b-a)/K, объем выборки N. Виды оценок гистограммы [39]: Гистограмма – последовательность числа попаданий в подинтервалы {Nj}, взятая без всяких изменений: ∑𝑁𝑁𝑗𝑗𝑗𝑗 =𝑁𝑁.
Выборочная вероятность попадания амплитуды в соответствующий интервал: 𝑃𝑃𝑗𝑗=𝑁𝑁𝑗𝑗 𝑁𝑁, ∑𝑃𝑃𝑗𝑗𝑗𝑗=1.
Выборочная вероятностная функция распределения: 𝑝𝑝𝑗𝑗=𝑁𝑁𝑗𝑗 𝑁𝑁;𝑏𝑏−𝑎𝑎 𝐾𝐾=𝑃𝑃𝑗𝑗 ∆, ∫𝑝𝑝(𝑥𝑥)𝑑𝑑𝑥𝑥≈∑𝑝𝑝𝑗𝑗∆=1.
Рисунок 3.3 – Гистограммы (оценки функции распределения) белого шума (σ = 500, μ = 0), вычисленные с интервалами 10 и 100 На рис унке 3.3 п оказаны графики выборочной функции распределения, вычисленные по одной реализации с разными интервалами группировки.
При изменении интервала группировки форма функции распределения остается прежней.
Функции распределения получили широкое применение в анализе сигна- лов.
Рассмотрим несколько примеров.
Функции совместного распределения нескольких параметров (многоме р- ные функции распределения) широко используются в прикладных задачах об- Р Амплитуда31 работки РС.
Многомерные распределения сложной формы обыкновенно аппроксимируют набором гауссовых распределений, называемых гауссовыми сме- сями.
На рисунке 3.4 приведен пример выборки двух параметров, аппроксимируемой моделью трех гауссовых функций распределения.
Рисунок 3.4.
Выборка двух параметров, аппроксимируемая моделью трех гауссовых функций распределения Пример необычной гистограммы сигнала показан на рисунке 3.5.
Рисунок 3.5 – Гистограмма сигнала Анализ этой гистограммы показывает, что сигнал первоначально был з а- писан в формате 12 бит, а затем был преобразован в формат 16 бит.
Гистограммы клиппированных сигналов (р ечевого и шума) показаны на рисунке 3.6.
Y X Амплитуда Р32 Рисунок 3.6 – Гистограммы чистого речевого сигнала и клиппированных речевых сигналов На гистограммах в области клиппирования сигналов появляется всплеск.
Это свойство гистограммы позволяет обнаружить на фонограмме участки клиппирования сигнала.
3.6 Анализ статистической взаимосвязи случайных величин Важной задачей первичного анализа сигналов является оценка их стат и- стической взаимосвязи.
Статистическая взаимосвязь оценивае тся с помощью нескольких мер.
Рассмотрим некоторые.
Ковариация – это математическое ожидание произведения двух центрир о- ванных случайных величин x, y [39]: cov(x, y) = σxy = E{(x – μx)(y – μy)}.
Для независимых величин cov(x, y) = 0.
Другой мерой подобия сигналов является дисперсия их разности.
Соо т- ношение между дисперсией и ковариацией определяется следующим соотношением: Dxy = E {(x[i] – y[i])²} = E {x[i]²} + E{y[i]²}- E{2 x[i] y[i]} = = Dx + Dy – 2cov(x, y).
Из этого соотношения следует: min Dxy  max cov (x, y).
Выборочная оценка ковариации (выборочная ковариация) двух дискре т- ных сигналов вычисляется следующим образом : 𝐶𝐶𝑥𝑥𝑦𝑦=1 𝑁𝑁−1∑ (𝑥𝑥[𝑖𝑖]−𝜇𝜇𝑥𝑥)(𝑦𝑦[𝑖𝑖]− 𝜇𝜇𝑦𝑦𝑁𝑁−1 𝑖𝑖=0).
Y X33 Однако, если x[i] = γ y [i], то ковариация будет зависеть от коэффицие н- та γ. Более подходящей мерой является коэффициент корреляции.
Корреляция – это нормированная ковариация [ 39]: 𝜌𝜌𝑥𝑥𝑦𝑦=𝜎𝜎𝑥𝑥𝑦𝑦 𝜎𝜎𝑥𝑥𝜎𝜎𝑦𝑦=𝐸𝐸�(𝑥𝑥−𝜇𝜇𝑥𝑥)�𝑦𝑦−𝜇𝜇𝑦𝑦�� 𝜎𝜎𝑥𝑥𝜎𝜎𝑦𝑦.
Если между величинами x, y имеется линейное соотношение (простейшая линейная связь) y[i] = α x[i] + β, то | ρxy| = 1.
Если величины x, y зашумлены, то | ρxy| < 1.
Если связь отсутствует, то | ρxy| = 0.
Выборочная оценка коэффициента корреляции центрированных проце с- сов вычисляется по следующей формуле: 𝜌𝜌𝑥𝑥𝑦𝑦=∑(𝑥𝑥[𝑖𝑖]𝑦𝑦[𝑖𝑖])𝑖𝑖 �∑𝑥𝑥[𝑖𝑖]2∑𝑦𝑦[𝑖𝑖]2𝑖𝑖 𝑖𝑖.
Быстрая выборочная оценка коэффициента корреляции процессов вычис- ляется по следующей формуле: ρxy = (∑ xy – 1/N∑x∑y) /[∑xx – 1/ N∑x∑x) (∑ yy – 1/N∑y∑y)] ½, где ∑xy = ∑i x[i] y[i], ∑x = ∑i x[i], ∑y = ∑i y[i].
Каким образом охарактеризовать статистическую взаимосвязь (степень «сходства») двух случайных процессов, например сигналов микрофонов?
Чтобы учесть возможный временной сдвиг между сигналами, необходимо вычислить коэффициенты ковариации при различных значениях временного сдвига между сигналами по времени.
Для этого используются ковариационные функции, ра с- смотренные в главе 4.
34 Вопросы и упражнения 1. y[i] = c × x [i] + a + n [i], где x[ i], n[i] – независимые случайные проце с- сы с нулевым средним.
Как по измерениям y[i], x[i] вычислить оценки коэффициентов a, c ?
2.Вы измерили N реализаций (значений) некоторого параметра x[i], i=1, N и вычислили оценку среднего значения 𝐴𝐴𝑥𝑥=1 N∑𝑥𝑥[𝑖𝑖].
Как оценить погрешность оценки среднего?
3.Докажите, что σ x² = E {x²}- E²{x}, где E { } – символ математического ожидания.
4.Чему равна дисперсия суммы двух независимых сигналов?
5.Изменится ли выборочная оценка мощности сигнала при увеличении частоты е го дискретизации?
6.Необходимо контролировать текущую ошибку оценки, чтобы остановится по достижению заданной точности.
Как это сделать?
7.Докажите быструю формулу вычисления выборочной оценки ковариации двух дискретных процессов: 𝑅𝑅𝑥𝑥𝑦𝑦=1 𝑁𝑁∑ (𝑥𝑥[𝑖𝑖]−𝜇𝜇𝑥𝑥)×�𝑦𝑦[𝑖𝑖]−𝜇𝜇𝑦𝑦�𝑁𝑁−1 0 = =1 𝑁𝑁∑ 𝑥𝑥[𝑖𝑖]𝑦𝑦[𝑖𝑖]𝑁𝑁−1 0 −�1 𝑁𝑁∑ 𝑥𝑥[𝑖𝑖]𝑁𝑁−1 0 �×�1 𝑁𝑁∑ 𝑦𝑦[𝑖𝑖]𝑁𝑁−1 0 �.
8.Будут ли различаться выборочные оценки мощности двух синусоид одинаковой амплитуды, но разной частоты?
35 4 ВРЕМЕННОЙ И ЧАСТОТНЫЙ АНАЛИЗ СИГНАЛОВ Для описания временных и частотных свойств речевых сигналов используются функции: корреляционная функция, спектр, коэффициенты линейного предсказания и ряд других.
В данном разделе рассмотрены ковариационные функции, спектры, функция когерентности и соотношения между ними.
4.1 Автоковариационная функция процесса Статистическая вязь двух сдвинутых по времени значений стационарной последовательности x[i] и x[i+m] характеризуется ковариацией Rm = R-m и соответствует корреляции с задержкой m. Автоковариационная функция процесса (АКФ) описывает статистическую связь между временными отсчетами сигнала, разнесенными на величину задержки.
Совокупность ковариаций с разным сдв и- гом называют автокорреляционной функцией процесса (temporal auto- correlation).
Несмещенная выборочная оценка автоковариационной функции процесса определяется формулой: 𝐶𝐶𝑥𝑥𝑥𝑥 [𝑚𝑚]=1 (𝑁𝑁−𝑚𝑚)∑ (𝑥𝑥[𝑖𝑖]−𝜇𝜇𝑥𝑥)×(𝑥𝑥[𝑖𝑖+𝑚𝑚]−𝜇𝜇𝑥𝑥)𝑁𝑁−𝑚𝑚−1 𝑖𝑖=0, m=-M+1,…-1, 0, 1,… M-1.
Свойства АКФ: Сxx[-m] = С xx[m], Сxx[0] = Dx, Сxx[m] → 0 при m → ∞.
Если сигнал является суммой сигналов разных независимых источников, тогда его КФ будет равна сумме АКФ этих сигналов: Rss [m] = ∑ Rxxi[m].
Чтобы сделать меру инвариантной к мощности (нормировке) сигналов, используют нормализованную АКФ (energy normalized correlation).
Нормализованная АКФ определяется формулой: 𝑅𝑅𝑋𝑋𝑋𝑋[𝑚𝑚]=𝐶𝐶𝑥𝑥𝑥𝑥[𝑚𝑚] 𝐶𝐶𝑥𝑥𝑥𝑥[0], или 𝑅𝑅𝑋𝑋𝑋𝑋[𝑚𝑚]=∑ 𝑥𝑥[𝑖𝑖]𝑥𝑥[𝑖𝑖+𝑚𝑚]𝐿𝐿−𝑚𝑚−1 𝑖𝑖=0 �∑ 𝑥𝑥2[𝑖𝑖]𝐿𝐿−𝑚𝑚−1 𝑖𝑖=0∑ 𝑥𝑥2[𝑖𝑖+𝑚𝑚]𝐿𝐿−𝑚𝑚−1 𝑖𝑖=0�1 2.
Параметрами оценки АКФ являются интервал суммирования L и интервал задержек M (максимальное запаздывание).
Основным применением автокорреляционной функции в анализе и обработке РС является оценка коэффициентов линейного предсказания при модел и- ровании речевых сигналов [ 31].
Другим применением АКФ является обнаружение скрытых периодичностей процессов, например основного тона РС.
Пример Обнаружение скрытых периодичностей процессов и оценка основного т о- на с помощью АКФ.
Пусть x[i] ≈ x [i + k ] + n [i], тогда 𝐶𝐶𝑥𝑥𝑥𝑥[𝑚𝑚]=1 𝑁𝑁−𝑚𝑚� (𝑥𝑥[𝑖𝑖]𝑥𝑥[𝑚𝑚+𝑘𝑘+𝑖𝑖]+𝑥𝑥[𝑖𝑖]𝑛𝑛[𝑚𝑚+𝑖𝑖])𝑁𝑁−𝑚𝑚−1 𝑖𝑖=0= =𝐶𝐶𝑥𝑥𝑥𝑥[𝑚𝑚+𝑘𝑘]+𝐶𝐶𝑥𝑥𝑛𝑛[𝑚𝑚].
Поскольку сигнал и шум не коррелированны, имеем : Сxx[m] ≈ С xx[m+k].
Таким образом, АКФ является периодической функцией с периодом основного тона сигнала.
На рисунке 4.1 представлен график АКФ на кадре речев о- го сигнала с периодом основного тона 37 мс.
Рисунок 4.1 – АКФ на кадре тонального речевого сигнала 4.2 Ковариация и ее оценка Кросс-ковариационный анализ необходим для идентификации систем, сравнения сигналов одного источника, принимаемых разными микрофонами и во многих других приложениях анализа и обработки РС.
С его помощью можно определять степень сходства двух временных последовательностей.
Иногда и с- пользуется термин кросс-ковариация, чтобы не путать с автоковариацией.
Пусть имеем два дискретных сигнала x[i], y[i], i = 0, 1, …N-1.
Функция кросс-ковариации (ФКК) определяется выражением : 𝐶𝐶𝑥𝑥𝑦𝑦[𝑚𝑚]=1 𝐿𝐿−𝑚𝑚∑ (𝑥𝑥[𝑖𝑖]−𝜇𝜇𝑥𝑥)×�𝑦𝑦[𝑖𝑖+𝑚𝑚]−𝜇𝜇𝑦𝑦�𝐿𝐿−𝑚𝑚−1 𝑖𝑖=0, Задержка Y37 m =-M, …-1, 0, 1,… M, где μx = < x[i]>, μy = <y[ i]>, m – «запаздывание».
M – «максимальное запаздыва-ние», i = 0,1,…L.
Свойства функции кросс-ковариации представлены ниже.
Cxy[m] → 0 при m → ∞, Cxy[-m] = Cyx [m], Cxx[-m] = Cxx [m], Cxy[m] + Cxy [-m] – четная функция, Cxy[m]- Cxy[-m] – нечетная функция.
Во многих случаях удобно пользоваться краткой векторной записью к о- вариационной и автокорреляционной функций.
Определим вектор отсчетов X[i] = [x[i], x[i-1],…x[i–M+1]]T, и вектор к о- вариаций Cxy = [Cxy[0], Cxy[ 1],… Cxy[M-1]]T. Оценку вектора ковариаций можно записать следующим образом: Cxy = < X[i] y[i]>.
В случае y[ i] = x[i] получим оценку вектора автокорреляций : Сxx = < X[i] x[i]>.
Обобщением ФКК для случая многомерных сигналов (микрофонных р е- шеток) является кросс-корреляционная матрица сигналов: 𝐴𝐴𝑋𝑋𝑋𝑋[𝑖𝑖,𝑗𝑗,𝑚𝑚]=1 𝐿𝐿−𝑚𝑚∑ (𝑥𝑥𝑖𝑖[𝑛𝑛]−𝜇𝜇𝑥𝑥𝑖𝑖)×�𝑥𝑥𝑗𝑗[𝑛𝑛+𝑚𝑚]−𝜇𝜇𝑣𝑣𝑗𝑗�𝐿𝐿−𝑚𝑚−1 𝑛𝑛=0, 𝑚𝑚 = −𝑅𝑅,..−1,0,1,.𝑅𝑅.
В векторной форме : Axy = <Y[i] XT[i]>.
Инвариантная к нормировке сигналов нормализованная кросс- корреляционная функция определяется формулой : Rxy[m] = Cxy [m]/ σxσy ≤ 1.
Пример Измерение временных задержек (сдвигов) между сиг налами.
Сигнал s(t) распространяется из точки A в точку B с задержкой Txy: A: x(t) = s(t) + n (t), B: y(t) = αs(t- Txy) + v (t).
Можно показать, что функция кросс-корреляции Cxy(τ) между сигналами x(t), y(t) будет иметь пик, соответствующий задержке сигнала между этими то ч- ками:38 Cxy(τ) = α Cxx(τ- Txy), Txy = argmax{ Cxy (τ)}.
По положению максимума ФКК можно измерить временной сдвиг между сигналами.
4.3 Спектральный анализ сигналов Спектральный анализ – это один из методов, который позволяет охара к- теризовать частотный состав измеряемого сигнала и описать сигнал в спе к- тральном пространстве [ 32].
Преобразование Фурье (Fourier transform) – это разложение функций на синусоиды.
Существует несколько видов преобразования Фурье [ 29, 32]: а) непериодический непрерывный сигнал можно разложить в интеграл Фурье: x(t) → X(f); б) периодический непрерывный сигнал можно разложить в бесконечный ряд Фурье x(t) → X[n]; в) непериодический дискретный сигнал можно разложить в интеграл Ф у- рье: x[i] → X(f); г) периодический дискретный сигнал можно разложить в конечный ряд Фурье: x[i] → X[n].
Речевой сигнал является нестационарным процессом, значения параме т- ров которого непрерывно меняются.
Поэтому выборочные оценки спектра бе- рутся на последовательных (обычно пересекающихся) кадрах в предположении, что на кадре процесс является стацион арным и характеризуется фиксированным спектром.
Дискретный вектор сигнала на кадре преобразуется с помощью пр е- образования Фурье в дискретный спектр той же размерности (конечный ряд Фурье).
Таким образом, при обработке РС используется только последний вид преобразования Фурье (дискретное преобразование Фурье, ДПФ).
В этой моде- ли сигнала неявно подразумевается его периодичность, то есть периодическое повторение за пределами интервала наблюдения.
Рассмотрим дискретное преобразование Фурье подробнее.
Спектр – представление функции x[i] на интервале [0,N-1] в виде суммы периодических компонент: 𝑥𝑥[𝑖𝑖]=� 𝐴𝐴𝑥𝑥[𝑛𝑛]𝑐𝑐𝑐𝑐𝑐𝑐 �2𝜋𝜋𝑖𝑖𝑛𝑛 𝑁𝑁+𝜑𝜑𝑥𝑥[𝑛𝑛]�𝑁𝑁−1 𝑛𝑛=0= =� �𝐴𝐴𝑐𝑐[𝑛𝑛]𝑐𝑐𝑐𝑐𝑐𝑐 (2𝜋𝜋𝑖𝑖𝑛𝑛/𝑁𝑁)+𝐴𝐴𝑐𝑐[𝑛𝑛]𝑐𝑐𝑖𝑖𝑛𝑛 (2𝜋𝜋𝑖𝑖𝑛𝑛/𝑁𝑁)�𝑁𝑁−1 𝑛𝑛=0, где N – размерность спектра.39 Для компактности записи можно представить пары коэффициентов спе к- тра в виде комплексных чисел (коэффициентов комплексного спектра) : X[n] = Ac [n] + jAs [n], тогда : 𝑥𝑥[𝑖𝑖]=∑𝑋𝑋[𝑛𝑛]𝑒𝑒𝑥𝑥𝑝𝑝 [𝑗𝑗2𝜋𝜋𝑖𝑖𝑛𝑛/𝑁𝑁].
В этом случае вектор коэффициентов дискретного комплексного спектра вычисляются из вектора отсчетов сигнала на кадре с помощью дискретного преобразования Фурье (Discrete Fourier Transform, DFT): 𝑋𝑋[𝑛𝑛]=𝐷𝐷𝑑𝑑𝐷𝐷 {𝑥𝑥[𝑖𝑖]}=� 𝑥𝑥[𝑖𝑖]𝑒𝑒𝑥𝑥𝑝𝑝 �−𝑗𝑗2𝜋𝜋𝑛𝑛𝑖𝑖 𝑁𝑁�=𝑁𝑁−1 𝑖𝑖=0 =� 𝑥𝑥[𝑖𝑖]�𝑐𝑐𝑐𝑐𝑐𝑐�2𝜋𝜋𝑛𝑛𝑖𝑖 𝑁𝑁�−𝑗𝑗𝑐𝑐𝑖𝑖𝑛𝑛 �2𝜋𝜋𝑛𝑛𝑖𝑖 𝑁𝑁��𝑁𝑁−1 𝑖𝑖=0,𝑛𝑛=0,...,𝑁𝑁−1.
Коэффициенты дискретного спектра соответствуют частотам n×Fs/N.
Свойства комплексного спектра вещественной последовательности x[i ]: Re{X[n]} = Re{X[N-n]}, n=1,… N/2, Im{X[n]} =- Im{X[N-i]}, n=1, …N/2, Im{X[n]} = 0, n=1, N /2.
Реальные коэффициенты спектра симметричны, мнимые – антисимме т- ричны относительно номера n= N/2.
Таким образом, вектор N отсчетов сигнала преобразу ется в вектор N независимых отсчетов комплексного спектра: N/2+1 значений реальной части и N/2-1 значений мнимой части.
В разных программах отсчеты комплексного спектра могут размещаться («упаковываться») в векторе спектра различными способами.
На рисунке 4.2 приведен пример дискретного спектра для N = 8.
Рисунок 4.2 – Реальная и мнимая части спектра вещественного сигнала (N=8) 40 Комплексные коэффициенты спектра могут быть представлены в поля р- ных координатах модуля и фазы: X[n] = |X[n]| exp(j2π Φx[n]) = Ax [n] exp(j2π Φx[n]) Ax[n] = (Re²{X[n]} + Im²{X[n]})½, 𝛷𝛷𝑥𝑥[𝑛𝑛]=𝑎𝑎𝑟𝑟𝑐𝑐𝑟𝑟𝑔𝑔 �𝐼𝐼𝑚𝑚{𝑋𝑋[𝑛𝑛]} 𝑅𝑅𝑒𝑒{𝑋𝑋[𝑛𝑛]}�, где обозначение arctg введено для главного значения.
Амплитудные коэффициенты Ax[n] называют амплитудным спектром, фазовые Φx[n] – фазовым спектром.
Вектор коэффициентов спектра может быть преобразован в вектор отсче- тов сигнала на кадре с помощью обратного дискретного преобразования Фурье (ОДПФ).
Оператор ОДПФ будем обозначать IDFT (Inverse Discrete Fourier Transform): 𝑥𝑥[𝑖𝑖]=𝐼𝐼𝐷𝐷𝑑𝑑𝐷𝐷 {𝑋𝑋[𝑛𝑛]}=1 𝑁𝑁� 𝑋𝑋[𝑛𝑛]𝑒𝑒𝑥𝑥𝑝𝑝 �𝑗𝑗2𝜋𝜋𝑛𝑛𝑖𝑖 𝑁𝑁�𝑁𝑁−1 𝑛𝑛=0= =1 𝑁𝑁∑ [𝑅𝑅𝑒𝑒{𝑋𝑋[𝑛𝑛]}+𝑗𝑗𝐼𝐼𝑚𝑚{𝑋𝑋[𝑛𝑛]}]�𝑐𝑐𝑐𝑐𝑐𝑐 �2𝜋𝜋𝑛𝑛𝑖𝑖 𝑁𝑁�+ 𝑗𝑗 𝑐𝑐𝑖𝑖𝑛𝑛 �2𝜋𝜋𝑛𝑛𝑖𝑖 𝑁𝑁��𝑁𝑁−1 𝑛𝑛=0, i=0, N-1.
Обратное дискретное преобразование Фурье выполняется с помощью той же самой процедуры, что и ДПФ.
Необходимо только вместо действительных отсчетов сигнала подставить комплексные значения спектра и поменять знак при мнимой части, а результат поделить на N. Поскольку реальная часть спектра является симметричной функцией, а мнимая – антисимметричной, то последовательность x[i] является веществе н- ной.
Замечание.
В принципе, имея N отсчетов сигнала, можно вычислить спектр для л ю- бой частоты (в интервале 0-Fs/2): 𝑋𝑋(𝑓𝑓)=∑ 𝑥𝑥[𝑛𝑛]𝑒𝑒𝑥𝑥𝑝𝑝 (−𝑗𝑗2𝜋𝜋𝑓𝑓𝐷𝐷𝑛𝑛)𝑁𝑁−1 𝑛𝑛=0.
Поэтому в дальнейшем мы также будем использовать такую запись : X(f) = FT{x[i]}.
Переход от непрерывного спектра к дискретному осуществляется выб о- ром частот fn = n /NT, n = 0,...,N-1.
4.4 Спектр мощности Спектральная плотность мощности (СПМ) показывает распределение дисперсий случайного процесса в непрерывном диапазоне частот 0 – π. Велич и- ну Pxx(ω)dω можно интерпретировать как приближенное значение дисперсии41 процесса в диапазоне частот ω – (ω + dω).
Рассмотрим дискретную оценку СПМ.
Периодограмма – оценка дискре т- ного спектра мощности сигнала на кадре определяется соотношением : Pxx[n] = |X[n]|² = Re ²{X[n]} + Im²{X[n]}.
Периодограмма имеет смысл распределения мощности сигнала по часто т- ным полосам.
Например, в белом шуме средний спектр мощности равномерный.
Оценка спектра мощности на кадре (на конечной выборке) имеет бол ь- шую дисперсию, которая не уменьшается с увеличением длины выборки, по- скольку при этом увеличивается размерность спектра.
Таким образом, оценка СПМ является несостоятельн ой.
Для решения этой проблемы разработан ряд методов оценки дискретного спектра мощности, основанных на усреднении (сглаживании) периодограмм [ 39]: а) метод Бартлетта : усреднение периодограмм по времени на непер е- крывающихся кадра х 𝑃𝑃𝑥𝑥𝑥𝑥[𝑛𝑛]=<|𝑋𝑋[n,k]|²>=1 𝐾𝐾∑|𝑋𝑋[𝑛𝑛,𝑘𝑘]|2 𝑘𝑘, где k – индекс кадров; б) метод Уэлча : сглаживани е периодограмм на перекрывающихся кадра х; в) метод Даньелла : сглаживания периодограмм по частотам ; г) совместное сглаживание периодограмм по частоте и времени ; д) метод Блэкмана-Тьюки: основан на соотношениях Винера-Хинчина, связывающих дискретные оценки спектра мощности и корреляционной функции Pxx[n] = DFT{ Сxx[m ]}, Сxx [m] = IDFT{Pxx[ n]}.
Рисунок 4.3 – Средние амплитудные спектры смеси белого шума и гармоники: наверху – в линейном масштабе, внизу – в логарифмическом масштабе N=128 Ахх Гц Гц Ахх, дБ N=128 N=256 N=256 N=512 N=51242 Обычно на графиках показывают средний спектр мощности, вычисле н- ный по методу Бартлетта или соответствующий ему амплитудный спектр 𝐴𝐴𝑥𝑥[𝑛𝑛]=�𝑃𝑃𝑥𝑥𝑥𝑥[𝑛𝑛].
В шкале дБ эти представления не различаются.
Отметим различие дискретных оценок спектра случайного и детермин и- рованного тонального сигнала.
На рисунке 4.3 показаны средние спектры ра з- ной размерности белого шума и гармоники.
Из графиков видно, что с изменением числа полос (размерности спектра) амплитуда спектра шума меняется и почти не меняется для гармоники.
4.5 Кросс-спектр В анализе дискрет ных сигналов кросс-спектр используется как элемент частотного анализа кросс-корреляции двух дискретных сигналов.
Плотность кросс-спектра (КСП) – это ра зложение ковариации по частотам: 𝑋𝑋[𝑛𝑛]=∑ 𝑥𝑥[𝑖𝑖]𝑒𝑒𝑥𝑥𝑝𝑝 (−𝑗𝑗2𝜋𝜋𝑖𝑖𝑛𝑛/𝑁𝑁)𝑁𝑁−1 𝑖𝑖=0 =𝐷𝐷𝑑𝑑𝐷𝐷 {𝑿𝑿}, 𝑋𝑋[𝑛𝑛]=∑ 𝑦𝑦[𝑖𝑖]𝑒𝑒𝑥𝑥𝑝𝑝 (−𝑗𝑗2𝜋𝜋𝑖𝑖𝑛𝑛/𝑁𝑁)𝑁𝑁−1 𝑖𝑖=0 =𝐷𝐷𝑑𝑑𝐷𝐷 {𝒀𝒀}.
Кросс-спектр является комплексной функцией и определяется следующим выражением : Pxy[n] = <X*[n] Y[n]> = Rxy [n] –jQxy [n].
Модуль и фаза кросс-спектра определя ются следующим и выражен иями: �𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]�2=𝑅𝑅𝑥𝑥𝑦𝑦2[𝑛𝑛]+𝑄𝑄𝑥𝑥𝑦𝑦2[𝑛𝑛], �𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]�=��𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]�2�1/2, 𝛷𝛷𝑥𝑥𝑦𝑦[𝑛𝑛]=𝑎𝑎𝑟𝑟𝑐𝑐𝑟𝑟𝑔𝑔 �𝑄𝑄𝑥𝑥𝑦𝑦[𝑛𝑛] 𝑅𝑅𝑥𝑥𝑦𝑦[𝑛𝑛]�, 𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]=�𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]�𝑒𝑒𝑥𝑥𝑝𝑝�𝑗𝑗𝛷𝛷𝑥𝑥𝑦𝑦[𝑛𝑛]�.
КСП характеризует степень и характер связи между частотными составляющими двух временных рядов.
Модуль КСП характеризует соотношение амплитуд спектральных составляющих рядов.
Характер опережения или запаздывания между рядами характеризуется фазовым спектром (фазовым сдвигом).
Свойства КСП [ 21]: �𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]�2≤𝑃𝑃𝑥𝑥𝑥𝑥[𝑛𝑛]𝑃𝑃𝑦𝑦𝑦𝑦[𝑛𝑛], �𝑃𝑃𝑦𝑦𝑥𝑥[𝑛𝑛]�2=�𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]�2, 𝑃𝑃𝑦𝑦𝑥𝑥[𝑛𝑛]=𝑃𝑃𝑥𝑥𝑦𝑦∗[𝑛𝑛].
Обобщением кросс-спектров для случая многомерных сигналов (напр и- мер, микрофонных решеток) является матрица кросс-спектров [ 39]: Pxx(f) = <X*(f) XT(f)>.43 4.6 Соотношение между ковариационной функцией и кросс-спектром Ковариация и кросс-спектр связаны преобразованием Фурье: 𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]=∑ 𝐶𝐶𝑥𝑥𝑦𝑦[𝑚𝑚]𝑁𝑁−1 𝑚𝑚=0 𝑒𝑒𝑥𝑥𝑝𝑝 �−𝑗𝑗2𝜋𝜋𝑚𝑚𝑛𝑛 𝑁𝑁�=𝐷𝐷𝑑𝑑𝐷𝐷 �𝐶𝐶𝑥𝑥𝑦𝑦[𝑚𝑚]�,𝑛𝑛 = 0,1,…𝑁𝑁−1, 𝐶𝐶𝑥𝑥𝑦𝑦[𝑚𝑚]=1 𝑁𝑁∑ 𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]𝑒𝑒𝑥𝑥𝑝𝑝 �𝑗𝑗2𝜋𝜋𝑚𝑚𝑛𝑛 𝑁𝑁�𝑁𝑁−1 𝑛𝑛=0 =𝐼𝐼𝐷𝐷𝑑𝑑𝐷𝐷 {𝑃𝑃𝑥𝑥𝑦𝑦[𝑛𝑛]}),𝑚𝑚 = 0,1,𝑁𝑁−1Pxy.
Для отдельного кадра : 𝐶𝐶𝑥𝑥𝑦𝑦[𝑚𝑚]=1 𝑁𝑁�� �𝑋𝑋∗[𝑛𝑛]𝑋𝑋[𝑛𝑛]�𝑒𝑒𝑥𝑥𝑝𝑝 �𝑗𝑗2𝜋𝜋𝑚𝑚𝑛𝑛 𝑁𝑁�𝑁𝑁−1 𝑛𝑛=0�= = IDFT {X*[n]Y[n]} = IDFT {DFT {x[i]}*×DFT {y[i]}}.
Для вещественных сигналов x[i], y[i] функция Cxy[m] вещественная, одн а- ко она не является симметричной относительно m=0.
4.7 Функция когерентности и ее оценка Когере ́нтность (Coherence) – от латинского Cohaerens («находящийся в связи» или «взаимосвязь»).
Когерентность объединяет спектральные и корреляционные характеристики процессов и характеризует корреляцию между проце с- сами отдельно в каждой спектральной полосе.
Функция когерентности является мерой (но рмированной 0..1) линейной связи двух сигналов на заданной частоте f. Комплексная функция когерентности Комплексная функция когерентности определяется выражением: Γxy(f) = (Pxy (f)/[Pxx(f) Pyy(f)]½) = = <X(f, k)*Y (f, k)> / [<| X(f, k)|²> <| Y(f, k)|²>]½ = |Γxy(f)| exp(φxy(f), Отсюда следует Γxy(f) = Γyx*(f).
Функция когерентности может принимать как положительные, так и отрицательные значения.
Вещественная функция когерентности определяется выражением : |Γxy(f)| = |Pxy(f)|/[Pxx(f) Pyy(f)] ½. Производным от функции когерентности является квадрат модуля ког е- рентности (КМК), определяемый выражением: Gxy(f) = |Γxy(f)|² = |Pxy(f)|²/[Pxx(f)Pyy(f)].
На каждой частоте КМК соответствует коэффициенту корреляции : ρ²xy = cov xy² / σ x² σy² ↔ | Γxy(f)|² = | Pxy(f)|² /[Pxx (f) Pyy(f)], где cov xy = <xy>, σ x² = < x²>, σ y² = < y²>.44 Рассмотрим роль усреднения в оценке когерентности.
Физический смысл усреднения значения заключается в суммировании мгновенных единичных ве к- торов на комплексной плоскости, в результате чего получается комплексный вектор произвольной длины.
Если мгновенные компоненты были синфазны, то отдельные вектора имеют одинаковое направление, и результирующий вектор будет большим.
Если мгновенные вектора имели разные направления, компенсирующие друг др уга, то результирующий вектор будет иметь малую длину.
Таким образом, коэффициент когерентности характеризует среднюю взаимосвязь фаз двух процессов.
Обыкновенно статистическая связь существует между детерминированными процессами или процессами, связанными линейным преобразованием.
В случае, когда исследуется связность сигнала во времени, используются сдвинутые на интервал ∆T кадры сигнала.
Тогда функцию когерентности можно интерпретировать как функцию автокорреляции на частоте f со сдвигом ∆T.
Та- ким образо м, функция когерентности является обобщением АКФ для сигнала на частоте f. В общем случае функция когерентности зависит как от временной, так и от пространственной координаты.
Различают пространственную и временную когерентность, которые характеризуют взаимосвязь процессов, разнесенных в пространстве или во времени.
Если рассматривать эти процессы как сигналы на входе и выходе системы, то изменение процесса во времени или в пространстве можно рассматривать как результат прохождения через систему.
Временная функция когерентности позволяет судить о корреляции спе к- тральных компонент сигнала во времени, пространственная – о корреляции спектральных компонент сигналов в пространстве.
Пространственная функция когерентности используется при анализ е акустических характеристик помещений и в методах обработки сигналов мик-рофонных решеток.
Оценка функции когерентности Функцию временной когерентности целесообразно вычислять на непересекающихся кадрах сигнала.
При пересечении кадров сигналы на кадрах становятся коррелированными, и значения оценки функции когерентности начина ют расти даже для некоррелированного процесса, например белого шума.
Особенность оценки функции когерентности заключается в том, что опе- рация усреднения выполняется раньше вычисления модуля.
Если усреднение не производится, то независимо от природы наблюдаемых процессов функция ко- герентности равна единице:45 |Γxy(f, k)| = |X*(f, k) Y(f, k) |/[|X(f, k)|² |Y(f, k)|²]½ = = |{X*(f, k)/|X(f, k)| × Y(f, k)/|Y(f, k)|}| = |exp[j(Фy(f, k)- Фx(f, k)]| = 1.
В определении функции когерентности используются средние спектры.
При этом усредняется не отношение мгновенных спектров, а отдельно спектры в числителе и знаменателе.
Операция усреднения означает сложение комплексных векторов (единич- ной длины).
Если фазовый угол между векторами постоянен, то результиру ю- щий комплексный вектор будет иметь длину единица, если фазовый угол меня-ется случайным образом, то длина результирующего вектора стремится к нулю.
Таким образом, в результате усреднения шум, котор ый можно считать случа й- ным вектором, подавляется, так как фазы двух сигналов не связаны между с о- бой.
Следовательно, функция когерентности измеряет степень общности между сигналами в полосе частот.
Более детально вопросы оценки функции когерентности дискретных по- следовательностей конечной длины и их случайная и систематическая погре ш- ности рассмотрены, например, в книге [ 39].
Функцию когерентности можно оценивать на реальных данных либо в ы- числить для модели сигналов.
Рассмотрим примеры оценки временной и пространственной когерентности.
Пример 1 На рисунке 4.4 приведена экспериментальная оценка среднего спектра периодической импульсной помехи, на рисунке 4.5 – оценка модуля временной функции когерентности (×10 4) периодической импульсной помехи между сиг- налами соседних кадров.
Рисунок 4.4 – Средний спектр периодической импульсной помехи Гц Ахх46 Рисунок 4.5 – Оценка модуля временной функции когерентности периодической импульсной помехи на соседних кадрах Пример 2 Теоретическая оценка пространственной функции когерентности.
На микрофоны 1, 2, расположенные на расстоянии d один от другого под углом θ относительно оси, проходящей через микрофоны, поступает широкополосный сигнал.
На микрофон 2 сигнал поступает с задержкой τ=d ×cos θ/c относительно сигнала микрофона 1: x2(t) = x 1(t + τ).
Комплексный спектр сигнала 2-го микрофона отличается от спектра 1-го микрофона комплексным множителем: X2(f, k) = X1 (f, k) e-j2π τf.
Тогда Γ12(f, d) = <X1(f, k)*X2(f, k))/[<|X1(f, k)|²> <|X2(f, k)|²>]½ = = exp(-j2π d cosθ f/c), где c=340 м/c – скорость звука в воздухе.
G12(f) = |Γ12(f) ² = 1.
Вопросы и упражнения 1.
Имеем дискретный сигнал (белый шум).
Оцениваем его средний спектр с разным размером окна (ДПФ 256, 512, 1024).
Изменится ли амплитуда выборочной оценки амплитудного спектра?
2.
Может ли функция когерентности принимать отрицательные значения?
Гц G, дБ47 5 СИСТЕМЫ И ПРЕОБРАЗОВАНИЯ СИГНАЛОВ В данной главе описаны некоторые типы систем и рассматриваются две основные задачи: первая – представление (моделирование) аналоговых систем в цифровой форме, вторая – оценка параметров дискретных систем.
Общие вопросы моделирования сигналов и систем изложены в монографии [ 42].
5.1 Общие сведения о системах При рассмотрении сигналов наряду с понятием «сигнала» используется понятие (или концепция) «системы».
Системы описывают преобразования сигналов (аналоговых и цифровых).
Понятие системы удобно, когда мы хотим связать два (или более) сигналов, возникающих при их преобразовании или реа изовать такое преобразование.
Часто удобно рассматривать сигнал как выход системы, которая может быть «реальной» или просто удобной моделью.
Осно в- ное назначение систем – моделирование и выполнение преобразований.
Акустические сигналы претерпевают различные преобразования: распространение сигнала в пространстве, преобразование микрофоном акустического сигнала в электрический, преобразования электрического сигнала.
После преобразования электрических сигналов в цифровую форму они обрабатываются уже в дискретных системах.
Система – это некоторое преобразование сигнала.
Система преобраз ует входной сигнал x(t) в выходной сигнал y(t).
Например, зависимость давления во з- духа в точке от времени можно рассматривать как звуковой сигнал.
Зависимость напряжения в проводнике от времени тоже может представлять звуковой сиг- нал.
Микрофон преобразует акустическую энергию звукового сигнала в напряжение.
Модель системы – математический способ описания преобразования сигналов и их характеристик.
Модель системы описывает связи между сигналами на входе и выходе (в дальнейшем – входом и выходом) и может быть описана в символьной форме следующим соотношением: Y = F {X}, где X – вход системы, Y – выход, F {} – преобразование, выполняемое системой.
Примером системы является аппарат речеобразования, преобразующий звук колебаний голосо вых связок в звуки речи.
Различные модели речеобразования рассмотрены, например, в книгах [ 31, 46, 47].
Перечислим основные задачи, связанные с применением систем.48 Задачи анализа.
Зная характеристики системы, необходимо определить выход по входу или вход по выходу: X, F → Y, Y, F → X. Задачи идентификации системы.
Имея вход и выход, необходимо опр е- делить характеристики системы: X, Y → F. Задачи «слепой» идентификации системы (blind system identification).
Зная выход, необходимо определить вход и характеристики системы: Y → F, X. Задачи синтеза.
Необходимо определить характеристики системы, реализующей заданное преобразование между входом и выходом: X, Y → F. Модели (наряду с аналитическими выражениями) являются формой пре д- ставления знаний о системах.
Для одного и того же физического объекта можно использовать разные модели.
Всякая модель имеет характер проекции [ 42].
Мо- дель позволяет «представить» или «заменить» систему (рисунок 5.1).
Рисунок 5.1 – Система и модель В дальнейшем, говоря о системе, мы будем подразумевать наши пре д- ставления о ней, то есть ее модель.
5.2 Линейные системы Линейная система – система, осуществляющая линейное преобразование сигнала, например, электрическая цепь с элементами, не зависящими от напр я- жений и токов.
Линейные системы – первое приближение (модель) преобразований сигналов.
Математическое определение линейности : y(t) = F {a x1(t) + b x2(t)} = a F{x1(t)} + b F{x2(t)}.
Большое количество реальных систем по преобразованию сигналов мо ж- 49 но считать линейными.
Например, микрофон является линейной системой (с достаточной степенью точности), так как если в него будут говорить од новр е- менно два человека с разной громкостью, то электрический сигнал на выходе будет взвешенной суммой сигналов (от каждого человека в отдельности) на входе, а коэффициенты будут означать громкость разговора первого и второго человека [ 29].
Однако в обработке РС широко применяются и нелинейные си с- темы.
Например, компрессор, экспандер и ряд других мгновенных преобразований являются нелинейными преобразованиями.
Инвариантная к временному сдвигу система – это система, сдвиг сигнала на входе которой порождает тот же отклик, только сдвинутый по времени, т.е. если x(t) → y(t), то x(t+τ) → y(t+τ).
Это означает, что свойства системы, напр и- мер микрофонов, не меняются во времени и не зависят от входного сигнала.
Далее мы будем рассматривать линейные инвариантные к сдвигу системы, называя их просто линейными.
Свойства линейных систем: а) постоянный (константа) сигнал переводится любой линейной системой в постоянный сигнал; б) при прохождении через линейную систему синусоида остается син у- соидой.
Могут измениться лишь ее амплитуда и фаза (сдвиг во времени).
5.3 Линейные дискретные системы Дискретные системы – системы, преобразующие сигналы, дискретные или по времени, или по уровню, или уровню и времени (то есть цифровые сиг- налы).
В дальнейшем мы будем называть дискретными системами системы, преобразующие цифровые сигналы.
Дискретные системы являются дискретным аналогом непрерывных систем.
Соотношение между непрерывной и дискретной системами схематически представлено на рисунке 5.2.
Рисунок 5.2 – Соотношение между непрерывной и дискретной системой Под дискретизацией системы подразумевается преобразование непрерывной динамической модели к дискретной форме описания в разностных уравнениях.
При этом предполагается, что в моменты t = iT дискретные сигналы y[i] = y(iT) полученной дискретной модели с определенной степенью точности повторяют значения сигналов y(t) исходной непрерывной системы.
Дискретная модель описывает преобразование дискретного входного си г- нала x[i] в выходной сигнал y[i]: x[i] → y[i] = F {x[i]}, где F{ } представляет собой дискретную систему (вычислительный процесс) преобразования входного сигнала x[i] в выходной сигнал y[i].
Простейшими дискретными системами являются линейные дискретные системы (ЛДС).
Основными операциями в ЛДС являются суммирование, у м- ножение и задержка на один отсчет (рисунок 5.3).
Рисунок 5.3 – Основные операции в ЛДС.
z-1 – оператор задержки сигнала на один отсчет Свойства линейности ЛДС формулируются так же, как и для непреры в- ных линейных систем.
Линейность : y[i] = F{ax 1[i] + bx 2[i]} = a F{x1[i]} + b F{x2[i]}.
Инвариантность во времени: y[i – K] = F {x[i – K]}.
5.4 Дискретная свёртка Рассмотрим формирование выходного сигнала в ЛДС.
Для этого рассмо т- рим реакцию системы на цифровую дельта-функцию – сигнал вида δ[0] = 1, δ[i≠0] = 0.
Любой дискретный сигнал можно разложить в сумму таких функций, сдвинутых во времени.
Например, бесконечный сигнал x[i] можно представить в виде : 𝑥𝑥[𝑖𝑖]= ∑ +∞ 𝑛𝑛=−∞𝑥𝑥[𝑛𝑛] 𝛿𝛿[𝑖𝑖−𝑛𝑛]= ∑ +∞ 𝑛𝑛=−∞𝑥𝑥[𝑖𝑖−𝑛𝑛]𝛿𝛿[𝑛𝑛].
Рассмотрим отклик (выходной сигнал) линейной системы на цифровую дельта-функцию.
Для этого подадим дельта-функцию в систему и измерим выходной сигнал.
Пусть выходной сигнал равен h[n]: δ[n] → h[n].
Сигнал h[n] называется импульсной характеристикой или реакцией сис- темы (impulse response), поскольку он является откликом системы на единичный 51 импульс.
Зная h[n] (отклик системы на дельта-функцию), можно вычислить о т- клик системы на любой входной сигнал.
Действительно, так как лю бой входной сигнал является линейной комбинацией сдвинутых во времени дельта-функций, то выходной сигнал будет той же самой линейной комбинацией сдвинутых во времени функций h[n].
Это следует из линейности системы и инвариантности к сдвигу по времени: 𝑦𝑦[𝑖𝑖] = � 𝑥𝑥[𝑖𝑖−𝑛𝑛] ℎ[𝑛𝑛]+∞ 𝑛𝑛= −∞.
Таким образом, каждая точка сигнала превращается в функцию h (сдвинутую в нужную позицию и умноженную на величину данной точки сигнала), а потом все эти функции складываются.
Дополнительно будем считать систему каузальной, если ее отклик следует за входом (что соответствует физически реализуемым системам).
Рассмотренная операция получения результирующего сигнала по исходному называется сверткой (convolution).
Итак, любая линейная система осуществляет свертку входного сигнала со своей импульсной характеристикой.
Это записывается так: y[i] = x[i] ∗ℎ[𝑖𝑖].
Функция h[n] называется импульсной характеристикой линейной системы.
Свойства свертки представлены ниже.
Для каузальной системы h[i <0] = 0.
Свертка с единичным импульсом: x[i] = x[i]∗δ[i].
Коммутативность : x[i] = x[i]∗h[i] = h [i]∗x[i].
Ассоциативность : x[i]∗h[i]∗g[i] =(x[i]∗h[i])∗g[i] = x [i]∗ (h[i]∗g[i]).
Дистрибутивность : x[i]∗(g[i] + h[i]) = x [i]∗g[i] + x [i]∗h[i], (x[i] + y[ i]) ∗h[i] = x[i]∗h[i] + y[i]∗h[i].
Периодичность: если h[i] является периодической, то h [i]∗x[i] также периодическая.
5.5 Система с конечной импульсной характеристикой Систему с конечным числом коэффициентов импульсной характеристики называют системой с конечной импульсной характеристикой (КИХ).
КИХ- систему (в отличие от свертки с бесконечным числом коэффициентов) можно представить в следующем виде:52 𝑦𝑦[𝑖𝑖] = 𝑥𝑥[𝑖𝑖]∗ ℎ[𝑖𝑖] = � 𝑥𝑥[𝑖𝑖 −𝑘𝑘] ℎ[𝑖𝑖]𝑅𝑅2 𝑘𝑘= 𝑅𝑅1.
Для каузальной системы y[i] = x[i]∗h[i] = ∑k= 0, +M x[i-k] h[i].
Для некаузальной системы y[i] = x[i]∗h[i] = ∑k=- M1, + M2 x[i-k] h[i].
Пример некаузальной системы: y[i] = ¼ (x[ i-1] + 2 x[i] + x[i +1]).
Частотное описание преобразования КИХ-системы дано ниже.
Представим уравнение свертки в частотной области.
ДПФ свертки прео б- разуется в произведение ДПФ импульсной реакции и ДПФ сигнала.
y[i]= h[i]∗ x[i] → DFT{ h[i]∗x[i]} = DFT{ h[i]} DFT{ x[i]}.
Разобьем входной и выходной сигнала на кадры конечного размера (fram- ing).
Применим ДПФ к кадрам входного сигнала конечного размера: Y(f, k) = H (f) X(f, k), H(f) = Y (f, k) /X(f, k), где k – индекс кадров, f – индекс частоты.
H(f) = DFT {h[i]}, X(f, k) = DFT {x[i]}, Y(f, k) = DFT {y[i] }, где H(f) – передаточная функция ЛДС, H(f) = DFT{h [i]} = ∑ n=0, L-1 h[n] exp (-j2πfTn).
Рассмотрим выходной сигнал системы : Y(f, k) = H (k) X(k) = Re{Y} + j Im{Y} = = (Re{H} + j Im{H}) (Re{X} + j Im{X}) = = (Re{H} Re{X}- Im{H} Im{X}) + j (Re{H} Im{X} + Im{H} Re{X}).
Поскольку h[n], x[n] – вещественные функции, то Re{H } Re{X } – симметричные, Im{H} Im{X}– антисимметричные функции, поэтому Re{Y} – симме т- ричная, Im{Y} – антисимметричная.
Следовательно, вектор кадра выходного сигнала Y [k] = IDFT {Y(f, k)}.
Последовательность кадров выходного сигнала преобразуется в вещественную функцию y[i] – выходного сигнала.
5.6 Система с бесконечной импульсной характеристикой В общем случае преобразование сигнала в ЛДС может быть представлено линейным разностным уравнением: y[i] = ∑ n=0, P bn x[i-n]- ∑ m=1,Q am y[i-m].
Схема этого преобразования приведена на рисунке 5.4.
Система имеет обратную связь, поскольку задержанный сигнал с выхода системы поступает обратно в систему.
Отклик такой системы на единичный и м-53 пульс может длиться бесконечно.
Поэтому такие системы называют системами с бесконечной импульсной характеристикой (БИХ).
Рассмотрим вкратце описание систем с БИХ.
Временное представление: y[i]∗a[i] = b[i]∗x[i] Частотное представление: Y(f) A(f) = X(f) B(f) АЧХ: Y(f) = X(f) B(f)/A(f) = H(f) X(f), H(f) = B(f)/A(f) Рисунок 5.4 – Схема линейной дискретной системы Пример 1 Простая БИХ-система : y[i] =- a1 y[i-1] + bo x [i] + b1 x [i-1].
Пример 2 Частный случай БИХ-системы (уравнение авторегрессии): y[i]∗a[i] = x[i].
5.7 Спектральное описание линейных систем с одним входом и выходом Предположим, что на вход линейной системы подается некоторый ста- ционарный случайный процесс x(t) с нулевым средним.
Тогда выход y(t) будет иметь такие свойства: y(t) = h(t) ∗x(t), Y(f) = H (f) X(f) = |H(f)| e j Φ(f) X(f), где |H(f)| – модуль передаточной функции системы (амплитудно-частотная х а- рактеристика, АЧХ), Φ(f) – фазовая характеристика передаточной функции (фазово-частотная характеристика, ФЧХ).
Функции плотности спектра мощности Pxx(f), Pyy(f) и функцию кросс- спектра Pxy(f) связывают соотношения : Pyy(f) = |H(f)|² Pxx (f), 54 Pxy(f) = H (f) Pxx (f).
Если спектр мощности входа и кросс-спектр мощности известны, то ча с- тотная функция отклика определена : Hxy (f) = Pxy (f)/Pxx (f).
В случае идеальной линейной системы без шума : Γ²xy(f) = |Pxy(f)|² / Pxx(f)Pyy(f) = =|H(f) Pxx (f)|² /Pxx(f) |H(f)|² Pxx (f) = 1.
Следовательно, в случае линейных систем функция когерентности дост и- гает своего теоретического максимума, равного единице на всех частотах.
Если же функция когерентности меньше единицы, то одной из возможных причин этого может служить отсутствие линейной зависимости выхода от входа ра с- сматриваемой системы, то есть нелинейность системы.
5.8 Оценка характеристик линейных систем Оценку характеристик систем выполняют по наблюдениям сигнала на вх о- де и выходе системы.
Другие методы выполняют по наблюдениям сигнала на в ы- ходе системы в предположении, что на вход системы поступает сигнал с извес т- ными свойствами, например, белый шум.
Рассмотрим некоторые из методов.
Оценка передаточной функции с использованием тестового сигнала Рассмотрим линейную систему : Y(f) = |H(f)| e jΦ(f) X(f).
Задача заключается в оценке амплитудной и фазовой характеристики передаточной функции H(f).
Оценка при помощи синусоид Метод реализуется с использованием инструментальных средств анализа аналоговых сигналов.
На вход системы подается косинус частоты fo: x(t) = A cos(2πfo t).
Спектр входного сигнала имеет вид: X(f) = A/2 [δ(f-fo) + δ(f+fo)].
Тогда спектр выходного сигнала будет иметь вид: Y(f) = |H(f)| ejΦ(f) A/2[δ(f-fo) + δ(f+fo)] = |H(fo)|A/2 (ejΦ(fo) + ejΦ(-fo)), а сигнал будет содержать информацию об АЧХ и ФЧХ системы : y(t) = A |H(fo)| cos(2πfot + Φ(fo)).55 Располагая инструментом оценки фаз и амплитуд, можно оценить АЧХ и ФЧХ системы [ 39].
Изменяя частоту тестового, сигнала можно измерить пер е- даточную функцию в нужном диапазоне.
Оценка при помощи случайного сигнала Другой метод основывается на цифровой обработке сигналов.
На вход системы подается широкополосный сигнал.
Дискретные спектры входного и выходного сигналов на кадрах (k) связаны соотношением : Y(f, k) = H (f) X(f, k).
Кросс-спектр входного и выходного сигналов определяется соотношением: Pxy(f) = <X*(f, k) Y(f, k) > = <X*(f, k)H(f) X(f, k)> = H (f) Pxx (f), где ()* – символ комплексного сопряжения.
Отсюда может быть вычислена оценка передаточной функции: Ĥ(f) = Pxy (f)/Pxx (f).
По передаточной функции можно вычислить импульсную характеристику системы: h[i] = FT-1{Ĥ(f)}.
Необходимо, чтобы входной сигнал имел спектральные компоненты во всем интересующем диапазоне частот, например белый шум.
Описанный метод особенно удобен для качественной экспресс-оценки АЧХ системы, если на ее вход подавать белый шум.
Оценка коэффициентов КИХ-системы по входу и выходу Рассмотрим процедуру оценки импульсной характеристики КИХ- системы.
Запишем отклик системы в векторной форме: y[n] = hT X[k] = XT[k] h, где k – индекс кадров, X[k] = [x[k], x[k-1],…x[k-L+1 ]]T – вектор входного сигн а- ла, h = [h[0], h[1],…h[L-1]]T – импульсная характеристика.
Запишем соотношения между вектором кросс-корреляции и импульсным откликом: <X[k] y[n]> = Cxy = < X[k] XT[k] h> = Axx h, где Cxy – вектор кросс-корреляции, Axx – матрица автокорреляции.
Решая систему линейных уравнений, получим оценку коэффициентов им- пульсного отклика: h = Axx-1 Cxy.56 Оценка коэффициентов авторегрессионной модели по входу и выходу Представим авторегрессионную модель в векторной форме: y[i] = AT Y[i] + e [i] = YT[i] A + e [i], где Y[i] = [y[i-1], y[i-2],…y[i –p]]T – вектор отсчетов сигнала, A = [a[1], a[2],… a [p]]T – вектор коэффициентов.
Запишем ошибки между сигналом y[i] и выходом фильтра ; E{|e[i]|²} = < (y[i] – AT Y[i])² >.
Минимизация СКО ошибки приводит к оптимальному решению: <Y[i] y[i]> = Cy = <Y[i] YT[i] A> = Cyy A. Решая систему линейных уравнений, получим оценку БИХ- коэффициентов: A = Cyy-1 Cy.
Всеобъемлющее описание методов идентификации систем читатель на й- дет в книге Гропа [ 18].
Вопросы и упражнения 1.
Система задана следующим уравнением: y [n] = x[n] + 2 x [n+1] + 3.
Является ли система линейной, инвариантной к сдвигу, каузальной?
2.
Приведите пример некоммутативной операции.
3.
Как вычислить фазовую характеристику линейной системы по входно-му и выходному сигналам?
4.
Почему АЧХ системы вычисляют по усредненным спектра м: Ĥ(f) = <X*(f, k)Y(f, k)>/<X*(f, k)X(f, k)>, а не мгновенным: Ĥ(f)= Y(f, k)/X(f, k)?
5.
Как оценить фазовый сдвиг сигнала на заданной частоте между двумя последовательными кадрами сигнала?
6.
При фиксированном временном сдвиге между кадрами фазовая задержка на разных частотах линейно увеличивается пропорционально частоте.
Как по функции фазовой задержки построить функцию временной задержки между кадрами или на различных частотах?
7.
Запишите соотношения между АЧХ и импульсной характеристикой КИХ-фильтра.57 6 ФИЛЬТРАЦИЯ ДИСКРЕТНЫХ СИГНАЛОВ Одним из применений цифровых систем является преобразование сигна- лов (и временных рядов) заданным образом.
Эти преобразования могут быть выполнены с помощью фильтров.
Слово «фильтр» возникло из физических явлений, изучаемых теорией электрических цепей, и получило дальнейшее разв и- тие в теории цифровой обработки сигналов.
Причины популярности фильтров заключаются в следующем: а) фильтры – простейшая модель преобразования процессов, сигналов.
Когда мы захотим преобразовывать сигналы, то естественно обратить ся именно к фильтрам; б) линейные фильтры являются простейшими устройствами для преобр а- зования цифро вых сигналов; в) цифровые фильтры являются преем никами аналоговых фильтр ов.
Задачи, решаемые с помощью фильтров: а) сглаживание ; б) выделение и подавление отдельных спектральных компонент ; в) обнаружение событий (импульсов, тональных компонент и пр.) ; г) выделение сигнала в шуме ; д) моделирование систем.
Теория и методы конструирования цифровых фильтров детально рассмотрены в многочисленных курсах и учебниках по цифровой обработке сигналов, например книгах [2, 47, 54] и многих других.
К настоящему времени процедуры конструирования многих фильтров автоматизированы.
Однако в конкретных областях фильтры конструируются с учетом специфики сигналов и применении.
В данной главе рассматриваются лишь некоторые фильтры, широко применяемые в ЦОРС.
6.1 Рекурсивные фильтры первого порядка Простейшие рекурсивные фильтры Общий вид рекурсивного фильтра первого порядка определяется соотношением: 𝑦𝑦[𝑖𝑖]=� 𝑏𝑏[𝑘𝑘]𝑥𝑥[𝑖𝑖−𝑘𝑘]−𝑎𝑎𝑦𝑦[𝑖𝑖−1].𝐾𝐾 𝑘𝑘=0 Простейшие фильтры первого порядка описываются тремя коэффициентами, значения которых определяются всего одним параметром (α = 1 – β):58 𝑦𝑦[𝑖𝑖]=𝑏𝑏0𝑥𝑥[𝑖𝑖]+𝑏𝑏1𝑥𝑥[𝑖𝑖−1]−𝑎𝑎𝑦𝑦[𝑖𝑖−1].
Формулы для некоторых простейших фильтров первого порядка приведены в таблице 6.1.
Таблица 6.1 – Простейшие фильтры первого порядка [39] Наименование фильтра Значения коэффициентов b0 b1 a ФНЧ (1- α) = β 0-α = (β- 1) ФНЧ усиленный (1 + α) / 2 =(1- β / 2) (1 + α) / 2 = (1- β / 2)- α =- (1- β) ФВЧ 1- α= β 0 α = (1- β) ФВЧ Конелла (выкалывающий) (1- α/2) = (1- β)/ 2-(1 + α /2) =- (1- β)/2-(1- α) =- β Дифференциатор 1-(1- α) =- β 0 Симметричный дифференциатор (1- α) = β-(1- α) =- β 0 Фильтр экспоненциального сглаживания Фильтр экспоненциального сглаживания (ФЭС) является самым распр о- страненным фильтром в цифровой обработке речевых сигналов благодаря своей простоте.
ФЭС определяется следующими соотношениями : b0 = β, b1 = 0, a = b 0 – 1 = β – 1=- α, где α – коэффициент забывания /усреднения (forgetting/ averaging factor), β – постоянная сглаживания (smoothing factor).
Используются различные формы записи ФЭС: y[i] = β x[i] + α y[i-1], y[i] = (1- β) y[i-1] + β x[i], y[i] = y [i-1] + β (x[i]- y[i-1], y[i] = α y[i-1] + (1- α) x[i] = β x[i] + α y[i-1], y[i] = x [i]- α (x[i]- y[i-1]).
Импульсная реакция ФЭС представляет собой: суммирующее экспоненциальное окно, характеризующее экспоненциальное забывание информации.
Отсюда название – фильтр экспоненциального сглаживания.
Пример Реакция ФЭС на импульсную последовательность с периодом To x[i] = ∑k59 20000 × δ(i – kTo), Fs = 8 кГц показана на рисунке  6.1.
Рисунок 6.1 – Исходный импульсный сигнал (1) и отклики ФЭС: (2) β = 0,0125 и (3) β = 0,0062 Из графиков видно, что уменьшение величины постоянной сглаживания β в два раза приводит к уменьшению амплитуды отклика в момент импульса в два раза и увеличению времени отклика.
Таким образом, постоянная сглаживания β характеризует способность ФЭС сглаживать случайные вариации сигнала.
В случае ступенчатого изменения амплитуды сигнала (процесса) параметр β характеризует время реакции фильтра на это изменение.
Частотная характеристика ФЭС Рассмотрим модель ФЭС и запишем ее z-преобразование: y[i] = α y[i-1] + (1- α) x[i], Y(z) = α z-1 Y(z) + (1- α) X(z).
Отсюда получаем передаточную функцию ФЭС: 𝐻𝐻(𝑧𝑧)=�𝑋𝑋(𝑧𝑧) 𝑋𝑋(𝑧𝑧)�=1−𝛼𝛼 (1−𝛼𝛼𝑧𝑧−1).
Тогда квадрат АЧХ будет иметь вид : 𝐻𝐻2(𝑧𝑧)=𝐻𝐻(𝑧𝑧)𝐻𝐻∗(𝑧𝑧)=(1−𝛼𝛼)2 (1−𝛼𝛼𝑧𝑧−1)(1−𝛼𝛼𝑧𝑧).
Учитывая соотношение {𝑧𝑧=e𝑗𝑗𝑗𝑗} между z-преобразованием и Фурье- преобразованием [47], получим формулу АЧХ в терминах частоты: 𝐻𝐻2(𝑧𝑧)==(1−𝛼𝛼)2 �1−𝛼𝛼𝑒𝑒−𝑗𝑗𝑗𝑗��1−𝛼𝛼𝑒𝑒𝑗𝑗𝑗𝑗�=(1−𝛼𝛼)2 1−2𝛼𝛼𝑐𝑐𝑐𝑐𝑐𝑐 (𝑗𝑗)+𝛼𝛼2.
Значения АЧХ на границах рабочего диапазона частот (нулевой частоте и частоте Найквиста) такие : Ω = 0; cos (0) = 1, H (0) = (1- α)/(1- α) = 1, Ω = π; cos (π) =-1, H (π) = (1- α)/(1 + α).
Таким образом, ФЭС сохраняет амплитуду сигнала на нулевой частоте и подавляет высокие частоты, то есть может применяться как ФНЧ, в частности, Время 2 3 160 для оценки среднего значения процесса или параметра.
Пример Рассмотрим процесс, представляющий собой сумму константы и белого шума: x[i] = C + v [i].
На рисунке 6.2 представлены средние спектры исходного сигнала и сигнала на выходе ФЭС при двух значениях постоянной сглаживания.
Рисунок 6.2 – Спектры сигналов (Fs = 8 кГц): (1) – исходный сигнал, (2) – ФЭС β = 0,0125 (ΔF = 100 Гц), (3) – ФЭС β = 0,0062 (ΔF = 50 Гц) Следует иметь в виду, что ФЭС имеет нелинейную фазовую характер и- стику, то есть сигналы различной частоты будут иметь на выходе ФЭС не толь- ко разную амплитуду, но и разную фазовую задержку.
Для компенсации разл и- чий фазовой задержки следует профильтровать сигнал (фонограмму) в прямом и обратном направлении.
Задание значений параметров ФЭС ФЭС работает как ФНЧ с некоторой эффективной полосой частот и вр е- менем реакции фильтра на изменение характеристики процесса.
Необходимо обеспечить значения этих параметров для произвольной частоты дискретизации Fs.
Связь между коэффициентом сглаживания β и полосой пропускания ΔF ФНЧ выражается следующими соотношениями: β ≈ 2ΔF/ Fs << 1.
Если ΔF = Fn, то β = 1 и y[i] = x[i].
Связь между коэффициентом сглаживания β и постоянной времени (адаптации) фильтра Тa выражается соотношением β ≈ 1/ TaFs.
Если, Ta = T, то y[i] = x[i].
ФЭС является сглаживающим фильтром со скользящим экспоненциальным окном.
Этому окну можно сопоставить эквивалентное прямоугольное окно в Ne отсчетов: 𝑥𝑥𝑎𝑎𝑣𝑣(𝑘𝑘)=1 𝑁𝑁𝑒𝑒∑ 𝑥𝑥[𝑖𝑖]𝑘𝑘 𝑘𝑘−𝑁𝑁𝑒𝑒 =𝑥𝑥𝑎𝑎𝑣𝑣(𝑘𝑘−1)+𝛽𝛽×�𝑥𝑥[𝑘𝑘]−𝑥𝑥𝑎𝑎𝑣𝑣(𝑘𝑘−1)�.
1 2 361 Эквивалентная длина прямоугольного окна равна Ne = 2/ β-1.
Постоя н- ную сглаживания можно вычислить через эквивалентную длину окна: β = 2/(Ne +1) ≈ 2/Ne.
Примеры Ta = 100 мс, Fs=10 кГц => β = 0,001, Ne = 1999.
Ta = 10 мс, Fs =10 кГц = > β = 0.01,  Ne = 199.
ΔF = 50 Гц, Fs =10 кГц => β = 0.01,  Ne = 1999.
Применения ФЭС Оценка среднего значения и удаление постоянной составляющей Поскольку H(0) = 1, то ФЭС сохраняет амплитуду сигнала на нулевой частоте и поэтому может быть использован для оценки текущего среднего значения зашумленного сигнала.
Пример Рассмотрим процесс, представляющий собой сумму константы и белого шума: x[i] =-500 + v [i], σv = 2000, Fs = 8 кГц.
На рисунке  6.3 показана осциллограмма исходного сигнала x[i] и сигнала на выходе ФЭС.
Рисунок 6.3 – Осциллограммы сигнала: (1) – исходный сигнал, (2) – ФЭС ΔF = 50 Гц, (3) – ФЭС ΔF = 10 Гц Графики показывают, что на выходе ФЭС формируется оценка среднего значения (-500).
Вариативность оценки зависит от коэффициента сглаживания.
Удаление медленно меняющейся постоянной составляющей сигнала (DC cut) Модель сигнала : y[i] = a[i] + x[i], где a[i] – тренд.
Оценка тренда : â[i] = â[i-1] + β (y[i] – â[i-1]), β <<1.
Удаление тренда: x[i] = y[i] – â[i].
1 2 362 Оценка средневыпрямленного значения фона Задача заключается в следующем.
Имеем РС в шуме.
Необходимо оценить средний уровень амплитуд фонового шума, например средневыпрямленную амплитуду.
Средневыпрямленное значение сигнала (огибающая амплитуд) вычисляется с помощью ФЭС: Mx[i+1] = Mx [i] + β (|x[i]| – Mx [i]).
На интервалах шума алгоритм дает оценку огибающей амплитуд фона, на интервалах речи – огибающую РС.
Необходимо замедлить обновление оценки огибающей на интервалах, где амплитуды РС существенно превосходит амплитуду фона.
Это может быть осуществлено с помощью управления коэффициентом сглаживания.
Если |x[i]| >> Mx[i], то β[i] = βo × (Mx[i]/|x[i]|).
В этом случае амплитудная огибающая на интервалах РС будет обновляться замедленно: Mx[i+1] = Mx [i] (1 + βo), βo<< 1.
Результат работы обычного ФЭС и ФЭС с управляемым коэффициентом сглаживания представлен на рисунке 6.4.
Рисунок 6.4 – Осциллограмма и средневыпрямленные значения сигнала: (1) – исходный сигнал, (2) – ФЭС Ta = 10 мс, (3) – ФЭС с управляемым коэффициентом Ta =1 с Интегратор Рекурсивный алгоритм интегратора : 𝑦𝑦[𝑖𝑖]=𝑥𝑥[𝑖𝑖]+(1−𝛽𝛽)𝑦𝑦[𝑖𝑖−1]=𝑦𝑦[𝑖𝑖−1]+𝛽𝛽�𝑥𝑥[𝑖𝑖] 𝛽𝛽−𝑦𝑦[𝑖𝑖−1]�, где β<<1 – коэффициент интегрирования входного сигнала.
Из приведенной формулы следует, что интегратор – это ФЭС с усилением.
Усиление обратно пропорционально постоянной сглаживания, то есть памяти фильтра.
Таким образом, величина накопленного сигнала будет возрастать с ростом памяти фильтра.
1 2 363 Рассмотрим произвольный рекурсивный фильтр 1-го порядка (0 < a < 1): 𝑦𝑦[𝑖𝑖]=𝑏𝑏𝑥𝑥[𝑖𝑖]+𝑎𝑎𝑦𝑦[𝑖𝑖−1]=𝑦𝑦[𝑖𝑖−1]+(1−𝑎𝑎)�𝑏𝑏 1−𝑎𝑎𝑥𝑥[𝑖𝑖]−𝑦𝑦[𝑖𝑖−1]�= = y[i-1] + (1- a)(g x[i]- y[i-1]).
Из приведенной формулы следует, что любой рекурсивный фильтр 1-го порядка можно свести к ФЭС с усилением.
Представим рекурсивный фильтр 1-го порядка как усилитель с обратной связью [ 68]: 𝑦𝑦[𝑖𝑖]=𝑏𝑏×�𝑥𝑥[𝑖𝑖]+𝑎𝑎 𝑏𝑏𝑦𝑦[𝑖𝑖−1]�=𝑏𝑏×(𝑥𝑥[𝑖𝑖]+𝑔𝑔×𝑦𝑦[𝑖𝑖−1]).
Коэффициент g описывает обратную связь, то есть использование части выхода в качестве входа в более позднее время.
Выход фильтра есть сумма двух входов, умноженная на коэффициент усиления b. Мы имеем : (x + gy) × b = y. Тогда y = bx/ (1 – gb).
Пусть b =-109, g = 1/10.
Тогда y =-10 x/(1 + 10-8) ≈-10 x. Таким образом, выходной сигнал равен входному, умноженному на минус 10, и не зависит от небольших изменений в характеристиках усилителя (т.е. нечувствителен к неточному значению коэффициента усиления).
6.2 Дифференцирующие фильтры Основное назначение дифференцирующих фильтров (ДФ) – контрастирование и детектирование коротких временных событий.
Соотношения для простейших ДФ приведены в таблице 6.2.
Таблица 6.2 – Простейшие фильтры первой производной Временные соотношения z-преобразование передаточной функции d[i] = x[i] – β x[i-1] H(z) = (1- β z-1) d[i] = 0,5 (x[i] – x[i-1]) H(z) = 0,5 (1- z-1) d[i] = x[i]- (x[i+1] + x[i-1])/2 H(z) = z (z-1 – 0,5 (1- z-2) d[i] = (2x[i+2] + x[i+1]- x[i-1] – 2x[i-2])/10 H(z) = 0,1 (2z2 + z – z-1 – 2z-2) d[i] = (x[i] – x[i-1]) + (1 –β) d[i-1] H(z) = (1 – z-1) / (1 – (1 – β) z-1)) d[i]=x[i+1]-x[i-1]+2(x[i+2]-x[i-2])+ ɑ d[i-1] H(z) = 0,1z4 (2 +z-1 –z-3 –2z-4)/(1 – ɑ z-1) 64 Поскольку дифференцирование приводит к усилению шумов, спектр ко- торых располагается преимущественно в диапазоне высоких частот, то для ограничения частотной полосы ДФ используется ослабление ВЧ компонент выхо-да дифференцирующего фильтра, например с помощью ФЭС.
Комбинация ДФ и ФЭС представляет собой усреднение разностей, что приводит к ослаблению влияния медленных изменений параметра.
Такой фильтр аналогичен фильтру высоких частот.
На рисунке  6.5 представлены спектры сигналов на выходе ДФ и комб и- нации ДФ и ФЭС.
Рисунок 6.5 – Спектр белого шума и сигналов на выходе фильтров: (1) – БШ, (2) – совместного ФЭС и ДФ, (3) – ФЭС, (4) – ДФ Дифференциальные фильтры детально рассмотрены в книге Хэмминга [69].
Операция дифференцирования в некотором смысле является обратной операции экспоненциального сглаживания.
Рассмотрим ФЭС : y[i] = (1- β) y[i-1] + β x[i] = ɑ y [i-1] + β x[i].
Отсюда получаем формулу восстановления исходного сигнала с помощью дифференцирующего фильтра : 𝑥𝑥[𝑖𝑖]=1 𝛽𝛽(𝑦𝑦[𝑖𝑖]−𝛼𝛼𝑦𝑦[𝑖𝑖−1]).
Аналогично, если мы применим операцию интегрирования к дифференцированному сигналу y[i] = x[i] – ɑ x[i-1], то сможем восстановить исходный сигнал x[i] = y[i] + ɑ x[i-1].
6.3 Сглаживающие КИХ-фильтры Фильтр экспоненциального сглаживания является простейшим сглаживающим фильтром и фильтром низких частот.
Недостатком этого фильтра является неравномерная по частоте фазовая задержка.
От этого недостатка свободны 4 2 3 1 Время КИХ-фильтры с симметричной импульсной характеристикой.
Сглаживающие КИХ-фильтры также одновременно является фильтрами низких частот.
Ра с- смотрим физический смысл одного из сглаживающих КИХ- фильтров.
Предположим, что на интервале [i-M…i+M ] мы аппроксимируем последовательность отсчетов x[ i] с помощью многочлена второй степени: x[m] = A + Bm + Cm ². Найдем коэффициенты из условия минимума суммы квадратов остато ч- ных ошибок : 𝑄𝑄(𝐴𝐴,𝐵𝐵,𝐶𝐶) = � [𝑥𝑥[𝑚𝑚]–(𝐴𝐴+ 𝐵𝐵𝑚𝑚 + 𝐶𝐶 𝑚𝑚²)]²𝑅𝑅 𝑚𝑚 = −𝑅𝑅  = = <[x[m]– (A+ Bm + C m²)]²> M, где< > M – обозначение операции суммирования: (∑m =-M, M).
min Q (A, B, C)  dQ/dA=0, dQ/dB=0, dQ/dC=0 → A<1> + B <m> + C <m²> = < x[m]>, A<m> + B <m²> + C < m³> = <m x[m]>, A<m²> + B<m³> + C <m4> = <m² x[m]>.
Взяв симметричный интервал точек {-M,…-1, 0, 1, …M }, обращаем в нули суммы нечетных степеней.
Решив систему уравнений, получим : A = (<m4><x>- <m²>< m² x[m]>) /(<1><m4>- <m²>²).
Тогда сглаженное значение последовательности x[m] в центральной точке m = 0 равно : ẋ[0]= 𝐴𝐴 = � ℎ[𝑚𝑚]𝑥𝑥[𝑚𝑚]𝑅𝑅 𝑚𝑚=−𝑅𝑅.
То есть сглаженное значение вычисляется как КИХ-фильтрация входного сигнала.
Для произвольного момента времени имеем: ẋ[𝑖𝑖] = � ℎ[𝑚𝑚] 𝑥𝑥[𝑖𝑖 − 𝑚𝑚]𝑅𝑅 𝑚𝑚 = −𝑅𝑅= 𝑥𝑥[𝑖𝑖]∗ℎ[𝑚𝑚].
Ниже приведены коэффициенты некоторых фильтров, построенные на основе этих соотношений [ 69]: а) для полинома 1-й степени: M = 1, h[m] = ¼[1, 2, 1]; б) для полиномов 2-й степени: M = 2, h[ m] = 1/35[-3, 12, 17, 12,-3]; M = 3, h[ m] = 1/21[-2, 3, 6, 7, 6, 3-2]; M = 4, h[ m] = 1/231[-21, 14, 39, 54, 59, 54, 39, 14,-21]; M = 5, h[ m] = 1/429[-36, 9, 44, 69, 84, 89, 84, 69, 44, 9,-36]; в) для полинома 4-й степени: M = 3, h[m] = 1/231[5,-30, 75, 131, 75,-30, 5].66 Порядок сглаживающего полинома и ширина окна определяют крутизну переходной области (границы полосы пропускания) и глубину подавления вне полосы пропускания.
Между сглаживающими КИХ-фильтрами (ФНЧ) и КИХ- фильтрами высо- ких частот существует простая мнемоническая связь: ФВЧ = 1 – ФНЧ, ФНЧ = 1 – ФВЧ.
При этом для коэффициентов фильтров выполняются следующие соо т- ношения: ФНЧ: ∑ h(n) = 1, ФВЧ: ∑ h(n) = 0.
Примеры ФНЧ = [½, ½ ] ↔ ФВЧ = [1, 0] – [½, ½ ] = [½,-½], ФНЧ = ⅓ [1, 1, 1 ] ↔ ФВЧ = [0, 1, 0 ] – ⅓ [1, 1, 1 ] = ⅓ [1,-2, 1].
6.4 Полосовые фильтры и фильтры-гребенки Поскольку акустические сигналы часто имеют тональную или гармоническую структуру, то в ряде приложений стоит задача выделения или, напротив, подавления сигнала в узкой полосе частот или для ряда гармоник.
Простейшими фильтрами выделения или подавления тонального сигнала являются полосовые фильтры второго порядка: резонансный фильтр и фильтр-пробка.
Полосовые фильтры второго порядка Резонансный щелевой фильтр (Slot, One-formant filter): 𝑦𝑦[𝑖𝑖]=𝐴𝐴×𝑥𝑥[𝑖𝑖]+𝐵𝐵×𝑦𝑦[𝑖𝑖−1]+𝐶𝐶×𝑦𝑦[𝑖𝑖−2].
Фильтр-пробка (Notch, One-zero filter): 𝑦𝑦[𝑖𝑖]=𝐴𝐴1×𝑥𝑥[𝑖𝑖]+𝐵𝐵1×𝑦𝑦[𝑖𝑖−1]+𝐶𝐶1×𝑦𝑦[𝑖𝑖−2], где C =-exp(- 2π ΔF/Fs), B = 2 exp (-2π ΔF/А)×cos(2π Fo/Fs), A = 1- B – C, A1 = 1/A, B1 =-B/A, C1 =-C/A, ΔF – ширина частотной полосы полосового фильтра, Fo – центральная частота полосового фильтра, Fs – частота дискретизации. 67 Пример Графики АЧХ щелевого фильтра и фильтра-пробки приведены на рису н- ке 6.6.
Рисунок 6.6 – А ЧХ фильтров: (1) – средний спектр сигнал а (2) – спектр сигнала на выходе фильтра пробки, (3) – спектр сигнала на выходе щелевого фильтра Недостаток фильтра-пробки – большая ширина полосы заграждения, щ е- левого фильтра – большая ширина полоса пропускания.
Фильтры-гребенки Многие акустические (в том числе речевые) и электрические сигналы представляют собой периодически повторяющиеся импульсы.
Спектры таких сигналов является линейчатым и представляют собой последовательность максимумов (гармоник), повторяющихся с шагом (частотой основного тона) Fo об- ратно пропорциональным периоду импульсов (основного тона) To: Fn = n ×Fo = n/To, n= 0, 1, 2,… Для выделения или подавления таких сигналов используют КИХ- или БИХ-фильтры-гребенки (comb-filters).
Соотношения для простейших фильтров- гребенок приведены в таблице 6.4, где использованы следующие обозначения: Zn – частоты минимумов АЧХ, Mn – частоты ма ксимумов АЧХ, T = 1/ Fs, Fo = 1/KT = Fs /K – частота ОТ гармоник.
Физическая интерпретация фильтров-гребенок заключается в том, что на выход через фильтр проходят сигналы, оказавшиеся «в фазе», и подавляются сигналы, оказавшиеся «в противофазе».
Остальные компоненты сигнала, с разными фазами, в результате микширования частично ослабляются.
2 1 368 Таблица 6.4 – Фильтры-гребенки и их параметры Формулы фильтров Нули (Zn) и максимумы (Mn) АЧХ n = 0, 1, … y[i] = x[i] + x[i-K] нечетный (Odd comb) Zn = Fs × (1/2 + n) /K = (Fs/2K, 3Fs/2K, …) Mn = n×Fs/K = (0, Fs/K, 2Fs/K…) y[i] = x[i] – x[i-K] четный (Even comb) Zn = n×Fs/K = (0, Fs/K, 2Fs/K …) Mn = Fs × (1/2 + n) /K = (Fs/2K, Fs3/2K, …) y[i] = x[i] + g y [i-K], 0 < g < 1 Mn = n×Fs/K = (0, Fs/K, 2Fs/K…) Многополосный щелевой (Multiple slot) y[i] = x[i] – g y[i-K], 0 <g< 1 Zn =n×Fs/K = (0, Fs/K, 2Fs/K…) Многополосный запирающий (Multiple notch) Временной отклик КИХ-фильтра-гребенки равен времени задержки одно- го из сигналов.
Временной и частотный отклик БИХ-фильтра зависит от врем е- ни задержки и величины коэффициента g. Чем ближе значение коэффициента к единице, тем больше время реакции фильтра.
При некоторых обстоятельствах, если существует достаточная задержка сигнала при возвращении с выхода на вход, система начинает осциллировать.
Такие ситуации могут возникнуть в больших аудиториях, которые имеют микрофон, сигнал с которого через выход усилителя поступает на акустические колонки системы.
Звук акустической колонки задерживается в пространстве на некоторое время, поступает на микрофон и далее после усиления снова поступает на колонку.
В результате в аудитории возникает характерный резкий шум.
Частота колебаний зависит от характеристик помещения, микрофона, колонки и усилителя.
Таким образом, при использовании систем с обратной связью есть риск возникновения самовозбуждения системы.
Задание параметров фильтра-гребенки Коэффициент g определяет степень ослабления основного тона.
Если g=1, то фильтр пропускает все гармоники основного тона (Fo), и подавляет нечетные гармоники n×Fo/2, если g=-1, фильтр пропускает нечетные гармоники основного тона n×Fo/2, подавляет четные гармоники.
Допустим необходимо подавить гармоники основного тона с частотой Fo, то есть нули должны быть на частотах n×Fo, n=0, 1, 2, … Тогда модель КИХ- фильтра-гребенки должна быть такой: y[i] = x [i]- g x[i-K], g>0.
Задержка K определяющая частоту следования максимумов и минимумов фильтра, задается на основе следующего соотношения: K = round (Fs/Fo).69 Рекурсивный фильтр-гребенка позволяет по сигналу на выходе КИХ- фильтра-гребенки восстановить сигнал на входе: x[i] = y [i] + g x[i-K].
Аналогично можно восстановить сигнал на входе БИХ-фильтра-гребенки: x[i] = y [i] + g y[i-K].
Ширина максимумов КИХ-фильтра равна ширине минимумов.
Минимумы (нули) являются глубокими, поэтому этот фильтр можно эффективно и с- пользовать для подавления гармоник.
В БИХ-фильтре более эффективно достигается выделение гармоник.
Пример 1 Рассмотрим КИХ-фильтры, аппроксимирующие гребенку гармоник ОТ речевого сигнала в заданном интервале Fo=100 –330 Гц.
Пусть Fs = 10 кГц, тогда K = 10000/(100 …330) = 100…33.
Таким образом, длина фильтра соответствует длине обычно применяемых фильтров.
Пример 2 Fs = 10 кГц, Fo = 500 Гц.
На рисунке 6.7 показаны характеристики КИХ- фильтров выделения и подавления гармоник ОТ.
Рисунок 6.7 – Средние спектры белого шума: (1) – до фильтрации, (2) – после фильтра подавления четных гармоник ОТ, (3) – после фильтра подавления нечетных гармоник ОТ Обобщение Пусть сигналы поступают на два микрофона с временным сдвигом ΔT.
Тогда у сигнала Y+(t) = X (t) + X (t-ΔT) нули будут на частотах Zn = (1/2 + n)/ΔT, n= 0, 1, 2,…, 2 3 1 Axx, дБ Гц70 а для сигнала Y-(t) = X (t)- X(t-ΔT) нули будут на частотах Zn = n/ΔT.
Положение нулей не зависит от частоты дискретизации.
Пример Данный пример демонстрирует неожиданный эффект микширования сиг- налов диктофона «Гном» при записи базы данных для задачи распознавания р е- чи с использованием внутренних микрофонов диктофона.
Для улучшения качества фонограммы записанные сигналы правого и левого каналов сложили.
Однако в результате качество распознавания неожиданно ухудшилось.
Причиной оказался комб-эффект, возникший из-за того, что диктор располагался на ра з- ном расстоянии от микрофонов, и между сигналами возникала небольшая временная задержка.
Рисунок 6.8 иллюстрирует эт от эффект.
На рисунке представлены средние спектры сигналов микрофонов и средний спектр микшированного сигнала.
Рисунок 6.8 – Средние спектры речи: (1) и (2) – сигналы x 1[i] и x2[i] микрофонов диктофона, (3) – сигнал 𝑦𝑦 [𝑖𝑖]=1 2(𝑥𝑥1[𝑖𝑖]+𝑥𝑥2[𝑖𝑖]) Из рисунка видно, что средние спектры сигналов микрофонов приблизительно одинаковые, а средний спектр микшированного сигнала имеет знач и- тельный провал в интервале 3000 –4000 Гц.
Таким образом, микширование сигналов привело к искажению результирующего сигнала.
Применение фильтров-гребенок Основными применениями фильтров-гребенок является детектирование гармонических сигналов и подавление гармонических помех.
Например, филь т- 3 1 2 Гц Axx, дБ71 ры-гребенки могут применяться для выделения РС в присутствии периодических импульсных наводок с известной фиксированной частотой.
Основным достоинством фильтров является простота их реализации.
Основной недостаток КИХ-фильтров – большая ширина заграждения, что приводит к подавлению значительной части РС.
Основной недостаток БИХ-фильтров – большое время реакции (затянутый во времени отклик).
6.5 Фильтры в частотной области Речевые сигналы занимают широкий спектральный диапазон (несколько октав), поэтому во многих случаях необходимо в разных на разных частотах применять разные правила обработки.
Это удобно делать с помощью фильтрации сигналов в частотной области.
Другим достоинством обработки в частотной области является ее вычислительная эффективность.
Частотная фильтрация — это процесс обработки звукового сигнала с целью изменения спектрального состава сигнала.
Задачами такой обработки могут быть: амплитудно-частотная коррекция сигнала (усиление или ослабление о т- дельных частотных составляющих); полное подавление спектра сигнала или шумов в определенной полосе частот.
Рассмотри м базовые алгоритмы обработки в частотной области.
Принципы фильтрации в частотной области В некоторых случаях АЧХ-фильтра H(f) задана лишь в частотной области, а фильтрацию необходимо проводить во временной области.
Тогда импульсная характеристика фильтра может быть вычислена на основе соотношения : h[i] = FT[H(f)].
Свойства H(f) и h[i] связаны следующими соотношениями: H(f) – вещественная и симметричная: Im{H(f)} = 0, Re{H(f)} = Re{H(-f)}  h [i] симметричная, вещественная.
H(f) – комплексно сопряженная: Im{H(f)} =- Im{H(-f)}, Re{H(f)} = Re{H(f)}  h [i] вещественная (но не симметричная).
Фильтрация в частотной области реализуется следующим образом.
Си г- нал сегментируется на кадры, каждый из которых последовательно преобразуется в комплексный спектр.
Комплексные спектры поэлементно умножаются на коэффициенты фильтра, после чего спектры преобразуются в последовательность кадров результирующего сигнала: X(f, k) = FT{X[k]},72 Y(f, k) = H (f) X(f, k), Y[k] = IFT{Y(f, k)}, где k – индекс кадров, f – индекс частот.
Комплексные спектры сигнала преобразуются в кадры выходного сигнала, из которых «собирается» сигнал на выходе фильтра.
Сигнал на выходе фильтра будет вещественным, поскольку выполняются следующие соотношения: X[k] – вещественная  Re{X (f, k)} – симметричная, Im{X(f, k)} – антисимметричная, H(f) – вещественная, Re{H (f)} – симметричная, Im{H(f)} – антисимметричная.
Тогда : Re{Y(f, k)} – симметричная, Im{Y(f, k)} – антисимметричная  y[i] вещественный (но не симметричный).
Отметим еще одно важное свойство частотного фильтра.
В случае, когда АЧХ фильтра является вещественной функцией, фаза выходного сигнала совпа-дает с фазой входного: 𝑟𝑟𝑔𝑔�𝛷𝛷𝑦𝑦(𝑓𝑓)�=�𝐼𝐼𝑚𝑚{𝑋𝑋(𝑓𝑓)} 𝑅𝑅𝑒𝑒{𝑋𝑋(𝑓𝑓)}�=�𝐻𝐻(𝑓𝑓)𝐼𝐼𝑚𝑚{𝑋𝑋(𝑓𝑓)} 𝐻𝐻(𝑓𝑓)𝑅𝑅𝑒𝑒{𝑋𝑋(𝑓𝑓)}�=�𝐼𝐼𝑚𝑚{𝑋𝑋(𝑓𝑓)} 𝑅𝑅𝑒𝑒{𝑋𝑋(𝑓𝑓)}�=𝑟𝑟𝑔𝑔[𝛷𝛷𝑥𝑥(𝑓𝑓)].
Явление Гиббса В случае покадровой обработки сигнала в частотной области кадр входного сигнала преобразуется фильтром в кадр выходного сигнала.
Однако временной отклик фильтра может не укладываться в один кадр.
В этом случае на границах кадров обработанного сигнала возникают скачки амплитуды.
Это называется явлением Гиббса.
Детали описаны, например, в книгах Хемминга [39, 69].
На слух этот эффект проявляется как периодический стук.
Рисунок 6.9 – Осциллограмма с явлением Гиббса
На рисунке 6.9 приведен фрагмент осциллограммы, на которой проявляется явление Гиббса.
Ослабление эффекта Гиббса достигается с помощью сглаживания частотной характеристики фильтра (когда это возможно) либо с помощью метод а пересечения и суммирования (overlap-add method, OLA) или пересечения и накопления (overlap-save method).
Описание алгоритма пересечения и суммирования приведено, например, в [37, 38]. 
Вопросы и упражнения 
1.Докажите что, если импульсная реакция h[k] симметричная, то передаточная функция H(f) вещественная.
2.Выведите формулу передаточной функции дифференцирующего фильтра.
3.Выведите формулу передаточной функции интегратора с утечкой (интегрирующего фильтра).
4.Выведите формулу АЧХ ФЭС.
5.Выведите формулу ФЧХ ФЭС. Как фазовая задержка ФЭС зависит от частоты?
6.Докажите, что при фильтрации вещественного сигнала в частотной области выходной сигнал также будет вещественным, если импульсная характеристика фильтра h [k], по которой с помощью ДПФ построена передаточная функция H(f), является вещественной.
7.Определите, с помощью какого фильтра-гребенки можно подавить то-нальную помеху с частотами 250, 350, 450,… Гц дискретного сигнала с Fs = 16 кГц.
8.Докажите, что ФЭС является линейным фильтром.
9. Докажите, что для КИХ-фильтров ФВЧ: ∑ k h[k] = 0, ФНЧ: ∑ k h[k] = 1.
10.Частота дискретизации сигнала равна Fs.
Усредненная характеристика вычисляется с использованием алгоритма экспоненциального сглаживания на окнах размера N, следующих с шагом L. Чему должен быть равен коэффициент сглаживания, если мы хотим оценивать среднюю характеристику на временном интервале Ta ?
11.Частота дискретизации сигнала равна 16 кГц.
Через каждые L отсчетов измеряется мгновенное значение параметра P[k], после чего мгновенные значения усредняются с помощью алгоритма экспоненциального сглаживания: Pa[k] = Pa [k-1] + β [P[k]- Pa[k-1]].
Какова величина параметра сглаживания β, если постоянная времени сглаживания Ta составляет 1с? 
ЗАКЛЮЧЕНИЕ 
Речевые технологии продолжают оставаться активно развивающейся областью, в которой трудятся большие коллективы ученых и инженеров.
Каждый год в этой области разрабатываются новые методы, алгоритмы и устройства и публикуется несколько книг по различным вопросам РТ. Цифровая обработка речевых сигналов как элемент РТ не является исключением.
ЦОРС – это одна из активно развивающихся областей речевых технологий.
Остается большое число нерешенных проблем, в частности, связанных с задачами дистанционного распознавания речи, человеко-машинного взаимодействия, слухом роботов, многоканальной обработки сигналов микрофонных решеток и многие другие.
Интенсивно развивающимся направлением речевых технологий на данном этапе являются методы на основе нейронных сетей.
Наряду с этим направлением интенсивно развиваются технологии пространственной фильтрации РС с использованием микрофонных решеток, методы нелинейной фильтрации и ряд других.
Все эти направления базируются на цифровой обработке сигналов.
Описанные в пособии характеристики и алгоритмы цифровой обработки сигналов могут быть полезны для работы не только с речевыми сигналами, но и в других областях, использующих методы анализа и обработки цифровых сигналов.
Ограниченный объем пособия не позволил рассмотреть углубленно многие важные вопросы ЦОРС.
Некоторые из них (по материалам других модулей курса) мы планируем осветить в следующих изданиях.
Однако большую часть тематики ЦОРС придется в дальнейшем осваивать самостоятельно.
В заключение хочу дать совет.
Столкнувшись с необходимостью решить какую-то проблему, попытайтесь сначала предложить ваше собственное реше-ние, а после обращайтесь к другим источникам.
Это полезно по трем причинам.
Во-первых, это развивает ваши творческие способности.
Во-вторых, это нередко помогает понять и оценить идеи других авторов.
В-третьих, наконец, ваша собственная идея может оказаться более плодотворной, чем те, что вы найдете у других.
Желаю творческих успехов!
ПРИЛОЖЕНИЕ А ПРОФЕССИОНАЛЬНЫЕ СООБЩЕСТВА В ОБЛАСТИ РЕЧЕВЫХ ТЕХНОЛОГИЙ 
Наименование ресурса Адрес ресурса в сети Интернет 
DSP groups: + SP processing http://www.dsprelated.com http:/docs.yahoo.com/info/term 
Defence Advanced Research Programs Agency (DAPRA) www.darpa.mil 
International Speech Communication Association (ISCA) www.isca-speech.org 
Acoustical Society of America (ASA) www.acousticalsociety.org 
Applied Voice Input/Output Society (AVIOS) www.avios.org 
Institute of Electrical and Electronics Engineers (IEEE) www.ieee.org 
Human Language Technologies Agency (HLT) www.hltcentral.org 
HMM Tool Kit Software (HTK) www.htk.eng.com.ac.uk 
IEEE Signal Processing Society (IEEE SPS) www.signalprocessingsociety.org 
Audio Engineering Society (AES) www.aes.org 
European Association for Speech, Signal, and Image Processing (EURASIP) www.eurasip.org 
European Language Resources Association (ERLA) www.icp.inpq.fr/ERLA 
European Acoustics Association (EAA) www.eaa-fenestra.org Forensic analysis of audio evidence www.ic.orni.gov 
International Computer Science Institute (ISCI) www.icsi.berkeley.edu 
IEEE Signal Processing Society (IEEE SPS) www.signalprocessingsociety.org
ПРИЛОЖЕНИЕ Б СИСТЕМЫ СТАНДАРТИЗАЦИИ 
Наименование ресурса Адрес ресурса в сети Интернет 
РОССТАНДАРТ Федеральное агентство по техническому регулированию и метрологии https://www.rostandart.ru https ://www.gost.ru 
ITU International Telecommunication Unite www.itu.int 
ISO International Organization for Standardization www.iso.org 
ANSI American National Standards Institute www.ansi.org 
NIST National Institute of Standards and Technology www.nist.gov 
ETSI European Telecommunications Standards Institute http://www.etsi.org http://portal.etsi.org 
DIN Deutsches Institut für Normung https://www.din.de 
COCOSDA The International Committee for the Co-ordination and Standardization of Speech Databases and Assessment Techniques www.cocosda.org
MPEG Moving Picture Experts Group https://mpeg.chiariglione.org 
AES Standards Committee http://www.aes.org/ standards/
IEC International Electrotechnical Commission Международная электротехническая комиссия (МЭК) https://www.iec.ch/homepage
ПРИЛОЖЕНИЕ В ОСНОВНЫЕ ЖУРНАЛЫ ПО РЕЧЕВЫМ ТЕХНОЛОГИЯМ 
IEEE Proceedings IEEE Transactions on Signal Processing (IEEE Signal Processing Society) 
IEEE Transactions on Acoustics Speech and Signal Processing 
IEEE Transactions on Speech and Audio Processing 
IEEE Journal of Selected Topics in Signal Processing 
IEEE Acoustics, Speech, and Signal Processing Magazine 
IEEE Transactions on Audio, Speech, and Language Processing 
IEEE Transactions on Information Forensics and Security 
IEEE Transactions on Image Processing 
IEEE Transactions on Multimedia 
IEEE Journal on Machine Learning Applications in Speech Journal of the Acoustical Society of America 
(JOSA) EURASIP Journal on Advances in Signal Processing Speech Communication 
(EURASIP and the ISCA) EURASIP Journal on Audio, Speech, and Music Processing Journal of the Audio Engineering Society 
(AES) Journal of Signal Processing (Japan Advanced Institute of Science and Technology) 
Acta Acustuca (The European Acoustics Association) Applied Ac oustics International Journal of Computer Science International Journal of Speech Technology Information and communication technologies and services Circuits, Systems, and Signal Processing (Springer) Acoustic Science & Technology (The Acoustical Society of Japan)
Журналы на русском языке: 
Речевые технологии (уклон в лингвистику).
Труды СПИИРАН (Санкт-Петербургский институт информатики и автоматиз а- ции Российской академии наук).
Цифровая обработка сигналов (статьи по речевым сигналам редко).
Научно-технический вестник информационных технологий, механики и оптики (статьи по речевым сигналам редко).
Известия вузов.
Приборостроение (статьи по речевым сигналам редко).
Радиотехника (статьи по речевым сигналам редко).
ПРИЛОЖЕНИЕ Г ОСНОВНЫЕ КОНФЕРЕНЦИИ ПО РЕЧЕВЫМ ТЕХНОЛОГИЯМ 
INTERSPEECH International Conference Acoustic Signal and Speech Processing (
ICASSP) International Convention of the Audio Engineering Society 
(AES) EURASIP conferences European Signal Processing Conference 
(EUSIPCO) SIGNAL PROCESSING Military Speech Technology Conferences International Workshop on Acoustic Signal Enhancement 
(IWAENC) International Workshop on Acoustic Echo and Noise Control International Conference Speech and Language Processing 
(ICSLP) International Congress on Sound and Vibration 
(ICSV) SpeechTEK International Conference on Signals and Systems Neural Information Processing Systems 
(NIPS) International Conference on Auditory Displays International Conference on Digital Audio Effects International Conference on Spatial Audio Digital Audio Processing for Loudspeakers and Headphones Конференции в Российской Федерации Цифровая обработка сигналов, организует Институт проблем управления (Мо- сква) Speech and Computer (SPECOM), организует СПИИРАН (Санкт-Петербург) 
СПИСОК ИСПОЛЬЗОВАННЫ Х ИСТОЧНИКОВ 
1.Аграновский, А. В. Теоретические аспекты алгоритмов обработки и классификации речевых сигналов / А. В. Аграновский, Д. А. Леднов. – М.: Радио и связь, 2004. – 164 с. 
2. Айфичер Э., Джервис Б. Цифровая обработка сигналов. Практический подход // М.:, Изд. дом «Вильямс», 2004. – 992 с. 
3. Андерсон Т. Статистический анализ временных рядов. – М., Мир, 1976.
4. Ахмад, Х. М., Жирков В. Ф. Введение в цифровую обработку речевых сигналов: учеб. пособие // Владим. гос. ун-т. – Владимир: Изд-во Владим. гос. ун-та, 2007. – 192 с. 
5. Бендатт Дж., Пирсон А. Измерение и анализ случайных процессов // М.: Мир, 1974.
6. Бендатт Дж., Пирсон А. Применения корреляционного и спектрального анализа // М.: Мир, 1983.
7. Бендатт Дж., Пирсон А. Прикладной анализ случайных данных // М.: Мир, 1989. – 540 с. 
8. Богоявленский С.Б. Теоретические и практические аспекты принятия решений в условиях неопределенности и риска. – СПб. : Изд-во СПбГЭУ, 2014.
9. Бокс Дж., Дженкинс Г. Анализ временных рядов, прогноз и управление. М., Мир, 1974, вып.1.
10. Болл Р. М. и др. Руководство по биометрии // М.: Техносфера, 2007. – 368 с. 
11. Брэгг У. Мир света. Мир звука // М.: Наука, 1967. — 336 с. 
12. Винцюк Т.К., Анализ, распознавание и интерпретация речевых сигналов — Киев: Наукова думка, 1987. – 264 стр. 
13. Васильев В., Гуров И. Компьютерная обработка сигналов в приложении к интерферометрическим системам – СПб.: БВХ-Санкт-Петербург, 1998. – 240 с. 
14. Борискевич А.А. Цифровая обработка речи и изображений. Минск, 2010. [Электронный ресурс]: URL: http://gendocs.ru/v35045/?cc=8 (дата обра щения 15.05.2020) 
15. Гоулд Б., Рейдер Ч. Цифровая обработка сигналов // М.: Сов. Радио, 1973. — 367 с.82 
16. Горшков Ю. Г. Обработка речевых и акустических биомедицинских сигналов на основе вейвлето в. 2017 
17. ГОСТ 8.417-81. Государственная система обеспечения единства измерений. Единицы величин 
18. Гроп Д. Методы идентификации систем // М.: Мир, 1979. – 302 с. 
19. Дворянкин С.В. Цифровая шумоочистка аудиоинформации. Под ред. А.В. Петракова. // М.: ИП РадиоСофт, 2011. – 208 с. 
20. Дегтяров Н.П. Параметрические и информационное описание речевых сигналов. – Минск, 2003 – 216 с. 
21. Дженкинс Г., Ваттс Д. Спектральный анализ и его приложения // М.: Мир, 1971. Вып. 1. – 316 с. 
22. Дьяконов В. П., Абраменкова И. MATLAB. Обработка сигналов и изображений. Специальный справочник // СПб: Питер, 2002.
23. Кирн П. Цифровой звук. Реальный мир.// М.: «Изд. дом Вильямс», 2008. – 720 с. 
24. Ковалгин Ю.А. Вологдин Э.И. Цифровое кодирование звуковых сигналов. – СПб. : Корона-принт, 2004. – 240с 
25. Корн Г., Корн Т. Справочник по математике для научных работников и инженеров, – М.: Мир, 1970.
26. Клюкин И. И. У дивительный мир звука // Л.: Судостроение, 1978.
27.Ли У. А. Методы авт оматического распознавания речи. М., Мир, 1983.
28.Лобанов Б.М., Цирульник Л.И. Компьютерный синтез и клонирование речи. – Минск: «Белорусская наука», 2008.
29.Лукин А. Введение в цифровую обработку сигналов (математические основы) // Лаборатория компьютерной графики и мультимедиа, МГУ, 2007.
30.Макс Ж. Методы и техника обработки сигналов при физических измерениях. В 2-х томах – М.: Мир, 1983.
31. Маркел Дж. Д., Грей А. Х. Линейное предсказание речи. – М.: Связь, 1980. – 308 с. 
32. Марпл С. Л. Цифровой спектральный анализ и его применение. – М.: Мир, 1990.83 
33. Матвеев Ю.Н., Симончик К.К., Тропченко А.Ю., Хитров М.В. Цифровая обработка сигналов. Учебное пособие // СПб. : СПбНИУ ИТМО, 2013. – 166 с. 
34. Михайлов, В. Г. Измерение параметров речи / В. Г. Михайлов, Л. В. Златоустова; под ред. М. А. Сапожкова. – М.: Радио и связь, 1979. – 416 с. 
35. Мороз Г. Компьютерная фонетика. Как пользоваться PRAAT (2017). [Электронный ресурс]: URL: http://web-corpora.net/~agricolamz/ talks/17.03.22. Praat/17.03.22_moroz_Praat.pdf. (дата обращения 15.05.2020) 
36. Назаров М.В. Методы цифровой обработки и передачи речевых сигналов / М.В. Назаров, Ю.Н. Прохоров. – М.: Радио и связь, 1985 – 176 с. 
37. Оппенгейм А., Шафер Р. Цифровая обработка сигналов. – М.: Связь, 1979. – 416 с. 
38. Оппенгейм А., Шафер Р. Цифровая обработка сигналов [Электронный ресурс]: издание 3-е, исправленное / А. Оппенгейм. – М.: Техносфера, 2012. – 1048 с. – Режим доступа: ЭБС «Айбукс». – Неогранич. доступ 
39. Отнес Р., Эноксон Л. Прикладной анализ временных рядов. Основные методы // М.: Мир, 1982. – 432 с. 
40. Применение цифровой обработки си гналов // Под ред. А. Оппенгейма. – М.: Мир, 1980. – 552 с. 
41. Папулис А. Теория систем и преобразований в оптике // М.: Мир, 1971.
42.Пешель М. Моделирование сигналов и систем // М.: Мир, 1981.
43. Плескунин В.И., Воронина Е.Д. Теоретические основы организации и анализа выборочных данных в эксперименте. Л., Изд-во Ленингр. Ун- та, 1979.
44. Попов О. Б. Компьютерный практикум по цифровой обработке аудиосигналов. Учебное пособие для ВУЗов. – М.: Горячая линия – Телеком, 2010. – 176 с. 
45. Прокудин А, Oetzmann A., Mazzoni D.Audacity 1.2.1. Вводный курс, 2004. [Электронный ресурс]: URL: http://ikonnikovo.narod.ru/Soft/Audacity/ audacity.pdf. (дата обращения 15.05.2020) 
46. Прохоров Ю. Н. Статистические модели и рекуррентное предсказание речевых сигналов. – М.: Сов. Радио, 1984. – 240 с. 
47. Рабинер Л., Гоулд Б. Теория и применение цифровой обработки сигналов. – М.: Мир, 1978. – 848 с.84 
48. Рабинер Л. Р., Шафер Р.В. Цифровая обработка речевых сигналов // М.: Радио и связь, 1981. – 395 с. 
49. Радзишевский А. Основы аналогового и цифрового звука // М., СПб., Киев, Изд-во дом «Вильямс», 2006/ – 281.
50. Рамишвили Г. С. Автоматическое распознавание говорящего по голосу. – М.: Радио и связь, 1981. – 224 с. 
51. Рылов А.С. Анализ речи в распознающих системах // Минск: Бестпринт, 2003. – 262 с. 
52. Сапожков М. А. Речевой сигнал в кибернетике и связи. – М.: Связьиздат, 1 963. – 367 с. 
53. Сиберт У. Цепи, сигналы, системы // М.: Мир, 1988.
54. Солонина А.И., Клионский Д.М., Меркучева Т.В., Перов С.Н. Цифровая обработка сигналов и MATLAB. СПб: «БХВ-Петербург», 2013.
55. Сорокин В.Н. Теория речеобразования. М.: Радио и Связь. 1985.
56.Сорокин В.Н. Синтез речи. М.: Наука, 1992.
57.Сорокин В.Н.Теоретические основы речевых технологий. Тезисы краткого курса лекций // Институт проблем передачи информации Р АН. [Электронный ресурс]: URL: http://iitp.ru/upload/content/1374/Sorokin.pdf. (дата обращения 15.05.2020).
58. Сорокин В.Н. Речевые процессы. М.: Народное образование, 2012.
59.Столбов М. Б. Кассу А.-Р. М. Цифровая обработка речевых сигналов: Учебно-методическое пособие по лабораторному практикуму – СПб. : НИУ ИТМО, 2016. – 71 с. 
60. Тампель И.Б., Карпов А.А. Автоматическое распознавание речи. Учебное пособие. – СПб. : Университет ИТМО, 2016.– 138 с. 
61. Топников, А. И. Цифровая обработка речевых сигналов: практикум / А. И. Топников ; Яросл. гос. ун-т им. П. Г. Демидова.– Ярославль : ЯрГУ, 2018.– 40 с. 
62. Тропченко А Ю., Тропченко А.А. Цифровая обработка сигналов. Методы предварительной обработки. Учебное пособие по дисциплине «Теоретическая информатика». – СПб.: СПбГУ ИТМО, 2009 – 100 с. 
63. Тэйлор Р. Шум. – М.: Мир, 1978. – 308 с.85 
64. Уидроу Б., Стирнз С. Адаптивная обработка сигналов. – М.: Радио и связь, 1989.
65. Фант. Г. Акустическая теория речеобразования. – М.: Наука, 1964. – 283 с. 
66. Фланаган Дж. Анализ, синтез и восприятие речи. – М.: Связь, 1968.
67. Фролов А. В. Синтез и распознавание речи. Современные решения / А. В. Фролов, Г. В. Фролов. – М. : Связь, 2003. – 216 с. 
68. Хемминг Р. В. Численные методы для научных работников и инженеров. – М.: Наука, 1972. – 400 с. 
69. Хемминг Р. В. Цифровые фильтры. – М.: Недра, 1987.
70. Цвикер Э., Фельдкеллер Р. Ухо как приемник информации. – М.: Сов. Радио, 1971. – 256 с. 71. Шелухин О.И., Лукьянцев Н.Ф. Цифровая обработка и передача речи.– М.: Радио и связь, 2000.– 454 с. 
72.Audacity.[Электронный ресурс]: URL: https://audacity-pro.site.(дата обращения 15.05.2020).
73.Benesty J., Sondhi M., Huang Y.(Eds).Springer Handbook of Speech Processing // Springer, 2008, 1161 P. 
74.PRAAT Short Tutorial (2003).[ Электронный ресурс ]: URL: https ://web.stanford.edu/dept/linguistics/ corpora /material / PRAAT _workshop _manual _v421.pdf. (дата обращения 15.05.2020) 75. SIS II Специализированный звуковой редактор STC-S521. Руководство пользователя. ЦВАУ 00432-01 94 76. VOICEBOX: Speech Processing Toolbox for MATLAB.[Электронный ресурс]: URL: http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.htm (дата обращения 15.05.2020).
ПЕРЕЧЕНЬ СОКРАЩЕНИЙ 
АКФ – автокорреляционная функция 
АЧХ – амплитудно-частотная характеристика 
АР – авторегрессия (модель временного ряда) 
АРСС – авторегрессия-скользящее среднее (модель временного ряда) 
АФ – адаптивный фильтр 
АЦП – аналого-цифровой преобразователь 
БИХ – бесконечная импульсная характеристика 
БПФ – быстрое преобразование Фурье 
БШ – белый шум 
ВЧ – высокие частоты 
Гц – герцы (частота) 
дБ – децибел 
ДПФ – дискретное преобразование Фурье 
ДФ – дифференцирующий фильтр 
ДШ – дисперсия шума 
КАС – кратковременный анализ сигналов 
Кбит – килобит 
КБ – килобайт 
кГц – килогерц 
КИХ – конечная импульсная характеристика 
КСА – кратковременный спектральный анализ сигналов 
КСП – кросс-спектр (плотность кросс-спектра) 
КЛП – коэффициенты линейного предсказания 
КФ – корреляционная функция 
КМК – квадрат модуля когерентности 
ЛДС – линейная дискретная система 
МБ - мегабайт 
МНК – метод наименьших квадратов 
МР – микрофонная решетка 
НЧ – низкие частоты 
НЧ-фильтрация – выделение низкочастотной составляющей сигнала 
ОБПФ – обратное быстрое преобразование Фурье
ОДПФ – обратное дискретное преобразование Фурье 
ОСШ – отношение сигнал-шум 
ОТ – основной тон гармоник 
ПКС – плотность кросс-спектра 
ПЛИС – программируемые логические интегральные схемы 
ПСМ – плотность спектра мощности 
ПФ – преобразование Фурье 
РС – речевой сигнал 
РТ – речевые технологии 
СА – спектральный анализ 
СИФ – спектральный инверсный фильтр 
СКО – средняя квадратическая ошибка оценки 
СПМ – спектральная плотность мощности 
СС – скользящее среднее (модель временного ряда) 
ФКК – функция кросс-ковариации 
ФЛП – фильтр линейного предсказания 
ФНЧ – фильтр низких частот 
ФВЧ – фильтр высоких частот 
ФШШ – фильтр широк ополосного шума 
ФЧХ – фазово-частотная характеристика 
ФЭС – фильтр экспоненциального сглаживания 
ЦАП – цифро-аналоговый преобразователь
ЦОС – цифровая обработка сигналов
ЦОРС – цифровая обработка речевых сигналов
ЦПОС – цифровой процессор обработка сигналов
СПИСОК СИМВОЛОВ И ОБОЗНАЧЕНИЙ 
A Ap – среднее значение параметра p 
Ap[k] – среднее значение параметра на кадре k 
Ak – коэффициенты линейного предсказания (КЛП) 
A – вектор КЛП A = [A1, A2,…A p]T 
A[k]- вектор КЛП на кадре k 
Ax[f] – средний амплитудный спектр сигнала x[i] 
Ax[n] – средний дискретный амплитудный спектр сигнала x[i] 
Ax[n, k]= |Xn(k)| – дискретный амплитудный спектр сигнала x[i] на кадре k 
ai – рекурсивные коэффициенты фильтра 
Axx – матрица автокорреляции B 
b – шаг (бин) дискретных отсчетов в области частот (=1/NT) в герцах 
bi – нерекурсивные коэффициенты фильтра C 
c –скорость звука в воздухе (340 м/с) 
Cxy[m] – дискретная кросс-ковариационная функция двух процессов, соответствующая временному сдвигу m 
Cxy – вектор кроссковариации двух процессов 
CCx[m] – коэффициенты кепстра 
CCx[m, k] – коэффициенты кепстра на k-м кадре cov (x, y), 
Cxy – ковариация двух случайных величин D 
D – дистанция 
Dx – дисперсия случайной переменной x 
DFT{ } – дискретное прямое преобразование Фурье 
E e – 2,7182818… exp(x) = ex 
Ex – энергия сигнала 
Ex[k] – энергия сигнала на k-м кадре 
ep[i] – огибающие мощности 
ex[i] – огибающие сигнала 
E{x} – математическое ожидание случайной величины x 
E{x[i]} – математическое ожидание дискретного сигнала x[i] 
f – частота (циклов, выборок, операций в секунду) 
Fs – частота дискретизации сигнала (Гц) (= 1/T) 
Fn – частота Найквиста (Гц) 
Fk – частота следования кадров (Гц) 
Fm – модуляционная частота (Гц) 
Fo – частота основного тона (Гц) 
Gxy[n] – дискретная квадратичная функция когерентности 
G[n, k] – частотный коэффициент передачи, целевая функция фильтра широкополосного шума для бина n на кадре k 
G(f, k) – частотный коэффициент передачи, целевая функция фильтра широкополосного шума на частоте f на кадре k 
g – коэффициент передачи 
g[i] – коэффициент передачи для дискретного момента времени i 
gSNR – изменение отношения сигнал-шум 
h[i] – функция импульсного отклика 
H(f) – амплитудно-частотная характеристик а 
H[n] – дискретная амплитудно-частотная характеристика 
H{ } – преобразование, выполняемое системой 
i – дискретное время (временной индекс) 
Im{ } мнимая часть числа, заключенного в скобки 
IDFT{ } – дискретное обратное преобразование Фурье
𝑗𝑗=√−1 – мнимая единица K k – индекс кадров сигнала 
L – индекс шага кадров 
L{ } – оператор линейного преобразования 
lg – десятичный логарифм
ln – натуральный логарифм 
LPCCx[m ] – коэффициенты кепстра линейного предсказания
Mx – средневыпрямленное значение сигнала (магнитуда)
Mx[k] – средневыпрямленное значение сигнала на k-м кадре (𝑅𝑅𝑥𝑥 [𝑘𝑘]=1 𝑁𝑁∑ 𝑥𝑥[𝑖𝑖]𝑖𝑖=𝑁𝑁 𝑖𝑖=1) 
Mx[i] – средневыпрямленное значение сигнала для дискретного момента времени i 
MFCCx [m] – мел-спектральные коэффициенты кепстра MTF(Fm) – модуляционная передаточная функция 
m – индекс
N – размерность (количество бинов) дискретного спектра n – индекс для дискретных частот (бинов) спектра 
p – параметр 
Pxx(f) – спектральная плотность мощности (спектр мощности) 
Pnn(f) – обычно спектр мощности шума
Pss(f) – обычно спектр мощности речевого сигнала 
Pxx[m] – дискретная спектральная плотность мощности 
Pxy(f) – кросс-спектр (взаимная спектральная плотность мощности) 
Px[i] – мощность сигнала для дискретного момента времени i 
Px[k] –мощность сигнала на k-м кадре 
Ps – мощность речевого сигнала
Pn – мощность шума 
PCCxy – коэффициент корреляции Пирсона 
q – индекс 
rxy[m] – дискретная кросс-корреляционная функция двух процессов (нормированная кросс-ковариация), соответствующая временному сдвигу m 
Rxx[m] – дискретная автоковариационная (автокорреляционная) функция, соответствующая временному сдвигу m 
rxx[m] – дискретная нормализованная (нормированная) КФ Rxx[m]/ Rxx [0] 
RXY – коэффициент корреляции между векторами Re{ } действительная часть числа, заключенного в скобки 
s[i] – временной ряд (обычно речевой сигнал) 
SNR – отношение сигнал-шум 
SNRseg – сегментное отношение сигнал-шум 
Sxx(f) – спектральная плотность энергии 
Sxx[n] – дискретная спектральная плотность энергии
t – непрерывное время 
T – шаг (интервал, период) дискретизации (выборки) по времени (= 1/Fs) 
THR – порог To – период основного тона, период процесса 
Ta – постоянная времени сглаживания Tr, 
T60 – время реверберации 
v[i] – возбуждающий случайный процесс (в т.ч. белый шум) 
W(f) – АЧХ фильтра (обычно фильтра Винера) 
w[i] – коэффициенты фильтра Винера 
x[i] – временной ряд, дискретный сигнал (обычно вход системы) 
x(t) – непрерывный сигнал (функция времени) 
x(iT) – дискретные временные отсчеты сигнала x (t) 
X[k] = [x[kL], x[kL-1], … x [kL-N+1]]T – вектор отсчетов сигнала на кадре X[n, k], 
Xn[k] – коэффициенты дискретного комплексного спектра сигнала на кадре k Xr[n, k], 
Xi[n, k] – реальная и мнимая части дискретного комплексного спектра на кадре k |Xn[k]|, 
|X[n,k]|| – модуль дискретного комплексного спектра на кадре k <x> – оценка средней величины сигнала x[i] 
y[i] – временной ряд, дискретный сигнал (обычно выход системы) 
z – оператор сдвига вперед: 
zx[i] = x[i+1] z-1 – оператор сдвига назад: 
z-1x[i] = x [i-1]
СИМВОЛЫ ГРЕЧЕСКОГО АЛФАВИТА 
α – коэффициент забывания /усреднения (forgetting/averaging factor)
β – постоянная сглаживания(smoothing factor) 
λ – длина звуковой волны 
δ[x] – дельта- функция Дирака δ[i] – единичная цифровая дельта-функция, функция Кронекера 
Δẋ – смещение оценки величины x Δ – оператор разности назад первого порядка: 
Δ x[i] = x[i]- x[i-1] = (1- z-1) x[i] 
ΔF (BW) – ширина полосы пропускания фильтра 
ΔT – временной интервал εt – возбуждающий случайный процесс, в т.ч. белый шум Γxy(f), Γxy(n) – комплексная функция когерентности 
μx – среднее значение случайной величины x ρxy – корреляция, нормированная ковариация: σ xy/ σ x σy ρi – нормированная автокорреляционная функция 
σ – стандартное отклонение 
τ – временная задержка, запаздывание π – 3,14159265… 
φ – фазовый угол Φx(f),
Φx[n] – фазовый спектр непрерывный и дискретный Φxy(f), 
Φxy[n] – фазовый кросс-спектр непрерывный и дискретный 
Ψx – среднее квадратичное значение случайной величины x 
ω – угловая частота, рад/с 
Ω – нормализованная угловая частота, рад/отсчет 
()* – символ комплексного сопряжения 
(∗) – символ свертки < > – обозначение операции усреднения по времени 
[ ]T – обозначение операции транспонирования вектора 
∏ – знак произведения 
∑ – знак суммы
АНГЛО-РУССКИЙ СЛОВАРЬ ТЕРМИНОВ 
Термин Определение 
AAccess Control and Authentication Контроль доступа 
Adaptive Filter (AF) Адаптивный фильтр 
Adaptive line enhancer (ALE) Адаптивный линейный компенсатор 
Adaptive null-forming (ANF) Адаптивный формирователь нуля 
Adaptive Noise Canceller (ANC) Адаптивный компенсатор шума 
Amplitude-Frequency Response (AFR) Амплитудно-частотная характеристика фильтра (АЧХ) 
Analogue-to-Digital Converter (ADC) Аналого-цифровой преобразователь (АЦП) 
Audio-to-Audio Alignment Приведение среднего спектра сигнала к среднему спектру образцового сигнала 
Autocorrelation (ACF) Автокорреляционная) функция (АКФ) 
Automatic Speech Recognition (ASR) Автоматическое распознавание речи
Back-end Прикладная (вторичная) обработка РС 
Band Диапазон частот, полоса 
Bandwidth (BW) Ширина полосы пропускания 
Band-pass filter (BPF) Пропускающий полосовой фильтр 
Band-stop filter (BSF) Заграждающий полосовой фильтр 
Bit rate Цифровой поток bps = bit/s Мера цифровой потока – число бит, передаваемых в секунду 
Blind equalization Слепое выравнивание канала 
Clipping Клиппирование
Channel deconvolution, equalization, compensation Компенсация, нормализация канала 
Cepstral Distance (CD) Кепстральная дистанция 
Cepstral Mean Normalization (CMN) Нормализация канала на основе вычитания среднего кепстра 
Cepstral Mean Subtraction (CMS) Вычитание среднего кепстра 
Comb-filter Фильтр-гребенка 
Computer Acoustic Scene Analysis (CASA) Компьютерный анализ акустических сцен
Cross correlation function (CCF) Кросс-ковариационная функция двух процессов (ККФ) 
Cross spectrum Кросс-спектр Cross power spectrum density (CSPD). Плотность кросс-спектра (ПКС)
Data compression Сжатие данных 
Dropouts Пропадание сигнала 
Digital-to-Analogue Converter (DAC) Цифро-аналоговый преобразователь (ЦАП) 
Direct current (DC), DC offset Постоянный ток, постоянная составляющая (среднее значение) сигнала 
DC cut Удаление медленно меняющейся постоянной составляющей сигнала 
Discrete Cosine Transformation (DCT) Дискретное косинусное преобразование 
Digital Signal Processing (DSP) Цифровая обработка сигналов (ЦОС)
Direction of Arrival (DOA) Направление прихода (сигнала) 
Decibel (dB) Децибел (дБ) 
Direct to Reverberation Ratio (DRR) Отношение интенсивностей прямого звука и реверберации 
Discrete Fourier Transform (DFT) Дискретное преобразование Фурье (ДПФ) 
Distortion Искажение 
Deep Neural Network (DNN) Глубокая нейронная сеть 
Dual-Tone Multi-Frequency (DTMF) Двухтональный аналоговый сигнал для кодирования знаков
Equaliser/Equalizer (EQ) Эквалайзер 
Early Decay Time (EDT) Раннее время затухания реверберации 
Echo Return Loss Enhancement (ERLE) Мера эффективности подавления эха компенсатором эха, дБ
Frequency-Domain Adaptive Filtering (FDAF) Частотный адаптивный фильтр 
Finite Impulse Response (FIR) Конечная импульсная характеристика (КИХ) 
Fast Fourier Transform (FFT) Быстрое преобразование Фурье (БПФ) 
Fourier Transform (FT) Преобразование Фурье (ПФ) 
Framing Разбиение сигнала на кадры 
Front-End Первичная обработка РС 
Fundamental Frequency Частота основного тона
Graphic EQ Графический эквалайзер 
Gain Коэффициент передачи (коэффициент усиления уровня звука или электрического сигнала) 
Gaussian Mixture Model (GMM) Модель гауссовых смесей 
Generalized Spectral Subtraction (GSS) Обобщенное спектральное вычитание 
Graphics Processing Unit (GPU), Графические процессоры
Harmonic cancellation Подавление гармоник 
Harmonic enhancement Выделение гармоник 
Hearing Aids Коррекция нарушений слуха и речи 
Hertz (Hz) Герц 
High-pass filter (HPF) Фильтр высоких частот (ФВЧ) 
Harmonic Tone Suppression (HTS) Подавление гармоник тона
Independent Component Analysis(IA) Анализ независимых компонент (метод слепого разделения сигналов независимых источников) 
Impulse response (IR) Импульсный отклик, характеристика 
Instant Tone Suppression (ITS) Подавление тональных импульсов 
Integrated Circuit (IC) Технология интегральных схем 
Interactive Voice Response (IVR) systems Системы голосового самообслуживания 
Infinite Impulse Response (IIR) Бесконечная импульсная характеристика (БИХ) 
Inverse Discrete Fourier Transform (IDFT) Дискретное обратное преобразование Фурье 
Inverse Fast Fourier Transform (IFFT) Обратное быстрое преобразование Фурье (ОБПФ) 
Inverse Discrete Cosine Transformation (IDCT) Дискретное обратное косинусное преобразование 
kHz Килогерц (кГц) 
Kurtosis Эксцесс
Language Recognition Распознавания языка 
Least Mean Square (LMS) Наименьшее среднеквадратическое значение
Least-squares error (LSE) Ошибка наименьших квадратов 
Linear Prediction (LP) Линейное предсказание 
Linear prediction coefficients (LPC) Коэффициенты линейного предсказания (КЛП) 
Linear Prediction Cepstral Coefficients (LPCC) Коэффициенты кепстра спектра линейного предсказания 
Linear Time-Invariant (LTI) Systems Инвариантные по времени линейные системы 
Linear Spectrum Frequency (LSF) domain Пространство линейного спектра частот
Low-pass filter (LPF) Фильтр низких частот (ФНЧ) 
Magnitude-squared Coherence function (MSC) Квадрат модуля когерентности (КМК) 
Magnitude Spectral Subtraction (MSS) Амплитудное спектральное вычитание 
Mean Среднее Mean Square Среднеквадратическое значение 
Mel-Frequency Cepstral Coefficients (MFCC) Коэффициенты кепстра мел-частотного спектра 
Mean Opinion Score MOS Средняя экспертная оценка 
Mel-Frequency Cepstral Coefficients (MFCC) Коэффициенты кепстра мел-частотного спектра 
Multiple-Input, Multiple-Output (MIMO) system Система с одним входом и одним выходом 
Multiple-Input, Single-Output MISO system Система со многими входами и многими выходами 
Multi-notch filter (MNF) Многополосный щелевой фильтр 
Magnitude Sum Function (MSF) Средний модуль, средневыпрямленное значение сигнала (магнитуда) 
Mean Square Error (MSE) Среднеквадратическая (средняя квадратическая ошибка (СКО) 
Minimum Mean Square Error (MMSE) Критерий минимума СКО 
MMSE Short-term Spectral Analysis (MMSE- STSA) Оценка кратковременной амплитуды спектра по критерию минимума СКО 
MMSE Logarithmic Spectral Analysis (MMSE-LSA) Оценка логарифмической амплитуды спектра по критерию минимума СКО 
Modulation Transfer Function (MTF) модуляционная передаточная функция 
Moving average estimator (filter) Фильтр скользящего среднего, в том числе фильтр экспоненциального сглаживания
Natural Language Processing (NLP) Понимание текстов и естественного языка Noise Cancellation Компенсация помехи
Noise Reduction/Suppression (NR/NS) Подавление шума
Normalized Least Mean Square (NLMS) Нормализованный минимум СКО (алгоритм минимума СКО с нормализацией) 
Non-negative Matrix Factorization (NMF) Неотрицательное матричное разложение (НМР) 
Nonlinear Spectral Subtraction (NSS) Нелинейное спектральное вычитание 
Notch filter Выкалывающий фильтр (подавляющий) фильтр-пробка 
Pulse Code Modulation (PCM) Импульсно-кодовая модуляция (цифровое представление звука)
Pitch Основной тон гармонического сигнала 
Pearson ’s Correlation Coefficient (PCC) Коэффициент корреляции Пирсона
Power Spectral Density (PSD) Спектральная плотность мощности (СПМ) 
Power Spectral Subtraction (PSS) Метод спектрального вычитания 
Root Mean Square (RMS) Квадратный корень из среднеквадратического значения 
Room Impulse Response (RIR) Импульсный отклик помещения 
Room Transfer Function (RTF) Передаточная функция помещения 
Real Time (RT) Масштаб реального времени Reverberation Time (TR) Время реверберации 
Speech enhancement Выделение речи 
Speech coding, data compression Сжатие и кодирование речевых сигналов
 Standard Deviation (Std) Стандартное отклонение,  
Single-Input, Multiple-Output (SIMO) system Система с одним входом и многими выходами 
Single-Input, Single-Output (SISO) system Система с одним входом и одним выходом 
Short-Time Кратковременная оценка 
Short-Time Energy (STE) Кратковременная энергия 
Signal to Interference Ratio (SIR) Отношение сигнал-помеха, интерференция 
Signal-to-Noise Ratio (SNR) Отношение сигнал-шум (ОСШ) 
Signal-to-Noise Ratio Enhancement (SNRE) Улучшение отношения сигнал-шум 
Slot-, one-formant filter Узкополосный полосовой фильтр 
Spectral-domain Спектральное пространство 
Spectral Subtraction Method (SSM) Метод спектрального вычитания 
Spectral Power Density (SPD) Спектральная плотность мощности (СПМ)
Spectral Flux (SF) Спектральный поток 
Speech /Text Analytics Речевая, текстовая и акустическая аналитика 
Speech coding Сжатие и кодирование речевых сигналов
 Speech enhancement Компенсация искажений РС 
Short-Time Fourier Transform (STFT) Кратковременное преобразование Фурье 
Short-Time Spectral Amplitude (STSA) Кратковременная амплитуда спектра 
Snapshots Измерения (замеры) 
Standard deviation (Std) Стандартное отклонение 
Speech Transmission Index (STI) Индекс передачи речи 
Teager Energy Operator (TEO) Энергия Тигера (Тигера-Кайзера) 
Text-to-Speech Synthesis (TSS) Автоматический синтез речи по тексту 
Time-Domain Methods (TD) Временные методы 
Time-Domain Adaptive Filtering (TDAF) Временной адаптивный фильтр 
Time waveform Осциллограмма 
Tonal Noise Suppression (TNS) Подавление тонального шума 
Tone Spectral Suppression (TSS) Спектральное подавление тонального шума 
Wiener Filter (WF) Фильтр Винера 
Windowing Оконное взвешивание 
Weighted Prediction Error (WPE) Взвешенная ошибка предсказания 
White Noise (WN) Белый шум (БШ) 
Voice Activity Detector (VAD) Детектор (обнаружитель) речевой активности 
Variance (Var) Дисперсия 
Voice Recognition/Biometric Authentication Верификация и идентификация дикторов, голосовая биометрия 
Voice Assistants Голосовая помощь 
Voice Cloning Клонирование голоса 
Voice over Internet Protocol (VoIP) Передача голоса по Интернет-протоколу 
Zero-Crossing Rate (ZCR) Частота пересечения нуля
СОДЕРЖАНИЕ 
ПРЕДИСЛОВИЕ............................................................................................................................ 3 
1 ВВЕДЕНИЕ В ПРЕДМЕТ.......................................................................................................... 5
1.1 Краткая история речевых технологий............................................................................... 5
1.2 Предметная область цифровой обработки речевых сигналов........................................ 7
1.3 Профессиональные сообщества и информационные ресурсы ЦОРС.......................... 11
1.4 Работа с пособием............................................................................................................. 12 
Вопросы и упражнения........................................................................................................... 14 
2 ЗВУК И ЕГО ЦИФРОВОЕ ПРЕДСТАВЛЕНИЕ................................................................... 15
2.1 Звук..................................................................................................................................... 15
2.2 Аналого-цифровое преобразование звуковых сигналов............................................... 16 
2.3 Дискретизация во времени............................................................................................... 16 
2.4 Понятие частоты................................................................................................................ 17 
2.5 Эффект наложения спектров............................................................................................ 18 
2.6 Квантование сигналов....................................................................................................... 18 
2.7 Цифровой звук и его запись............................................................................................. 20 
2.8 Осциллограмма.................................................................................................................. 21 
Вопросы и упражнения........................................................................................................... 24 
3 СТАТИСТИЧЕСКИЕ ХАРАКТЕРИСТИКИ РЕЧЕВЫХ СИГНАЛОВ.............................. 25 
3.1 Случайная величина и ее характеристики...................................................................... 25 
3.2 Случайный процесс и его характеристики...................................................................... 27 
3.3 Выборочные оценки параметров и их погрешности...................................................... 27 
3.4 Выборочные оценки основных параметров случайного процесса............................... 29 
3.5 Выборочная оценка функции распределения................................................................. 30 
3.6 Анализ статистической взаимосвязи случайных величин............................................ 32 
Вопросы и упражнения........................................................................................................... 34 
4 ВРЕМЕННОЙ И ЧАСТОТНЫЙ АНАЛИЗ СИГНАЛОВ..................................................... 35 
4.1 Автоковариационная функция процесса......................................................................... 35 
4.2 Ковариация и ее оценка.................................................................................................... 36 
4.3 Спектральный анализ сигналов........................................................................................ 38 
4.4 Спектр мощности.............................................................................................................. 40 
4.5 Кросс-спектр...................................................................................................................... 42 
4.6 Соотношение между ковариационной функцией и кросс-спектром........................... 43 
4.7 Функция когерентности и ее оценка............................................................................... 43 
Вопросы и упражнения........................................................................................................... 46 
5 СИСТЕМЫ И ПРЕОБРАЗОВАНИЯ СИГНАЛОВ............................................................... 47 
5.1 Общие сведения о системах............................................................................................. 47
5.2 Линейные системы............................................................................................................ 48 
5.3 Линейные дискретные системы....................................................................................... 49 
5.4 Дискретная свёртка........................................................................................................... 50 
5.5 Система с конечной импульсной характеристикой....................................................... 51 
5.6 Система с бесконечной импульсной характеристикой.................................................. 52 
5.7 Спектральное описание линейных систем с одним входом и выходом...................... 53 
5.8 Оценка характеристик линейных систем........................................................................ 54 
Вопросы и упражнения........................................................................................................... 56 
6 ФИЛЬТРАЦИЯ ДИСКРЕТНЫ Х СИГНАЛОВ...................................................................... 57 
6.1 Рекурсивные фильтры первого порядка.......................................................................... 57 
6.2 Дифференцирующие фильтры......................................................................................... 63 
6.3 Сглаживающие КИХ-фильтры......................................................................................... 64 
6.4 Полосовые фильтры и фильтры-гребенки...................................................................... 66 
6.5 Фильтры в частотной области.......................................................................................... 71 
Вопросы и упражнения........................................................................................................... 74 ЗАКЛЮЧЕНИЕ............................................................................................................................ 75 
ПРИЛОЖЕНИЕ А ПРОФЕССИОНАЛЬНЫЕ СООБЩЕСТВА В ОБЛАСТИ РЕЧЕВЫХ ТЕХНОЛОГИЙ........................................................................................................ 76 
ПРИЛОЖЕНИЕ Б СИСТЕМ Ы СТАНДАРТИЗАЦИИ........................................................... 77 
ПРИЛОЖЕНИЕ В ОСНОВНЫЕ ЖУРНАЛЫ ПО РЕЧЕВЫМ ТЕХНОЛОГИЯМ.............. 78 
ПРИЛОЖЕНИЕ Г ОСНОВНЫЕ КОНФЕРЕНЦИИ ПО РЕЧЕВЫМ ТЕХНОЛОГИЯМ..... 80 
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ.................................................................. 81 
ПЕРЕЧЕНЬ СОКРАЩЕНИЙ..................................................................................................... 86 
СПИСОК СИМВОЛОВ И ОБОЗНАЧЕНИЙ............................................................................ 88 СИМВОЛЫ ГРЕЧЕСКОГО АЛФАВИТА................................................................................ 93 
АНГЛО-РУССКИЙ СЛОВАРЬ ТЕРМИНОВ........................................................................... 94      
Столбов Михаил Борисович  Основы анализа и обработки речевых сигналов Учебное пособие 
В авторской редакции Редакционно-издательский отдел Университета ИТМО Зав. РИО    Н.Ф. Гусарова Подписано к печати Заказ № Тираж Отпечатано на ризографе
Редакционно-издательский отдел Университета ИТМО 197101, Санкт-Петербург, Кронверкский пр., 49, литер А
