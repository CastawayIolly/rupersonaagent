{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "import transformers\n",
    "\n",
    "t5_cpu = transformers.T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-base-multitask\", resume_download=True)\n",
    "t5_cuda = transformers.T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-base-multitask\", resume_download=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cpu = torch.randint(high=30000, size=(1, 32), dtype=torch.int64)\n",
    "input_cuda = torch.randint(high=30000, size=(1, 32), dtype=torch.int64).cuda()\n",
    "\n",
    "t5_cpu.generate(input_cpu, do_sample=True, num_beams=4, max_new_tokens=20)\n",
    "t5_cuda.generate(input_cuda, do_sample=True, num_beams=4, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "t5_ort_cpu = ORTModelForSeq2SeqLM.from_pretrained(\"cointegrated/rut5-base-multitask\",\n",
    "                                                   from_transformers=True,\n",
    "                                                   provider=\"CPUExecutionProvider\")\n",
    "\n",
    "t5_ort_cuda = ORTModelForSeq2SeqLM.from_pretrained(\"cointegrated/rut5-base-multitask\",\n",
    "                                                   from_transformers=True,\n",
    "                                                   provider=\"CUDAExecutionProvider\")\n",
    "t5_ort_cpu.generate(input_cpu, do_sample=True, num_beams=4, max_new_tokens=20)\n",
    "t5_ort_cuda.generate(input_cuda, do_sample=True, num_beams=4, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForSeq2SeqLM\n",
    "\n",
    "t5_ort_trt = ORTModelForSeq2SeqLM.from_pretrained(\"cointegrated/rut5-base-multitask\",\n",
    "                                      from_transformers=True,\n",
    "                                      provider=\"TensorrtExecutionProvider\")\n",
    "t5_ort_trt.generate(input_cuda, do_sample=True, num_beams=4, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "results = []\n",
    "for seq_len in tqdm([2, 8, 32, 64]):\n",
    "    input_cpu = torch.randint(high=30000, size=(1, seq_len), dtype=torch.int64)\n",
    "    input_cuda = torch.randint(high=30000, size=(1, seq_len), dtype=torch.int64).cuda()\n",
    "    for model, description in tqdm(zip([t5_cpu, t5_cuda, t5_ort_cpu, t5_ort_cuda, t5_ort_trt],\n",
    "                                  [\"PyTorch (CPU)\", \"PyTorch (CUDA)\", \"ORT (CPU)\", \"ORT (CUDA)\", \"ORT-TRT\"])):\n",
    "        input_tensor = input_cpu if \"CPU\" in description else input_cuda\n",
    "        model.generate(input_tensor, do_sample=True, num_beams=4, max_new_tokens=20)  # warmup\n",
    "        results.append(benchmark.Timer(\n",
    "            stmt=\"model.generate(input_tensor, do_sample=True, num_beams=4, max_new_tokens=20)\",\n",
    "            globals={'model': model, 'input_tensor': input_tensor},\n",
    "            num_threads=8,\n",
    "            label=\"label\",\n",
    "            sub_label=f\"seq_len={seq_len}\",\n",
    "            description=description,\n",
    "        ).blocked_autorange(min_run_time=10))\n",
    "compare = benchmark.Compare(results)\n",
    "compare.colorize()\n",
    "compare.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}